[
  {
    "objectID": "talk/2021-05-04-data-viz-accessibility/index.html",
    "href": "talk/2021-05-04-data-viz-accessibility/index.html",
    "title": "Revealing Room for Improvement in Accessibility within a Social Media Data Visualization Learning Community",
    "section": "",
    "text": "Presented with Liz Hare, PhD from Dog Genetics, LLC"
  },
  {
    "objectID": "talk/2021-05-04-data-viz-accessibility/index.html#abstract",
    "href": "talk/2021-05-04-data-viz-accessibility/index.html#abstract",
    "title": "Revealing Room for Improvement in Accessibility within a Social Media Data Visualization Learning Community",
    "section": "Abstract",
    "text": "Abstract\nWe all aim to use data to tell a compelling story, and many of us enjoy sharing how we got there by open-sourcing our code, but we don‚Äôt always share our story with everyone. Even kind, supportive, and open communities like the #TidyTuesday R learning community on Twitter has a ways to go before the content shared can be accessible to everyone.Lived experiences of blind R users tell us that most data visualizations shared for TidyTuesday are inaccessible to screen reading technology because they lack alternative text (i.e.¬†alt text) descriptions. Our goal was to bring this hidden lack of accessibility to the surface by examining the alternative text accompanying data visualizations shared as part of the TidyTuesday social project.We scraped the alternative text from 6,443 TidyTuesday images posted on Twitter between April 2, 2018 and January 31, 2021. The first image attached to each tweet was considered the primary image and was scraped for alternative text. Manual web inspection revealed the CSS class and HTML element corresponding to the primary image, as well as the attribute containing the alternative text. We used this information and the ROpenSci {RSelenium} package to scrape the alternative text. Our preliminary analysis found that only 2.4% of the images contained a text description entered by the tweet author compared to 84% which were described by default as ‚ÄòImage.‚ÄôThis small group of intentional alternative text descriptions had a median word count of 18 (range: 1-170), and a median character count of 83 (range: 8-788). As a reference point, Twitter allows 240 characters in a single tweet and 1,000 characters for image descriptions. This analysis was made possible thanks to a dataset of historical TidyTuesday tweet data collected using the ROpenSci {rtweet} package, and openly available in the TidyTuesday GitHub repository.We will present during Session 0 on May 4, 2021: Crowdcast Link"
  },
  {
    "objectID": "talk/2022-02-11-tdw-ehr-lessons/index.html",
    "href": "talk/2022-02-11-tdw-ehr-lessons/index.html",
    "title": "Lessons Learned from the EHR",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "talk/2020-08-31-tour-of-the-tidyverse/index.html",
    "href": "talk/2020-08-31-tour-of-the-tidyverse/index.html",
    "title": "An Antarctic Tour of the Tidyverse",
    "section": "",
    "text": "Learn how to explore and manipulate data in R with packages from the Tidyverse. We‚Äôll introduce the eight core packages that make up the Tidyverse and use at least one function from each package while exploring a dataset on the migration of penguins.\n\n\n\n Back to top"
  },
  {
    "objectID": "talk/index.html",
    "href": "talk/index.html",
    "title": "Talks",
    "section": "",
    "text": "Considering Equity in Data Visualization\n\n\nInvited talk for the Leonard Davis Institute of Health Economics Summer Undergraduate Mentored Research Program (SUMR)\n\n\n\nResearch\n\n\n\n\n\n\nJul 10, 2024\n\n\nSilvia Canel√≥n, Emily Seeburger\n\n\n\n\n\n\n\n\n\n\n\n\nEnvironmental Justice and Policy Panel\n\n\nPanel discussion hosted by Penn Science Policy and Diplomacy Group & Climate Leaders @Penn\n\n\n\nResearch\n\n\n\n\n\n\nMar 26, 2024\n\n\nSilvia Canel√≥n\n\n\n\n\n\n\n\n\n\n\n\n\nPlace-based Interventions to Promote Structural Change & Equity\n\n\nTalk for the Philadelphia Department of Public Health Epis for Equity work group, highlighting the placed-based intervention projects at the Urban Health Lab\n\n\n\nResearch\n\n\n\n\n\n\nOct 11, 2023\n\n\nSilvia Canel√≥n, Emily Seeburger\n\n\n\n\n\n\n\n\n\n\n\n\nData Analytics 101\n\n\nPractical talk highlighting how data can be leveraged to support community-academic partnerships\n\n\n\nEducation\n\n\n\n\n\n\nMar 9, 2023\n\n\nSilvia Canel√≥n, Emily Seeburger\n\n\n\n\n\n\n\n\n\n\n\n\nThinking Big with Maps in R\n\n\nTips on Wrangling Large Vector Data into Interactive Maps\n\n\n\nR\n\n\ngeospatial\n\n\n\n\n\n\nNov 10, 2022\n\n\nSilvia Canel√≥n\n\n\n\n\n\n\n\n\n\n\n\n\nCreating the Philly Center City SIPS Interactive Map\n\n\nR-Ladies Philly workshop on webscraping, geocoding, and interactive map-making\n\n\n\nR\n\n\nWorkshop\n\n\nEducation\n\n\nR-Ladies\n\n\nrvest\n\n\ntidygeocoder\n\n\nleaflet\n\n\n\n\n\n\nSep 29, 2022\n\n\nSilvia Canel√≥n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Traumatic Brain Injury Mechanisms and Severity Using Electronic Health Records\n\n\nFlashtalk and poster presenting preliminary results for a study on TBI among female patients at Penn Medicine\n\n\n\nResearch\n\n\nEHR\n\n\nTBI\n\n\n\n\n\n\nApr 27, 2022\n\n\nSilvia Canel√≥n, Rebecca Morse, Mary Regina Boland\n\n\n\n\n\n\n\n\n\n\n\n\nLessons Learned from the EHR\n\n\nToronto Data Workshop talk about working with Electronic Health Record data\n\n\n\nResearch\n\n\nEHR\n\n\n\n\n\n\nFeb 11, 2022\n\n\nSilvia Canel√≥n\n\n\n\n\n\n\n\n\n\n\n\n\nProfessional, Polished, Presentable: Making Great Slides with xaringan\n\n\nA useR!2021 tutorial about making great slides with xaringan\n\n\n\nR\n\n\nEducation\n\n\nxaringan\n\n\nuseR\n\n\n\n\n\n\nJul 7, 2021\n\n\nGarrick Aden-Buie & Silvia Canel√≥n\n\n\n\n\n\n\n\n\n\n\n\n\nRevealing Room for Improvement in Accessibility within a Social Media Data Visualization Learning Community\n\n\nData visualization accessibility talk to share what we found after scraping alternative (alt) text from data viz shared on Twitter as part of the #TidyTuesday social project.\n\n\n\nR\n\n\nEducation\n\n\nTidyTuesday\n\n\nTidyTuesdayAltText\n\n\nrtweet\n\n\nRSelenium\n\n\naccessibility\n\n\n\n\n\n\nMay 4, 2021\n\n\nSilvia Canel√≥n, Liz Hare\n\n\n\n\n\n\n\n\n\n\n\n\nThe Impact of Sickle Cell Status on Adverse Delivery Outcomes Using Electronic Health Record Data\n\n\nApplied Clinical Research Informatics: Solving Real World Problems. Oral Presentations S17: March 23, 2021 11:30am-1pm ET\n\n\n\nResearch\n\n\n\n\n\n\nMar 22, 2021\n\n\nSilvia P. Canel√≥n, Samantha Butts, Mary Regina Boland\n\n\n\n\n\n\n\n\n\n\n\n\nWriting Presentations in R\n\n\nPackage demonstration for R-Ladies Seattle showing how to make beautiful slides with xaringan and how to deploy them.\n\n\n\nR\n\n\nEducation\n\n\nDemo\n\n\nR-Ladies\n\n\nxaringan\n\n\n\n\n\n\nMar 16, 2021\n\n\nSilvia Canel√≥n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Learn-R to Teach-R: An Expert Panel on Effective R Instruction\n\n\nAn R-Ladies Philly panel and discussion event on R instruction and education.\n\n\n\nR\n\n\nEducation\n\n\nR-Ladies\n\n\n\n\n\n\nFeb 18, 2021\n\n\nSilvia Canel√≥n, Ama Nyame-Mensah, Cass Wilkinson Salda√±a\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducci√≥n al Paquete xaringan\n\n\nTaller del paquete xaringan para presentaciones, creado para R-Ladies Xalapa\n\n\n\nR\n\n\nWorkshop\n\n\nEducation\n\n\nR-Ladies\n\n\nEspa√±ol\n\n\nxaringan\n\n\n\n\n\n\nDec 17, 2020\n\n\nSilvia Canel√≥n\n\n\n\n\n\n\n\n\n\n\n\n\nSharing Your Work with xaringan: The Basics and Beyond\n\n\nAn introduction to xaringan for presentations, created for the NHS-R Community 2020 Virtual Conference\n\n\n\nR\n\n\nxaringan\n\n\nWorkshop\n\n\nxaringan\n\n\n\n\n\n\nNov 3, 2020\n\n\nSilvia Canel√≥n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Antarctic Tour of the Tidyverse\n\n\nAn introductory tidyverse tutorial created and presented for R-Ladies Chicago\n\n\n\nR\n\n\nEducation\n\n\nTutorial\n\n\nR-Ladies\n\n\ntidyverse\n\n\n\n\n\n\nAug 31, 2020\n\n\nSilvia Canel√≥n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "talk/2021-02-18-r-teaching-panel/index.html",
    "href": "talk/2021-02-18-r-teaching-panel/index.html",
    "title": "From Learn-R to Teach-R: An Expert Panel on Effective R Instruction",
    "section": "",
    "text": "This panel and discussion event will be focused on R instruction and education. As a learner, what are some recommended resources for developing my R skills? As an instructor, how can I make my materials and presentations more effective? What does data science education look like in 2021? What types of careers are out there in R education? How can I gain experience teaching R?\nPanelists:\nAma Nyame-Mensah is a Postdoctoral Fellow and Research Associate in the School of Social Policy & Practice and the Graduate School of Education at the University of Pennsylvania. Her current work rethinks whether and how quantitative and computational methods can contribute to a more equitable understanding of marginalized children‚Äôs and families‚Äô learning and development. Ama is passionate about empowering people to use data for social analysis and critique data and data technologies. When not working, Ama can be found tinkering with data and designing visualizations. Website: https://www.anyamemensah.com\nCass Wilkinson Salda√±a helps learners, researchers, and communities to engage meaningfully (and critically) with data. They currently work as a Data Instructional Specialist at the Children‚Äôs Hospital of Philadelphia‚Äôs Research Institute, and teach introduction to R courses at Yeshiva University. Previously, Cass worked as the Social Science and Geospatial Data Librarian at Cornell University. As a data educator and data librarian, Cass participates and collaborates in open source ecosystems, especially in the domains of open science, digital scholarship, and civic data. They also strive to advocate for justice in worker and learner communities. Website: https://cassws.net\nSilvia Canel√≥n is a postdoctoral research scientist in biomedical informatics at the University of Pennsylvania in Philadelphia. She uses data science in the public and population health fields and is particularly interested in leveraging electronic health record data to study reproductive health outcomes. Silvia is formally trained as a biomedical engineer and an RStudio Certified Tidyverse Instructor. She loves community organizing and is passionate about R education as a way to help build power in her communities."
  },
  {
    "objectID": "talk/2021-02-18-r-teaching-panel/index.html#description",
    "href": "talk/2021-02-18-r-teaching-panel/index.html#description",
    "title": "From Learn-R to Teach-R: An Expert Panel on Effective R Instruction",
    "section": "",
    "text": "This panel and discussion event will be focused on R instruction and education. As a learner, what are some recommended resources for developing my R skills? As an instructor, how can I make my materials and presentations more effective? What does data science education look like in 2021? What types of careers are out there in R education? How can I gain experience teaching R?\nPanelists:\nAma Nyame-Mensah is a Postdoctoral Fellow and Research Associate in the School of Social Policy & Practice and the Graduate School of Education at the University of Pennsylvania. Her current work rethinks whether and how quantitative and computational methods can contribute to a more equitable understanding of marginalized children‚Äôs and families‚Äô learning and development. Ama is passionate about empowering people to use data for social analysis and critique data and data technologies. When not working, Ama can be found tinkering with data and designing visualizations. Website: https://www.anyamemensah.com\nCass Wilkinson Salda√±a helps learners, researchers, and communities to engage meaningfully (and critically) with data. They currently work as a Data Instructional Specialist at the Children‚Äôs Hospital of Philadelphia‚Äôs Research Institute, and teach introduction to R courses at Yeshiva University. Previously, Cass worked as the Social Science and Geospatial Data Librarian at Cornell University. As a data educator and data librarian, Cass participates and collaborates in open source ecosystems, especially in the domains of open science, digital scholarship, and civic data. They also strive to advocate for justice in worker and learner communities. Website: https://cassws.net\nSilvia Canel√≥n is a postdoctoral research scientist in biomedical informatics at the University of Pennsylvania in Philadelphia. She uses data science in the public and population health fields and is particularly interested in leveraging electronic health record data to study reproductive health outcomes. Silvia is formally trained as a biomedical engineer and an RStudio Certified Tidyverse Instructor. She loves community organizing and is passionate about R education as a way to help build power in her communities."
  },
  {
    "objectID": "talk/2020-12-17-introduccion-xaringan/index.html",
    "href": "talk/2020-12-17-introduccion-xaringan/index.html",
    "title": "Introducci√≥n al Paquete xaringan",
    "section": "",
    "text": "El taller tiene por objetivo introducir a las participantes al paquete xaringan de R como una herramienta para crear diapositivas de presentaci√≥n impresionantes que se pueden implementar en la web para compartir f√°cilmente.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "talk/2020-11-03-xaringan-basics-and-beyond/index.html",
    "href": "talk/2020-11-03-xaringan-basics-and-beyond/index.html",
    "title": "Sharing Your Work with xaringan: The Basics and Beyond",
    "section": "",
    "text": "This four-hour hands-on workshop will be a gentle introduction to the xaringan package as a tool to create impressive presentation slides that can be deployed to the web for easy sharing.\nDay 1 (Nov.¬†3, 3-5pm BST) will cover the nuts and bolts of creating presentation slides using xaringan and deploying them in HTML format for easy sharing with others.\nDay 2 (Nov.¬†5, 3-5pm BST) will cover how to take your slides to the next level with the xaringanExtra package and how to customize slides with CSS.\nThis workshop is designed for R users already familiar with R Markdown and GitHub."
  },
  {
    "objectID": "talk/2020-11-03-xaringan-basics-and-beyond/index.html#description",
    "href": "talk/2020-11-03-xaringan-basics-and-beyond/index.html#description",
    "title": "Sharing Your Work with xaringan: The Basics and Beyond",
    "section": "",
    "text": "This four-hour hands-on workshop will be a gentle introduction to the xaringan package as a tool to create impressive presentation slides that can be deployed to the web for easy sharing.\nDay 1 (Nov.¬†3, 3-5pm BST) will cover the nuts and bolts of creating presentation slides using xaringan and deploying them in HTML format for easy sharing with others.\nDay 2 (Nov.¬†5, 3-5pm BST) will cover how to take your slides to the next level with the xaringanExtra package and how to customize slides with CSS.\nThis workshop is designed for R users already familiar with R Markdown and GitHub."
  },
  {
    "objectID": "talk/2023-10-11-epis4equity/index.html",
    "href": "talk/2023-10-11-epis4equity/index.html",
    "title": "Place-based Interventions to Promote Structural Change & Equity",
    "section": "",
    "text": "Deeply Rooted\nIGNITE: A Randomized Controlled Trial of Concentrated Investment in Black Neighborhoods to Address Structural Racism as a Fundamental Cause of Poor Health\nSPARROw\nNature and Wellbeing Project"
  },
  {
    "objectID": "talk/2023-10-11-epis4equity/index.html#projects-highlighted",
    "href": "talk/2023-10-11-epis4equity/index.html#projects-highlighted",
    "title": "Place-based Interventions to Promote Structural Change & Equity",
    "section": "",
    "text": "Deeply Rooted\nIGNITE: A Randomized Controlled Trial of Concentrated Investment in Black Neighborhoods to Address Structural Racism as a Fundamental Cause of Poor Health\nSPARROw\nNature and Wellbeing Project"
  },
  {
    "objectID": "talk/2022-09-29-ccd-sips/index.html",
    "href": "talk/2022-09-29-ccd-sips/index.html",
    "title": "Creating the Philly Center City SIPS Interactive Map",
    "section": "",
    "text": "A gentle introduction to web-scraping, geocoding and map-making in an end-to-end analysis. The workshop will cover how to scrape the bar and restaurant data from the Center City SIPS website and convert the addresses to latitude and longitude, as well as how to plot the geographic data onto a map and customize the visualization with {leaflet}.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "My blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n\n  \n\n\n\n\n Back to top"
  },
  {
    "objectID": "project/2021-07-07-presentable-user2021/index.html",
    "href": "project/2021-07-07-presentable-user2021/index.html",
    "title": "Professional, Polished, Presentable",
    "section": "",
    "text": "The xaringan package brings professional, impressive, and visually appealing slides to the powerful R Markdown ecosystem. Through our hands-on tutorial, you will learn how to design highly effective slides that support presentations for teaching and reporting alike. Over three hours, you will learn how to create an accessible baseline design that matches your institution or organization‚Äôs style guide. Together we‚Äôll explore the basics of CSS‚Äîthe design language of the internet‚Äîand how we can leverage CSS to produce elegant slides for effective communication."
  },
  {
    "objectID": "project/2021-07-07-presentable-user2021/index.html#abstract",
    "href": "project/2021-07-07-presentable-user2021/index.html#abstract",
    "title": "Professional, Polished, Presentable",
    "section": "",
    "text": "The xaringan package brings professional, impressive, and visually appealing slides to the powerful R Markdown ecosystem. Through our hands-on tutorial, you will learn how to design highly effective slides that support presentations for teaching and reporting alike. Over three hours, you will learn how to create an accessible baseline design that matches your institution or organization‚Äôs style guide. Together we‚Äôll explore the basics of CSS‚Äîthe design language of the internet‚Äîand how we can leverage CSS to produce elegant slides for effective communication."
  },
  {
    "objectID": "project/2020-03-25-data-hack-opioid/index.html",
    "href": "project/2020-03-25-data-hack-opioid/index.html",
    "title": "Visualizing the Inside Journey of Recovery from Opioid Use Disorder",
    "section": "",
    "text": "Referral process pipeline (PDF)"
  },
  {
    "objectID": "project/2020-03-25-data-hack-opioid/index.html#data-hack-hosts",
    "href": "project/2020-03-25-data-hack-opioid/index.html#data-hack-hosts",
    "title": "Visualizing the Inside Journey of Recovery from Opioid Use Disorder",
    "section": "Data Hack hosts",
    "text": "Data Hack hosts\n\nCode for Philly\nDataPhilly\nR-Ladies Philly\nPhilly Data Jawn\nCity of Philadelphia"
  },
  {
    "objectID": "project/2020-03-25-data-hack-opioid/index.html#partner-organizationsinterviewees",
    "href": "project/2020-03-25-data-hack-opioid/index.html#partner-organizationsinterviewees",
    "title": "Visualizing the Inside Journey of Recovery from Opioid Use Disorder",
    "section": "Partner organizations/interviewees",
    "text": "Partner organizations/interviewees\n\nPrevention Point Prevention: drop-in, medical, mobile clinic, and re-entry case managers.\nHealth Federation of Philadelphia: Opioid Response Program Coordinator and intern.\nPenn Medicine Center for Opioid Recovery and Engagement: Certified recovery specialists, emergency medicine physician, and individual in recovery."
  },
  {
    "objectID": "project/2024-06-16-ccd-sips/index.html",
    "href": "project/2024-06-16-ccd-sips/index.html",
    "title": "Philly Center City District SIPS: An Interactive Map",
    "section": "",
    "text": "Philly‚Äôs Center City District posted a list of restaurants and bars participating in Philly‚Äôs 2024 CCD SIPS. CCD SIPS is a series of summer Wednesday evenings (5-7pm) filled with happy hour specials, between June 5th and August 28th.\nInformation from the website was scarped in order to present the information as a map. You can click or tap on the circle map markers to see information about each restaurant/bar along with a direct link to their posted happy hour specials.\nCheck out the link at the top of this post for a larger version of the interactive map below, search the table below, or take a look at CCD SIPS maps from past years."
  },
  {
    "objectID": "project/2024-06-16-ccd-sips/index.html#map-view",
    "href": "project/2024-06-16-ccd-sips/index.html#map-view",
    "title": "Philly Center City District SIPS: An Interactive Map",
    "section": "Map view",
    "text": "Map view"
  },
  {
    "objectID": "project/2024-06-16-ccd-sips/index.html#table-view",
    "href": "project/2024-06-16-ccd-sips/index.html#table-view",
    "title": "Philly Center City District SIPS: An Interactive Map",
    "section": "Table view",
    "text": "Table view"
  },
  {
    "objectID": "project/2024-06-16-ccd-sips/index.html#past-years",
    "href": "project/2024-06-16-ccd-sips/index.html#past-years",
    "title": "Philly Center City District SIPS: An Interactive Map",
    "section": "Past years",
    "text": "Past years\n\n\n\n\n\n\n\n\n\n\n\n\n2023\n\n\n\nWeb analytics\n\n1,760 unique visitors in the United States visited this post 2,330 times between June 7th and August 30th, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2019\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "project/2020-12-09-xaringan/index.html",
    "href": "project/2020-12-09-xaringan/index.html",
    "title": "nhsr CSS Theme for xaringan",
    "section": "",
    "text": "In preparation for a xaringan workshop I created for the NHS-R 2020 Conference, I designed a custom CSS theme with input from the NHS-R Community that followed the NHS identity guidelines. This theme was also contributed to the nhsrtheme package developed by Tom Jemmett."
  },
  {
    "objectID": "project/2020-12-09-xaringan/index.html#theme",
    "href": "project/2020-12-09-xaringan/index.html#theme",
    "title": "nhsr CSS Theme for xaringan",
    "section": "",
    "text": "In preparation for a xaringan workshop I created for the NHS-R 2020 Conference, I designed a custom CSS theme with input from the NHS-R Community that followed the NHS identity guidelines. This theme was also contributed to the nhsrtheme package developed by Tom Jemmett."
  },
  {
    "objectID": "project/2021-05-04-tidy-tuesday-alt-text/index.html",
    "href": "project/2021-05-04-tidy-tuesday-alt-text/index.html",
    "title": "TidyTuesdayAltText",
    "section": "",
    "text": "The original data were collected and made available by Tom Mock (@thomas_mock) using {rtweet}. These data are available in the TidyTuesday repository.\nThese tweets were processed and scraped for alternative text by Silvia Canel√≥n (@spcanelon)\n\nData were filtered to remove tweets without attached media (e.g.¬†images)\nData were supplemented with reply tweets collected using {rtweet}. This was done to identify whether the original tweet or a reply tweet contained an external link (e.g.¬†data source, repository with source code)\nAlternative (alt) text was scraped from tweet images using {RSelenium}. The first image attached to each tweet was considered the primary image and only the primary image from each tweet was scraped for alternative text. The following attributes were used to build the scraper:\n\n\nCSS selector: .css-1dbjc4n.r-1p0dtai.r-1mlwlqe.r-1d2f490.r-11wrixw\nElement attribute: aria-label\n\n\n\n\nFigure 1: Example of web inspection being used to identify the CSS selector utilized for alt-text web scraping\n\n\nThis data package does not include data that could directly identify the tweet author in order to respect any author‚Äôs decision to delete a tweet or make their account private after the data was originally collected.1\nTo obtain the tweet text, author screen name, and many other tweet attributes, you can ‚Äúrehydrate‚Äù the TweetIds (or ‚Äústatus‚Äù ids)2) using the {rtweet} package.3"
  },
  {
    "objectID": "project/2021-05-04-tidy-tuesday-alt-text/index.html#about-the-data",
    "href": "project/2021-05-04-tidy-tuesday-alt-text/index.html#about-the-data",
    "title": "TidyTuesdayAltText",
    "section": "",
    "text": "The original data were collected and made available by Tom Mock (@thomas_mock) using {rtweet}. These data are available in the TidyTuesday repository.\nThese tweets were processed and scraped for alternative text by Silvia Canel√≥n (@spcanelon)\n\nData were filtered to remove tweets without attached media (e.g.¬†images)\nData were supplemented with reply tweets collected using {rtweet}. This was done to identify whether the original tweet or a reply tweet contained an external link (e.g.¬†data source, repository with source code)\nAlternative (alt) text was scraped from tweet images using {RSelenium}. The first image attached to each tweet was considered the primary image and only the primary image from each tweet was scraped for alternative text. The following attributes were used to build the scraper:\n\n\nCSS selector: .css-1dbjc4n.r-1p0dtai.r-1mlwlqe.r-1d2f490.r-11wrixw\nElement attribute: aria-label\n\n\n\n\nFigure 1: Example of web inspection being used to identify the CSS selector utilized for alt-text web scraping\n\n\nThis data package does not include data that could directly identify the tweet author in order to respect any author‚Äôs decision to delete a tweet or make their account private after the data was originally collected.1\nTo obtain the tweet text, author screen name, and many other tweet attributes, you can ‚Äúrehydrate‚Äù the TweetIds (or ‚Äústatus‚Äù ids)2) using the {rtweet} package.3"
  },
  {
    "objectID": "project/2021-05-04-tidy-tuesday-alt-text/index.html#tidytuesday-databases-on-notion",
    "href": "project/2021-05-04-tidy-tuesday-alt-text/index.html#tidytuesday-databases-on-notion",
    "title": "TidyTuesdayAltText",
    "section": "TidyTuesday databases on Notion",
    "text": "TidyTuesday databases on Notion\nI use the data available in the TidyTuesday repository to populate some searchable TidyTuesday databases at tiny.cc/notion-dataviz with data visualizations tagged by the dataset of the week, hashtags, mentions, etc.\n\n\n\nFigure 2: Screenshot of the 2021 TidyTuesday database on Notion, taken on June 1, 2021\n\n\n\n\n\nFigure 3: Screenshot of the tweet sharing the TidyTuesday database on Notion"
  },
  {
    "objectID": "project/2021-05-04-tidy-tuesday-alt-text/index.html#footnotes",
    "href": "project/2021-05-04-tidy-tuesday-alt-text/index.html#footnotes",
    "title": "TidyTuesdayAltText",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDeveloper Policy ‚Äì Twitter Developers | Twitter Developer‚Ü©Ô∏é\nTweet object | Twitter Developer‚Ü©Ô∏é\nGet tweets data for given statuses (status IDs). ‚Äî lookup_tweets ‚Ä¢ rOpenSci: rtweet‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/2022-05-31-ccd-sips/index.html",
    "href": "blog/2022-05-31-ccd-sips/index.html",
    "title": "Creating the Philly Center City SIPS Interactive Map",
    "section": "",
    "text": "Philly‚Äôs Center City District posted a list of restaurants and bars participating in Philly‚Äôs 2022 CCD Sips. CCD Sips is a series of summer Wednesday evenings (4:30-7pm) filled with happy hour specials, between June 1st and August 31st.\nI prefer to take in this information as a map instead of a list, so I scraped some information from the website and made one! You can click or tap on the circle map markers to see information about each restaurant/bar along with a direct link to their posted happy hour specials.\nCheck out the link at the top of this post for a larger version of the interactive map below. And jump down to the tutorial if you‚Äôd like to learn how I used R to build the interactive map!"
  },
  {
    "objectID": "blog/2022-05-31-ccd-sips/index.html#tutorial-start",
    "href": "blog/2022-05-31-ccd-sips/index.html#tutorial-start",
    "title": "Creating the Philly Center City SIPS Interactive Map",
    "section": "Tutorial start",
    "text": "Tutorial start\nAside from the tidyverse and here packages, I used a handful of R packages to bring this map project together.\n\n\n\n\n\n\n\n\nPackage\nPurpose\nVersion\n\n\n\n\nrobotstxt\nCheck website for scraping permissions\n0.7.13\n\n\nrvest\nScrape the information off of the website\n1.0.1\n\n\nggmap\nGeocode the restaurant addresses\n3.0.0\n\n\nleaflet\nBuild the interactive map\n2.0.4.1\n\n\nleaflet.extras\nAdd extra functionality to map\n1.0.0"
  },
  {
    "objectID": "blog/2022-05-31-ccd-sips/index.html#scraping-the-data",
    "href": "blog/2022-05-31-ccd-sips/index.html#scraping-the-data",
    "title": "Creating the Philly Center City SIPS Interactive Map",
    "section": "Scraping the data",
    "text": "Scraping the data\n\nChecking site permissions\nCheck the site‚Äôs terms of service using the robotstxt package, which downloads and parses the site‚Äôs robots.txt file.\nWhat I wanted to look for was whether any pages are not allowed to be crawled by bots/scrapers. In my case there weren‚Äôt any, indicated by Allow: /.\nget_robotstxt(\"https://centercityphila.org/explore-center-city/ccd-sips/sips-list-view\")\n\n\nOutput\n\n[robots.txt]\n--------------------------------------\n\n# robots.txt overwrite by: on_suspect_content\n\nUser-agent: *\nAllow: /\n\n\n\n[events]\n--------------------------------------\n\nrequested:   https://centercityphila.org/explore-center-city/ccd-sips/sips-list-view/robots.txt \ndownloaded:  https://centercityphila.org/explore-center-city/ccd-sips/sips-list-view/robots.txt \n\n$on_not_found\n$on_not_found$status_code\n[1] 404\n\n\n$on_file_type_mismatch\n$on_file_type_mismatch$content_type\n[1] \"text/html; charset=utf-8\"\n\n\n$on_suspect_content\n$on_suspect_content$parsable\n[1] FALSE\n\n$on_suspect_content$content_suspect\n[1] TRUE\n\n\n[attributes]\n--------------------------------------\n\nproblems, cached, request, class\n\n\n\nHarvesting data from the first page\nThen I used the rvest package to scrape the information from the tables of restaurants/bars participating in CCD Sips.\nI‚Äôve learned that ideally you would only scrape each page once, so I checked my approach with the first page before I wrote a function to scrape the remaining pages.\n# define the page\nurl &lt;- \"https://centercityphila.org/explore-center-city/ccd-sips/sips-list-view?page=1\"\n\n# read the page html\nhtml1 &lt;- read_html(url)\n\n# extract table info\ntable1 &lt;- \n  html1 |&gt; \n  html_node(\"table\") |&gt; \n  html_table()\ntable1 |&gt; head(3) |&gt; kableExtra::kable()\n\n\n\n\nName\n\n\nAddress\n\n\nPhone\n\n\nCCD SIPS Specials\n\n\n\n\n\n\n1225 Raw Sushi and Sake Lounge\n\n\n1225 Sansom St, Philadelphia, PA 19102\n\n\n215.238.1903\n\n\nCCD SIPS Specials\n\n\n\n\n1518 Bar and Grill\n\n\n1518 Sansom St, Philadelphia, PA 19102\n\n\n267.639.6851\n\n\nCCD SIPS Specials\n\n\n\n\nAir Grille Garden at Dilworth Park\n\n\n1 S 15th St, Philadelphia, PA 19102\n\n\n215.587.2761\n\n\nCCD SIPS Specials\n\n\n\n\n# extract hyperlinks to specific restaurant/bar specials\nlinks &lt;- \n  html1 |&gt; \n  html_elements(\".o-table__tag.ccd-text-link\") |&gt; \n  html_attr(\"href\") |&gt; \n  as_tibble()\nlinks |&gt; head(3) |&gt; kableExtra::kable()\n\n\n\n\nvalue\n\n\n\n\n\n\n#1225-raw-sushi-and-sake-lounge\n\n\n\n\n#1518-bar-and-grill\n\n\n\n\n#air-grill-garden-dilworth-park\n\n\n\n\n# add full hyperlinks to the table info\ntable1Mod &lt;-\n  bind_cols(table1, links) |&gt; \n  mutate(Specials = paste0(url, value)) |&gt; \n  select(-c(`CCD SIPS Specials`, value))\ntable1Mod |&gt; head(3) |&gt; kableExtra::kable()\n\n\n\n\nName\n\n\nAddress\n\n\nPhone\n\n\nSpecials\n\n\n\n\n\n\n1225 Raw Sushi and Sake Lounge\n\n\n1225 Sansom St, Philadelphia, PA 19102\n\n\n215.238.1903\n\n\nhttps://centercityphila.org/explore-center-city/ccd-sips/sips-list-view?page=1#1225-raw-sushi-and-sake-lounge\n\n\n\n\n1518 Bar and Grill\n\n\n1518 Sansom St, Philadelphia, PA 19102\n\n\n267.639.6851\n\n\nhttps://centercityphila.org/explore-center-city/ccd-sips/sips-list-view?page=1#1518-bar-and-grill\n\n\n\n\nAir Grille Garden at Dilworth Park\n\n\n1 S 15th St, Philadelphia, PA 19102\n\n\n215.587.2761\n\n\nhttps://centercityphila.org/explore-center-city/ccd-sips/sips-list-view?page=1#air-grill-garden-dilworth-park\n\n\n\n\n\n\nHarvesting data from the remaining pages\nOnce I could confirm that the above approach harvested the information I needed, I adapted the code into a function that I could apply to pages 2-3 of the site.\ngetTables &lt;- function(pageNumber) {\n  Sys.sleep(2)\n  \n  url &lt;- paste0(\"https://centercityphila.org/explore-center-city/ccd-sips/sips-list-view?page=\", pageNumber)\n  \n  html &lt;- read_html(url)\n  \n  table &lt;- \n    html |&gt; \n    html_node(\"table\") |&gt;\n    html_table()\n  \n  links &lt;- \n    html |&gt; \n    html_elements(\".o-table__tag.ccd-text-link\") |&gt; \n    html_attr(\"href\") |&gt; \n    as_tibble()\n  \n  tableSpecials &lt;&lt;-\n    bind_cols(table, links) |&gt; \n    mutate(Specials = paste0(url, value)) |&gt; \n    select(-c(`CCD SIPS Specials`, value))\n}\nI used my getTable() function and the purrr::map_df() function to harvest the table of restaurants/bars from pages 2 and 3. Then I combined all the data frames together and saved the complete data frame as an .Rds object so that I wouldn‚Äôt have to scrape the data again.\n# get remaining tables\ntable2 &lt;- map_df(2:3, getTables) \n\n# combine all tables\ntable &lt;- bind_rows(table1Mod, table2)\ntable |&gt; head(3) |&gt; kableExtra::kable()\n\n\n\n\nName\n\n\nAddress\n\n\nPhone\n\n\nSpecials\n\n\n\n\n\n\n1028 Yamitsuki Sushi & Ramen\n\n\n1028 Arch Street, Philadelphia, PA 19107\n\n\n215.629.3888\n\n\nhttps://centercityphila.org/explore-center-city/ccd-sips/sips-list-view?page=1#1028-yamitsuki-sushi-ramen\n\n\n\n\n1225 Raw Sushi and Sake Lounge\n\n\n1225 Sansom St, Philadelphia, PA 19102\n\n\n215.238.1903\n\n\nhttps://centercityphila.org/explore-center-city/ccd-sips/sips-list-view?page=1#1225-raw-sushi-and-sake-lounge\n\n\n\n\n1518 Bar and Grill\n\n\n1518 Sansom St, Philadelphia, PA 19102\n\n\n267.639.6851\n\n\nhttps://centercityphila.org/explore-center-city/ccd-sips/sips-list-view?page=1#1518-bar-and-grill\n\n\n\n\n# save full table to file\nwrite_rds(\n  table,\n  file = here(\"content/blog/2022-05-31-ccd-sips/specialsScraped.Rds\")\n  )"
  },
  {
    "objectID": "blog/2022-05-31-ccd-sips/index.html#geocoding-addresses",
    "href": "blog/2022-05-31-ccd-sips/index.html#geocoding-addresses",
    "title": "Creating the Philly Center City SIPS Interactive Map",
    "section": "Geocoding addresses",
    "text": "Geocoding addresses\nThe next step was to use geocoding to convert the restaurant/bar addresses to geographical coordinates (longitude and latitude) that I could map. I used the ggmap package and the Google Geocoding API service because this was a small project (59 addresses/requests) which wouldn‚Äôt make a dent in the free credit available on the platform.\nThe last time I geocoded addresses was for an almost identical project in 2019 and I had issues using the same API key from back then, so I made a new one. I restricted my new key to the Geocoding and Geolocation APIs.\n# register my API key\n# ggmap::register_google(key = \"[your key]\")\n\n# geocode addresses\nspecials_ggmap &lt;- \n  table |&gt; \n  mutate_geocode(Address)\n\n# rename new variables\nspecials &lt;- \n  specials_ggmap |&gt; \n  rename(Longitude = lon,\n         Latitude = lat) \nspecials |&gt; head(3) |&gt; kableExtra::kable()\n\n\n\n\nName\n\n\nAddress\n\n\nPhone\n\n\nSpecials\n\n\nLongitude\n\n\nLatitude\n\n\n\n\n\n\n1028 Yamitsuki Sushi & Ramen\n\n\n1028 Arch Street, Philadelphia, PA 19107\n\n\n215.629.3888\n\n\nhttps://centercityphila.org/explore-center-city/ccd-sips/sips-list-view?page=1#1028-yamitsuki-sushi-ramen\n\n\n-75.15746\n\n\n39.95354\n\n\n\n\n1225 Raw Sushi and Sake Lounge\n\n\n1225 Sansom St, Philadelphia, PA 19102\n\n\n215.238.1903\n\n\nhttps://centercityphila.org/explore-center-city/ccd-sips/sips-list-view?page=1#1225-raw-sushi-and-sake-lounge\n\n\n-75.16149\n\n\n39.95004\n\n\n\n\n1518 Bar and Grill\n\n\n1518 Sansom St, Philadelphia, PA 19102\n\n\n267.639.6851\n\n\nhttps://centercityphila.org/explore-center-city/ccd-sips/sips-list-view?page=1#1518-bar-and-grill\n\n\n-75.16665\n\n\n39.95020\n\n\n\n\nI made sure to save the new data frame with geographical coordinates as an .Rds object so I wouldn‚Äôt have to geocode the data again! This would be particularly important if I was working on a large project.\n# save table with geocoded addresses to file\nwrite_rds(\n  specials,\n  file = here(\"content/blog/2022-05-31-ccd-sips/specialsGeocoded.Rds\"))"
  },
  {
    "objectID": "blog/2022-05-31-ccd-sips/index.html#building-the-map",
    "href": "blog/2022-05-31-ccd-sips/index.html#building-the-map",
    "title": "Creating the Philly Center City SIPS Interactive Map",
    "section": "Building the map",
    "text": "Building the map\nTo build the map, I used the leaflet package. Some of the resources I found helpful, in addition to the package documentation:\n\nScrape website data with the new R package rvest (+ a postscript on interacting with web pages with RSelenium) ¬∑ Hollie at ZevRoss ‚Äì how to style pop-ups\nLeaflet Map Markers in R ¬∑ Jindra Lacko ‚Äì how to customize marker icons\nA guide to basic Leaflet accessibility ¬∑ Leaflet ‚Äì accessibility considerations. Though it‚Äôs unclear to me how these features built into the Leaflet library translate over to the leaflet R package. For example, I couldn‚Äôt find an option for adding alt-text or a title to each marker, but maybe I wasn‚Äôt looking in the right place within the documentation.\n\n\nCustomizing map markers\n# style pop-ups for the map with inline css styling\n\n# marker for the restaurants/bars\npopInfoCircles &lt;- paste(\"&lt;h2 style='font-family: Red Hat Text, sans-serif; font-size: 1.6em; color:#43464C;'&gt;\", \"&lt;a style='color: #00857A;' href=\", specials$Specials, \"&gt;\", specials$Name, \"&lt;/a&gt;&lt;/h2&gt;\",\"&lt;p style='font-family: Red Hat Text, sans-serif; font-weight: normal; font-size: 1.5em; color:#9197A6;'&gt;\", specials$Address, \"&lt;/p&gt;\")\n\n# marker for the center of the map\npopInfoMarker&lt;-paste(\"&lt;h1 style='padding-top: 0.5em; margin-top: 1em; margin-bottom: 0.5em; font-family: Red Hat Text, sans-serif; font-size: 1.8em; color:#43464C;'&gt;\", \"&lt;a style='color: #00857A;' href='https://centercityphila.org/explore-center-city/ccdsips'&gt;\", \"Center City District Sips 2022\", \"&lt;/a&gt;&lt;/h1&gt;&lt;p style='color:#9197A6; font-family: Red Hat Text, sans-serif; font-size: 1.5em; padding-bottom: 1em;'&gt;\", \"Philadelphia, PA\", \"&lt;/p&gt;\")\n\n# custom icon for the center of the map\nawesome &lt;-\n  makeAwesomeIcon(\n    icon = \"map-pin\",\n    iconColor = \"#FFFFFF\",\n    markerColor = \"darkblue\",\n    library = \"fa\"\n  )\n\n\nPlotting the restaurants/bars\nleaflet(data = specials, \n        width = \"100%\", \n        height = \"850px\",\n        # https://stackoverflow.com/a/42170340\n        options = tileOptions(minZoom = 15,\n                              maxZoom = 19)) |&gt;\n  # add map markers ----\n  addCircles(\n    lat = ~ specials$Latitude, \n    lng = ~ specials$Longitude, \n    fillColor = \"#009E91\", #olivedrab goldenrod\n    fillOpacity = 0.6, \n    stroke = F,\n    radius = 12, \n    popup = popInfoCircles,\n    label = ~ Name,\n    labelOptions = labelOptions(\n      style = list(\n        \"font-family\" = \"Red Hat Text, sans-serif\",\n        \"font-size\" = \"1.2em\")\n      ))\n\n\n\n\n\n\nAdding the map background\nleaflet(data = specials, \n        width = \"100%\", \n        height = \"850px\",\n        # https://stackoverflow.com/a/42170340\n        options = tileOptions(minZoom = 15,\n                              maxZoom = 19)) |&gt;\n  # add map markers ----\n  addCircles(\n    lat = ~ specials$Latitude, \n    lng = ~ specials$Longitude, \n    fillColor = \"#009E91\", #olivedrab goldenrod\n    fillOpacity = 0.6, \n    stroke = F,\n    radius = 12, \n    popup = popInfoCircles,\n    label = ~ Name,\n    labelOptions = labelOptions(\n      style = list(\n        \"font-family\" = \"Red Hat Text, sans-serif\",\n        \"font-size\" = \"1.2em\")\n      )) |&gt;\n  # add map tiles in the background ----\n  addProviderTiles(providers$CartoDB.Positron)\n\n\n\n\n\n\nSetting the map view\nleaflet(data = specials, \n        width = \"100%\", \n        height = \"850px\",\n        # https://stackoverflow.com/a/42170340\n        options = tileOptions(minZoom = 15,\n                              maxZoom = 19)) |&gt;\n  # add map markers ----\n  addCircles(\n    lat = ~ specials$Latitude, \n    lng = ~ specials$Longitude, \n    fillColor = \"#009E91\", #olivedrab goldenrod\n    fillOpacity = 0.6, \n    stroke = F,\n    radius = 12, \n    popup = popInfoCircles,\n    label = ~ Name,\n    labelOptions = labelOptions(\n      style = list(\n        \"font-family\" = \"Red Hat Text, sans-serif\",\n        \"font-size\" = \"1.2em\")\n      )) |&gt;\n  # add map tiles in the background ----\n  addProviderTiles(providers$CartoDB.Positron) |&gt;\n  # set the map view\n  setView(mean(specials$Longitude), \n          mean(specials$Latitude), \n          zoom = 16)\n\n\n\n\n\n\nAdding a marker at the center\nleaflet(data = specials, \n        width = \"100%\", \n        height = \"850px\",\n        # https://stackoverflow.com/a/42170340\n        options = tileOptions(minZoom = 15,\n                              maxZoom = 19)) |&gt;\n  # add map markers ----\n  addCircles(\n    lat = ~ specials$Latitude, \n    lng = ~ specials$Longitude, \n    fillColor = \"#009E91\", #olivedrab goldenrod\n    fillOpacity = 0.6,\n    stroke = F,\n    radius = 12, \n    popup = popInfoCircles,\n    label = ~ Name,\n    labelOptions = labelOptions(\n      style = list(\n        \"font-family\" = \"Red Hat Text, sans-serif\",\n        \"font-size\" = \"1.2em\")\n      )) |&gt;\n  # add map tiles in the background ----\n  addProviderTiles(providers$CartoDB.Positron) |&gt;\n  # set the map view\n  setView(mean(specials$Longitude), \n          mean(specials$Latitude), \n          zoom = 16) |&gt;\n  # add marker at the center ----\n  addAwesomeMarkers(\n    icon = awesome,\n    lng = mean(specials$Longitude), \n    lat = mean(specials$Latitude), \n    label = \"Center City District Sips 2022\",\n    labelOptions = labelOptions(\n      style = list(\n        \"font-family\" = \"Red Hat Text, sans-serif\",\n        \"font-size\" = \"1.2em\")\n      ),\n    popup = popInfoMarker,\n    popupOptions = popupOptions(maxWidth = 250))\n\n\n\n\n\n\nAdding fullscreen control\nleaflet(data = specials, \n        width = \"100%\", \n        height = \"850px\",\n        # https://stackoverflow.com/a/42170340\n        options = tileOptions(minZoom = 15,\n                              maxZoom = 19)) |&gt;\n  # add map markers ----\n  addCircles(\n    lat = ~ specials$Latitude, \n    lng = ~ specials$Longitude, \n    fillColor = \"#009E91\", #olivedrab goldenrod\n    fillOpacity = 0.6, \n    stroke = F,\n    radius = 12, \n    popup = popInfoCircles,\n    label = ~ Name,\n    labelOptions = labelOptions(\n      style = list(\n        \"font-family\" = \"Red Hat Text, sans-serif\",\n        \"font-size\" = \"1.2em\")\n      )) |&gt;\n  # add map tiles in the background ----\n  addProviderTiles(providers$CartoDB.Positron) |&gt;\n  # set the map view\n  setView(mean(specials$Longitude), \n          mean(specials$Latitude), \n          zoom = 16) |&gt;\n  # add marker at the center ----\n  addAwesomeMarkers(\n    icon = awesome,\n    lng = mean(specials$Longitude), \n    lat = mean(specials$Latitude), \n    label = \"Center City District Sips 2022\",\n    labelOptions = labelOptions(\n      style = list(\n        \"font-family\" = \"Red Hat Text, sans-serif\",\n        \"font-size\" = \"1.2em\")\n      ),\n    popup = popInfoMarker,\n    popupOptions = popupOptions(maxWidth = 250)) |&gt; \n  # add fullscreen control button ----\n  leaflet.extras::addFullscreenControl()"
  },
  {
    "objectID": "blog/2022-05-31-ccd-sips/index.html#creating-the-map-with-quarto",
    "href": "blog/2022-05-31-ccd-sips/index.html#creating-the-map-with-quarto",
    "title": "Creating the Philly Center City SIPS Interactive Map",
    "section": "Creating the map with Quarto",
    "text": "Creating the map with Quarto\nThe first time around, I created a standalone map by first running an R script with the necessary code, and then exporting the HTML output as a webpage. This worked well enough, except that I realized:\n\nThe title of the map webpage (the name that is displayed on a browser tab) was just ‚Äúmap‚Äù because the name of the HTML file was map.html. I wanted something more descriptive.\nThe map wasn‚Äôt mobile-responsive. In other words, the map markers and text looked too small when viewed on a mobile device.\n\n\nChanging the webpage title\nThe webpage title was a quick one to fix thanks to a Stack Overflow response to a question about turning off the title in an R Markdown document. The pagetitle YAML option lets you set the HTML‚Äôs title tag independently of the document title:\npagetitle: \"Philly CCD Sips 2022 Map\"\n\n\nFixing the mobile-responsiveness\nThe mobile-responsiveness issue could be solved by adding metadata to the map HTML, but I would need to be able to blend HTML with R code. I have been practicing using Quarto and figured I could make a standalone map from a Quarto document (.qmd) rather than an R Markdown one (.Rmd or .Rmarkdown). You can find the map‚Äôs Quarto document alongside this blog post.\nAccording to the Leaflet library documentation and this Stack Overflow answer, fixing the map to be mobile-responsive required adding the following metadata to the HTML code:\n&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no\" /&gt;\nI used the metathis R package to add this metadata to an R code chunk in my Quarto document using the meta_viewport() function:\n# make mobile-responsive\nmeta_viewport(\n  width = \"device-width\",\n  initial_scale = \"1.0\",\n  maximum_scale = \"1.0\",\n  user_scalable = \"no\"\n  )\n\nUpdate: In the process of updating this post I‚Äôm noticing that specifying the viewport metadata tag doesn‚Äôt seem to be necessary anymore, and I don‚Äôt understand why ü§î ‚Ä¶so I‚Äôll leave the step as is, just in case it‚Äôs helpful to anyone ü§∑üèΩ‚Äç‚ôÄÔ∏è\n\n\n\nAdding social media tags\nThen I added more metadata. I was particularly interested in adding social media tags so that if I (or anyone else) shared this map webpage, an informative preview would display as a social card.\nI used the meta_social() function to add these tags:\n# tags for social media\nmeta_social(\n  title = \"Philly CCD Sips 2022 Interactive Map\",\n  url = \"https://www.silviacanelon.com/blog/2022-ccd-sips/map.html\",\n  image = \"https://github.com/spcanelon/silvia/blob/main/content/blog/2022-05-31-ccd-sips/featured.png?raw=true\",\n  image_alt = \"Map of Philly's Center City with a pop-up saying Center City District Sips 2022\",\n  og_type = \"website\",\n  og_author = \"Silvia Canel√≥n\",\n  twitter_card_type = \"summary_large_image\",\n  twitter_creator = \"@spcanelon\"\n)\nGreat, I had added all of the metadata I was interested in! Except that because I was using Quarto, and not one of the more common outputs I had a couple of extra steps to take:\n\nWrite my metadata tags to an HTML file, using the write_meta() function:\n# write meta tags to file\nwrite_meta(path = \"meta-map.html\")\nManually include this HTML in my webpage via the Quarto file. The include-in-header Quarto YAML option helped me here:\ninclude-in-header: meta-map.html\n\n\n\nMaking the map fullscreen\nA side effect of creating the map from a Quarto (or R Markdown) document is that the output is styled by default to fit within the width of an article (in this case 900 pixels). I wanted the map to take up the whole width of the page, so I made use of the page-layout Quarto YAML option:\nformat: \n  html:\n    page-layout: custom\nAnother option that worked pretty well was to use the column: screen code chunk option built into Quarto. The Quarto documentation even shows an example to display a Leaflet map I but it left a thin margin at the top margin, and I wanted the map to be flush against the top edge of the webpage.\n\n\nRendering the standalone map\nLastly, I added one more option to the YAML that would render the Quarto document into a self-contained HTML with all of the content needed to create the map.\nformat:\n  html:\n    page-layout: custom\n    self-contained: true"
  },
  {
    "objectID": "blog/2022-01-18-hello-umami/index.html",
    "href": "blog/2022-01-18-hello-umami/index.html",
    "title": "Hello Umami: Deploying a Privacy-Friendly Open Source Tool for Web Analytics",
    "section": "",
    "text": "A brief walkthrough of the steps I took to deploy Umami web analytics for my personal website, as documented in a short Twitter thread.\n\n07:50pmMonths ago I removed GA from my #RStats #blogdown site & this weekend I added http://umami.is üçö (@caozilla) as an open source, privacy-friendly, web analytics alternative\nI was intimidated by the self-hosting aspect, but the docs + @Railway made it possible! Steps in üßµ"
  },
  {
    "objectID": "blog/2022-01-18-hello-umami/index.html#what-to-expect",
    "href": "blog/2022-01-18-hello-umami/index.html#what-to-expect",
    "title": "Hello Umami: Deploying a Privacy-Friendly Open Source Tool for Web Analytics",
    "section": "",
    "text": "A brief walkthrough of the steps I took to deploy Umami web analytics for my personal website, as documented in a short Twitter thread.\n\n07:50pmMonths ago I removed GA from my #RStats #blogdown site & this weekend I added http://umami.is üçö (@caozilla) as an open source, privacy-friendly, web analytics alternative\nI was intimidated by the self-hosting aspect, but the docs + @Railway made it possible! Steps in üßµ"
  },
  {
    "objectID": "blog/2022-01-18-hello-umami/index.html#installation",
    "href": "blog/2022-01-18-hello-umami/index.html#installation",
    "title": "Hello Umami: Deploying a Privacy-Friendly Open Source Tool for Web Analytics",
    "section": "Installation",
    "text": "Installation\n07:50pmSteps I followed:\n\nInstall Railway CLI with Homebrew https://docs.railway.app/develop/cli\nInstall PostgreSQL with Homebrew https://wiki.postgresql.org/wiki/Homebrew\nFork Umami repo & follow steps in ‚ÄúRunning on Railway from a forked repository‚Äù at https://umami.is/docs/running-on-railway\nClone repo locally w git"
  },
  {
    "objectID": "blog/2022-01-18-hello-umami/index.html#railway",
    "href": "blog/2022-01-18-hello-umami/index.html#railway",
    "title": "Hello Umami: Deploying a Privacy-Friendly Open Source Tool for Web Analytics",
    "section": "Railway",
    "text": "Railway\n07:50pm5. Link local setup to Railway project in the terminal w/ railway link &lt;projectid&gt;. Project ID is in the Railway dashboard under Setup\n\nCreate PostgreSQL tables using railway run in local umami directory + steps in ‚ÄúCreate database tables‚Äù at https://umami.is/docs/running-on-railway\n\n07:50pm7. Deploy with railway up! üöÑ\n\nFollow steps in Umami Getting Started docs https://umami.is/docs/login to login & add website\nAdd tracking code to website. In my #HugoApero #blogdown site I added it to layouts/partials/head.html. My example at https://github.com/spcanelon/silvia/blob/7d407b5967ae5d1bfe9df97e9a395fd02adeb985/layouts/partials/head.html#L21-L29"
  },
  {
    "objectID": "blog/2022-01-18-hello-umami/index.html#tracker-configuration",
    "href": "blog/2022-01-18-hello-umami/index.html#tracker-configuration",
    "title": "Hello Umami: Deploying a Privacy-Friendly Open Source Tool for Web Analytics",
    "section": "Tracker Configuration",
    "text": "Tracker Configuration\n07:50pm10. In order to not track my own visits to my site, I followed the tip in @DeepankarBhade‚Äôs post https://dpnkr.in/blog/self-host-umami and disabled Umami from my browser‚Äôs local storage. He kindly explained the steps to me in this thread üòÖ https://twitter.com/DeepankarBhade/status/1480214508987551750?s=20"
  },
  {
    "objectID": "blog/2022-01-18-hello-umami/index.html#pricing",
    "href": "blog/2022-01-18-hello-umami/index.html#pricing",
    "title": "Hello Umami: Deploying a Privacy-Friendly Open Source Tool for Web Analytics",
    "section": "Pricing",
    "text": "Pricing\n07:50pmA note about Railway pricing https://docs.railway.app/reference/limits:\nI‚Äôm using the free tier, the Starter Plan, which has $5 of credits. In the past 2 days I‚Äôve used $0.7258 of my credits & it‚Äôs estimated I‚Äôll use $3.04 by the end of the month. My site receives relatively low traffic, so YMMV\n07:51pmThere is a free-ish $10 credit Railway plan available also, where you would only get billed for any usage above $10\nFor a fully free & more adventurous experience you could give up the convenience of Railway & self-host! See the Umami docs for options https://umami.is/docs/hosting"
  },
  {
    "objectID": "blog/2022-01-18-hello-umami/index.html#goatcounter",
    "href": "blog/2022-01-18-hello-umami/index.html#goatcounter",
    "title": "Hello Umami: Deploying a Privacy-Friendly Open Source Tool for Web Analytics",
    "section": "GoatCounter",
    "text": "GoatCounter\n07:51pmI‚Äôll leave you with another great free, open source, privacy-friendly option, which is GoatCounter üêê https://www.goatcounter.com/. And @mattdray wrote a blogdown post about it! https://twitter.com/mattdray/status/1306353556706992128?s=20\nFor more convos about GA web analytics alternatives, see https://twitter.com/ma_salmon/status/1379363183526285312?s=20"
  },
  {
    "objectID": "blog/2022-01-18-hello-umami/index.html#updating-umami",
    "href": "blog/2022-01-18-hello-umami/index.html#updating-umami",
    "title": "Hello Umami: Deploying a Privacy-Friendly Open Source Tool for Web Analytics",
    "section": "Updating Umami",
    "text": "Updating Umami\n01:52pmNote to self ‚Äì how to update http://umami.is with new releases:\nRecent update to v1.25.0 https://github.com/mikecao/umami/releases/tag/v1.25.0\n\nFetch upstream from my umami fork\nLocally in terminal, change to my umami directory\ngit pull, npm install, railway up üöÑ\n\nüöÄ #WebAnalytics"
  },
  {
    "objectID": "blog/2021-03-16-deploying-xaringan-slides/index.html",
    "href": "blog/2021-03-16-deploying-xaringan-slides/index.html",
    "title": "Deploying xaringan Slides with GitHub Pages",
    "section": "",
    "text": "This post was featured in the RStudio Blog R Views under a revised title: Deploying xaringan Slides with GitHub Pages. The original title was ‚ÄúDeploying xaringan Slides: A Ten-Step GitHub Pages Workflow.‚Äù Other changes include an introductory paragraph and greater clarity in the ‚ÄúChoose your own adventure‚Äù section. Many thanks to Chief Editor Joe Rickert for a very encouraging and helpful editorial process! I am humbled by his note on R Views:\nSilvia‚Äôs post is a mini masterpiece of clear, concise writing that elucidates complex technology within the narrow context of explaining a single well-defined task. Silvia does not attempt to say everything she knows about the subject, and she resists digressions that might obscure the path she is laying out. It is an example of achieving clarity through saying less.\nThis post will guide you step-by-step through the process of creating an HTML xaringan slide deck and deploying it to the web for easy sharing with others. We will be using the xaringan package to build the slide deck, GitHub to help us host our slides for free with GitHub Pages, and the usethis package to help us out along the way. You will get the most out of this workflow if you are already familiar with R Markdown and GitHub, and if you have already connected RStudio (or your preferred IDE) to Git and GitHub.1 The post will not cover the nuts and bolts of xaringan or talk about slide design & customization, but you can find lots of learning resources listed at the end."
  },
  {
    "objectID": "blog/2021-03-16-deploying-xaringan-slides/index.html#packages",
    "href": "blog/2021-03-16-deploying-xaringan-slides/index.html#packages",
    "title": "Deploying xaringan Slides with GitHub Pages",
    "section": "Packages",
    "text": "Packages\nThis workflow was developed using:\n\n\n\nSoftware / package\nVersion\n\n\n\n\nR\n4.0.3\n\n\nRStudio\n1.4.1103\n\n\nxaringan\n0.19\n\n\nusethis\n2.0.0\n\n\n\ninstall.packages(\"xaringan\")\ninstall.packages(\"usethis\")"
  },
  {
    "objectID": "blog/2021-03-16-deploying-xaringan-slides/index.html#creating-your-xaringan-slide-deck",
    "href": "blog/2021-03-16-deploying-xaringan-slides/index.html#creating-your-xaringan-slide-deck",
    "title": "Deploying xaringan Slides with GitHub Pages",
    "section": "Creating your xaringan slide deck",
    "text": "Creating your xaringan slide deck\n1. Create a new RStudio project for your presentation:\nusethis::create_project(\"filepath/for/your/presentation/repo-name\")\n\nüìç If you‚Äôre not sure where you are on your computer, check your working directory with getwd() and use it as a filepath reference point\n\n\n2. Create a xaringan deck using a xaringan template: File &gt; New File &gt; R Markdown &gt; From Template &gt; Ninja Presentation &gt; OK\n3. Delete what you don‚Äôt need and save your R Markdown file with whatever name you like. If you pick index.Rmd the live link you share at the end will be relatively short.\n4. Render HTML slides from the open Rmd file using xaringan‚Äôs infinite moon reader:\nxaringan::infinite_moon_reader()"
  },
  {
    "objectID": "blog/2021-03-16-deploying-xaringan-slides/index.html#initialize-version-control-with-git",
    "href": "blog/2021-03-16-deploying-xaringan-slides/index.html#initialize-version-control-with-git",
    "title": "Deploying xaringan Slides with GitHub Pages",
    "section": "Initialize version control with git",
    "text": "Initialize version control with git\n5. Initialize version control of your slides with git:\nusethis::use_git()\nYou‚Äôll be asked if you want to commit the files in your project (with the message ‚ÄúInitial commit‚Äù) and then if you want to restart to activate the Git pane. Say yes to both ‚úÖ\n\nNote: At the moment usethis names the primary branch ‚Äúmaster‚Äù by default. Issue #1341 suggests the option to instead name it ‚Äúmain‚Äù is in the works.\n\n\n6. Connect your local project with a GitHub repo:\nusethis::use_github()\n\nYou could use the function argument private = TRUE to create a private GitHub repository. But you may have to remember to change the visibility before deploying to GitHub Pages.\n\n\n7. Your new GitHub repo with all of your xaringan project files will automatically open up in your browser\n\nRepo for the R-Ladies xaringan template: https://github.com/spcanelon/RLadies-xaringan-template"
  },
  {
    "objectID": "blog/2021-03-16-deploying-xaringan-slides/index.html#making-and-committing-changes-to-your-slides",
    "href": "blog/2021-03-16-deploying-xaringan-slides/index.html#making-and-committing-changes-to-your-slides",
    "title": "Deploying xaringan Slides with GitHub Pages",
    "section": "Making and committing changes to your slides",
    "text": "Making and committing changes to your slides\n8. Edit your slides as you wish. Commit often! And then push to GitHub. Use the tools provided by the Git pane in RStudio, or use the following commands in the Terminal:\n# Step 1: Stage all modified files\ngit add .\n# Step 2: Describe the changes you made to your files\ngit commit -m \"&lt;A brief but descriptive commit message&gt;\"\n\nConsider writing a commit message that finishes the following sentence:2 ‚ÄúIf applied, this commit will‚Ä¶‚Äù (e.g.¬†‚ÄúChange the slide theme,‚Äù ‚ÄúAdd hello slide‚Äù)\n\n# Step 3: Push the changes to your GitHub repository\ngit push"
  },
  {
    "objectID": "blog/2021-03-16-deploying-xaringan-slides/index.html#deploying-your-slides",
    "href": "blog/2021-03-16-deploying-xaringan-slides/index.html#deploying-your-slides",
    "title": "Deploying xaringan Slides with GitHub Pages",
    "section": "Deploying your slides",
    "text": "Deploying your slides\n9. When you‚Äôre ready to deploy your slides, you can use the usethis::use_github_pages() function which makes the process of deploying via GitHub Pages super easy. I recommend pointing branch to the name of your primary branch.\nusethis::use_github_pages(branch = \"master\")\n\nNote: Your repository must be public for your deployed slides to be available publicly, unless you have a paid GitHub account.\n\n\nAlso, you only need to follow this step once to deploy your slides to the web. As long as you remember to push to your repo any changes that you make to your slides (Rmd and HTML), GitHub Pages will know how to render them.\n\n\n10. Visit the link provided to see your newly deployed slides! üöÄDon‚Äôt panic if you don‚Äôt see them right away, sometimes it takes a little time. This is the link you will share with the world when you present. Notice it looks very similar to your GitHub repo link.\n\nLink to the R-Ladies xaringan template rendered slides: https://spcanelon.github.io/RLadies-xaringan-template"
  },
  {
    "objectID": "blog/2021-03-16-deploying-xaringan-slides/index.html#foundation",
    "href": "blog/2021-03-16-deploying-xaringan-slides/index.html#foundation",
    "title": "Deploying xaringan Slides with GitHub Pages",
    "section": "Foundation",
    "text": "Foundation\n\nSharing Your Work with xaringan ‚Ä¢ Silvia Canel√≥n ‚Äì workshop site\nIntroducci√≥n al Paquete xaringan ‚Ä¢ Silvia Canel√≥n ‚Äì R-Ladies Meetup\nMaking Slides with R Markdown ‚Ä¢ Alison Hill ‚Äì workshop slides\nPresentation Ninja ‚Ä¢ xaringan Official Document ‚Äì package documentation\nChapter 7 xaringan Presentations ‚Ä¢ R Markdown: The Definitive Guide ‚Äì book chapter"
  },
  {
    "objectID": "blog/2021-03-16-deploying-xaringan-slides/index.html#sharing-your-slides",
    "href": "blog/2021-03-16-deploying-xaringan-slides/index.html#sharing-your-slides",
    "title": "Deploying xaringan Slides with GitHub Pages",
    "section": "Sharing your slides",
    "text": "Sharing your slides\n\nSharing Your xaringan Slides ‚Ä¢ Garrick Aden‚ÄëBuie ‚Äì blog post\nFunctions For Building Xaringan Slides To Different Outputs ‚Ä¢ xaringanBuilder ‚Äì package site\nSharing on Short Notice ‚Ä¢ Alison Hill & Desir√©e De Leon ‚Äì video resource for deploying via Netlify"
  },
  {
    "objectID": "blog/2021-03-16-deploying-xaringan-slides/index.html#making-your-slides-extra-special",
    "href": "blog/2021-03-16-deploying-xaringan-slides/index.html#making-your-slides-extra-special",
    "title": "Deploying xaringan Slides with GitHub Pages",
    "section": "Making your slides extra special",
    "text": "Making your slides extra special\n\nProfessional, Polished, Presentable ‚Ä¢ Garrick Aden‚ÄëBuie & Silvia Canel√≥n ‚Ä¢ useR!2021 ‚Äì site for an intermediate xaringan workshop\nHome ‚Ä¢ yihui/xaringan Wiki ‚Ä¢ GitHub ‚Äì wiki of customizations for xaringan\nMaking Extra Great Slides ‚Ä¢ Garrick Aden‚ÄëBuie ‚Äì talk & slides with xaringan overview and featuring CSS styling and xaringanthemer\nApplying design guidelines to slides with {xaringanthemer} ‚Ä¢ katie jolly ‚Äì blog post\nA playground of extensions for xaringan ‚Ä¢ xaringanExtra ‚Äì package site\nCustom xaringan CSS Themes ‚Ä¢ xaringanthemer ‚Äì package site"
  },
  {
    "objectID": "blog/2021-03-16-deploying-xaringan-slides/index.html#footnotes",
    "href": "blog/2021-03-16-deploying-xaringan-slides/index.html#footnotes",
    "title": "Deploying xaringan Slides with GitHub Pages",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nChapter 12 Connect RStudio to Git and GitHub | Happy Git and GitHub for the useR‚Ü©Ô∏é\nHow to Write a Git Commit Message | Chris Beams‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Meeting People Where They R",
    "section": "",
    "text": "Hello Quarto: Porting my Website from Hugo Ap√©ro\n\n\nNotes from porting my personal Blogdown website to Quarto \n\n\n\nR\n\n\nquarto\n\n\nwebsite\n\n\n\n\n\n\nSep 29, 2023\n\n\nSilvia Canel√≥n\n\n\n\n\n\n\n\n\n\n\n\n\nCreating the Philly Center City SIPS Interactive Map\n\n\nAn R tutorial on webscraping, geocoding, and map-making \n\n\n\nR\n\n\ntutorial\n\n\nmaps\n\n\nwebscraping\n\n\nrobotstxt\n\n\nrvest\n\n\nleaflet\n\n\nggmap\n\n\n\n\n\n\nMay 31, 2022\n\n\nSilvia Canel√≥n\n\n\n\n\n\n\n\n\n\n\n\n\nHello Umami: Deploying a Privacy-Friendly Open Source Tool for Web Analytics\n\n\nA use case for adding Umami web analytics to a blogdown site and deploying using Railway.\n\n\n\nR\n\n\nWebsite\n\n\nblogdown\n\n\ntest\n\n\nHugo\n\n\n\n\n\n\nJan 18, 2022\n\n\nSilvia Canel√≥n\n\n\n\n\n\n\n\n\n\n\n\n\nResources for Data Viz Accessibility\n\n\nA selection of general and R-specific resources on how and why to make accessible data visualizations.\n\n\n\nR\n\n\ndata viz\n\n\na11y\n\n\nggpattern\n\n\nhighcharter\n\n\n\n\n\n\nSep 23, 2021\n\n\nSilvia Canel√≥n\n\n\n\n\n\n\n\n\n\n\n\n\nWAVE Audit No.¬†1\n\n\nFirst audit using the WebAIM Web Accessibility Evaluation Tool (WAVE)\n\n\n\nWebsite\n\n\nEducation\n\n\na11y\n\n\n\n\n\n\nJun 2, 2021\n\n\nSilvia Canel√≥n\n\n\n\n\n\n\n\n\n\n\n\n\nHello Hugo Ap√©ro: Converting a Blogdown Site from Hugo Academic\n\n\nA tutorial on how to take your personal Hugo Academic/Wowchemy website and convert it to the Hugo Ap√©ro theme\n\n\n\nR\n\n\nWebsite\n\n\nTutorial\n\n\ngit\n\n\nblogdown\n\n\nHugo\n\n\n\n\n\n\nJun 1, 2021\n\n\nSilvia Canel√≥n\n\n\n\n\n\n\n\n\n\n\n\n\nDeploying xaringan Slides with GitHub Pages\n\n\nA ten-step workflow for creating an HTML xaringan slide deck and deploying it to the web using GitHub Pages\n\n\n\nR\n\n\nTutorial\n\n\nxaringan\n\n\ngit\n\n\n\n\n\n\nMar 16, 2021\n\n\nSilvia Canel√≥n\n\n\n\n\n\n\n\n\n\n\n\n\nBecoming certified as an RStudio Tidyverse Instructor\n\n\nAn overview of the RStudio Instructor certification process and collection of resources to support anyone on their certification journey.\n\n\n\nR\n\n\nRStudio\n\n\nEducation\n\n\ntidyverse\n\n\n\n\n\n\nOct 7, 2020\n\n\nSilvia Canel√≥n\n\n\n\n\n\n\n\n\n\n\n\n\nCustomizing Hugo Academic‚Äôs Dark Mode with Help from Atom\n\n\nTutorial on how to customize the dark mode in Hugo‚Äôs Academic theme with help from the Atom text editor package Pigments.\n\n\n\nWebsite\n\n\nTutorial\n\n\nAtom\n\n\nblogdown\n\n\nHugo\n\n\nCSS\n\n\n\n\n\n\nJun 16, 2020\n\n\nSilvia Canel√≥n\n\n\n\n\n\n\n\n\n\n\n\n\nMigrating from Trello to Airtable: Working with JSON Data in R\n\n\nTutorial on how to migrate your current Trello board to an Airtable base from start to finish.\n\n\n\nR\n\n\nTutorial\n\n\njson\n\n\njsonlite\n\n\ntidyverse\n\n\n\n\n\n\nMay 12, 2020\n\n\nSilvia Canel√≥n\n\n\n\n\n\n\nNo matching items\n\n Back to topReuseCC BY-SA 4.0"
  },
  {
    "objectID": "blog/2021-06-02-wave-audit-1/index.html",
    "href": "blog/2021-06-02-wave-audit-1/index.html",
    "title": "WAVE Audit No.¬†1",
    "section": "",
    "text": "Did you know that 97.4% of home pages have web accessibility failures??? üò±\nThis finding is one of many from an accessibility analysis that non-profit WebAIM (Web Accessibility in Mind) conducts annually on home pages of the top one million websites. You can find a summary of these findings in a WebAIM blog post and detailed information in the full report, both published on April 30, 2021.\nLearning about all of the ways that digital content is made inaccessible to people with disabilities has made me take inventory of the different ways that I have contributed to this problem (there was some shame to process here üôà).\nThe magic of R Markdown has given me the gift of turning R code into a variety of HTML outputs including R notebooks, xaringan presentation slides, and websites like this one ‚Äì all of which I‚Äôve been able to share freely online with others. This magic though (like all magic?) comes with limitations. R tools (and technology more broadly) can‚Äôt automatically ensure that its various outputs are accessible to everyone. That‚Äôs where we come in as software developers and content creators and take personal responsibility. At the risk of extending this metaphor too far, I‚Äôll finish by offering the framework that we all need to practice (accessibility) spells/skills in order to use these magical tools responsibly.\nAll of this to say that gaining awareness about accessibility as a way to create the more inclusive world that I want to live in has motivated me to do better. I even found myself excited to conduct accessibility audits on my digital content, including my personal website (data viz too)!"
  },
  {
    "objectID": "blog/2021-06-02-wave-audit-1/index.html#home-page",
    "href": "blog/2021-06-02-wave-audit-1/index.html#home-page",
    "title": "WAVE Audit No.¬†1",
    "section": "Home page",
    "text": "Home page\nLink: https://silvia.rbind.io/\nAudit results:\n\n1 error\n\n1 x Missing alternative text\n\n6 alerts\n\n1 x Suspicious link text\n5 x Redundant title text\n\n\n\n\n\nFigure 1: Audit for my home page"
  },
  {
    "objectID": "blog/2021-06-02-wave-audit-1/index.html#about-page",
    "href": "blog/2021-06-02-wave-audit-1/index.html#about-page",
    "title": "WAVE Audit No.¬†1",
    "section": "About page",
    "text": "About page\nLink: https://silvia.rbind.io/about/\nAudit results:\n\n4 errors\n\n3 x Linked image missing alternative text\n1 x Empty link\n\n19 alerts\n\n2 x Skipped heading level\n1 x Possible heading\n4 x Suspicious link text\n7 x Redundant link\n5 x Redundant title text\n\n\n\n\n\nFigure 2: Audit for my About page header\n\n\n\n\n\nFigure 3: Audit for the main section of my About page\n\n\n\n\nFull page screenshot\n\n\n\n\nFigure 4: Audit for my About page in full page view"
  },
  {
    "objectID": "blog/2021-06-02-wave-audit-1/index.html#blog-page",
    "href": "blog/2021-06-02-wave-audit-1/index.html#blog-page",
    "title": "WAVE Audit No.¬†1",
    "section": "Blog page",
    "text": "Blog page\nLink: https://silvia.rbind.io/blog/\nAudit results:\n\n6 errors\n\n1 x Missing alternative text\n5 x Linked image missing alternative text\n\n10 alerts\n\n5 x Redundant link\n5 x Redundant title text\n\n\n\n\n\nFigure 5: Audit for my Blog listing page in full page view\n\n\n\nBlog example\nLink: https://silvia.rbind.io/blog/hello-hugo-apero/\nAudit results:\n\n25 errors\n\n1 x Missing alternative text\n24 x Empty link\n\n177 contrast errors\n\n177 x Very low contrast\n\n17 alerts\n\n9 x Long alternative text\n1 x Skipped heading level\n1 x Broken same-page link\n6 x Redundant title text\n\n\n\n\n\nAlerts shown for links in the navigation bar and for a heading item. Errors shown for the blog decorative image and for a link symbol next to a header."
  },
  {
    "objectID": "blog/2021-06-02-wave-audit-1/index.html#talk-page",
    "href": "blog/2021-06-02-wave-audit-1/index.html#talk-page",
    "title": "WAVE Audit No.¬†1",
    "section": "Talk page",
    "text": "Talk page\nLink: https://silvia.rbind.io/talk/\nAudit results:\n\n5 errors\n\n5 x Linked image missing alternative text\n\n13 alerts\n\n5 x Linked image missing alternative text\n2 x Skipped heading level\n5 x Redundant link\n5 x Redundant title text\n1 x YouTube video\n\n\n\n\n\nFigure 7: Audit for my Talk listing page\n\n\n\n\nFull page screenshot\n\n\n\n\nFigure 8: Audit for my About page header in full page view\n\n\n\n\nTalk example\nLink: https://silvia.rbind.io/talk/2021-data-viz-accessibility/\nAudit results:\n\n1 error\n\n1 x Empty link\n\n6 alerts\n\n1 x Skipped heading level\n5 x Redundant title text\n\n\n\n\n\nFigure 9: Audit for my CSV Conf talk post in full page view"
  },
  {
    "objectID": "blog/2021-06-02-wave-audit-1/index.html#publication-page",
    "href": "blog/2021-06-02-wave-audit-1/index.html#publication-page",
    "title": "WAVE Audit No.¬†1",
    "section": "Publication page",
    "text": "Publication page\nLink: https://silvia.rbind.io/publication/\nAudit results:\n\n0 errors\n5 alerts\n\n5 x Redundant title text\n\n\n\n\n\nFigure 10: Audit for my Publication listing page\n\n\n\n\nFull page screenshot\n\n\n\n\nAlerts displayed for the navigation bar and footer\n\n\n\n\nPublication example\nLink: https://silvia.rbind.io/publication/2021-geospatial-analysis-pregnancy-outcomes/\nAudit results:\n\n1 errors\n\n1 x Empty link\n\n6 alerts\n\n1 x Skipped heading level\n5 x Redundant title text\n\n\n\n\n\nFigure 12: Audit for my geospatial analysis publication in full page view"
  },
  {
    "objectID": "blog/2021-06-02-wave-audit-1/index.html#project-page",
    "href": "blog/2021-06-02-wave-audit-1/index.html#project-page",
    "title": "WAVE Audit No.¬†1",
    "section": "Project page",
    "text": "Project page\nLink: https://silvia.rbind.io/project/\nAudit results:\n\n3 errors\n\n3 x Empty link\n\n5 alerts\n\n5 x Redundant title text\n\n\n\n\n\nFigure 13: Audit for my Project listing page\n\n\n\nProject example\nLink: https://silvia.rbind.io/project/2021-tidy-tuesday-alt-text/\nAudit results:\n\n2 errors\n\n2 x Empty link\n\n10 alerts\n\n3 x Long alternative text\n1 x Skipped heading level\n6 x Redundant title text\n\n\n\n\n\nFigure 14: Audit for my TidyTuesdayAltText project post\n\n\n\n\nFull page screenshot\n\n\n\n\nFigure 15: Audit for my TidyTuesdayAltText project post in full page view"
  },
  {
    "objectID": "blog/2021-06-01-hello-hugo-apero/index.html#what-to-expect",
    "href": "blog/2021-06-01-hello-hugo-apero/index.html#what-to-expect",
    "title": "Hello Hugo Ap√©ro: Converting a Blogdown Site from Hugo Academic",
    "section": "What to expect",
    "text": "What to expect\nBy the end of the tutorial you will have switched your website from using the Hugo Academic theme to using the new Hugo Ap√©ro theme designed by Alison Hill \nSpecifically you will be able to migrate your blog, publications, and talks. If you need to migrate courses, I recommend taking a look at how Alison and Kelly Bodwin organized their courses and workshops into projects using this theme. I didn‚Äôt have projects prior to converting my site, but after creating a few projects post-Ap√©ro I‚Äôm confident any projects you‚Äôve created pre-Ap√©ro will carry over easily.\n\nProjects on my site: https://silvia.rbind.io/project\n\n\n\n\n\n\n\nMy Project listing: https://silvia.rbind.io/project\n\n\n\nIf you like videos, Alison recorded a walkthrough of this conversion process using Julia Silge‚Äôs site as an example.\nWhat not to expect\nA tutorial on how to create a Hugo Ap√©ro site from scratch ‚Äì but don‚Äôt worry! Alison covers this in a workshop she gave for R-Ladies Tunis and in the Get started series of blog posts included in the documentation site."
  },
  {
    "objectID": "blog/2021-06-01-hello-hugo-apero/index.html#the-plan",
    "href": "blog/2021-06-01-hello-hugo-apero/index.html#the-plan",
    "title": "Hello Hugo Ap√©ro: Converting a Blogdown Site from Hugo Academic",
    "section": "The Plan",
    "text": "The Plan\nI was lucky that Alison had already started converting her own personal site because she gave me a template and example to follow! \nWe‚Äôll follow the steps below throughout the tutorial and each of the six steps comes with its own commit in my git history, so you can see exactly what I changed and when. \n{{}}\nThen we‚Äôll reuse and migrate your existing content, set up a contact form, tidy up your directory, explore some resources for customizing your new site, and end with the grand finale: deploying your new site!"
  },
  {
    "objectID": "blog/2021-06-01-hello-hugo-apero/index.html#prework",
    "href": "blog/2021-06-01-hello-hugo-apero/index.html#prework",
    "title": "Hello Hugo Ap√©ro: Converting a Blogdown Site from Hugo Academic",
    "section": "Prework",
    "text": "Prework\nBranch deploy\nCreate a new apero branch from the primary branch of your website repository\n\ngit checkout -b apero to create new local branch\ngit push --set-upstream origin apero to push new branch to GitHub\n\nCreate a new Netlify deploy from your apero branch by enabling branch deploys on Netlify.com. Garrick Aden-Buie kindly provided some great resources on how to do this on Twitter. Netlify will automatically deploy a live preview of your site from your new branch to a link like &lt;branch-name&gt;--silvia.netlify.app. In my case it was https://apero‚Äìsilvia.netlify.app\n Site settings: Build & deploy &gt; Continuous Deployment &gt; Deploy contexts\n\n\n\n\n\n\n\nNetlify site settings for deploy contexts\n\n\n\nYour new apero branch deploy at this point is an independent copy of your current website so from here on out you can make changes freely without affecting anything in your main branch :tada:\nHugo version\nThe last piece of prework before we dive in is to update your local version of Hugo and update the Hugo version accordingly in a few different places.\n\n\nUpdate Hugo locally using blogdown::install_hugo() (for me the latest version was v0.82.1)\nblogdown::install_hugo()\n\n\nUpdate .Rprofile and then restart R per the instructions that appear in the console.\n# fix Hugo version\noptions(blogdown.hugo.version = \"0.82.1\")\n\n\nUpdate netlify.toml\n[context.production.environment]\n  HUGO_VERSION = \"0.82.1\"\n  HUGO_ENV = \"production\"\n  HUGO_ENABLEGITINFO = \"true\"\n\n[context.branch-deploy.environment]\n  HUGO_VERSION = \"0.82.1\"\n\n[context.deploy-preview.environment]\n  HUGO_VERSION = \"0.82.1\"\n\n\nRun blogdown::check_site() to find any issues. In my case these checking functions found a Hugo version mismatch and I ended up having to specifically run blogdown::install_hugo(\"0.82.1\") to resolve it.\nConsole output\n‚Äï Checking netlify.toml...\n‚óã Found HUGO_VERSION = 0.82.1 in [build] context of netlify.toml.\n| Checking that Netlify & local Hugo versions match...\n| Mismatch found:  blogdown is using Hugo version (0.69.2) to build site locally.  Netlify is using Hugo version (0.82.1) to build site.\n‚óè [TODO] Option 1: Change HUGO_VERSION = \"0.69.2\" in netlify.toml to match local version.\n‚óè [TODO] Option 2: Use blogdown::install_hugo(\"0.82.1\") to match Netlify version, and set options(blogdown.hugo.version = \"0.82.1\") in .Rprofile to pin this Hugo version (also remember to restart R).\n| Checking that Netlify & local Hugo publish directories match...\n‚óã Good to go - blogdown and Netlify are using the same publish directory: public\n‚Äï Check complete: netlify.toml\n\n\n\nIf you end up needing to make your own changes, I recommend running blogdown::check_site() again when you‚Äôre done to make sure you‚Äôve resolved all of the issues.\nAnd then run blogdown::serve_site() to render a live preview of your site :rocket:"
  },
  {
    "objectID": "blog/2021-06-01-hello-hugo-apero/index.html#install-theme-alongside-academic-change-in-config.toml",
    "href": "blog/2021-06-01-hello-hugo-apero/index.html#install-theme-alongside-academic-change-in-config.toml",
    "title": "Hello Hugo Ap√©ro: Converting a Blogdown Site from Hugo Academic",
    "section": "1. Install theme alongside Academic, change in config.toml\n",
    "text": "1. Install theme alongside Academic, change in config.toml\n\n\n Follow along with me at commit cc5d24\n\nThe first step is to install all of the Hugo Ap√©ro theme files to the theme/ folder in your site directory:\n\nblogdown::install_theme(theme = \"hugo-apero/hugo-apero\",\n                        update_config = FALSE, \n                        force = TRUE)\n\n\nConsole output\n\ntrying URL 'https://github.com/hugo-apero/hugo-apero/archive/main.tar.gz'\ndownloaded 21.4 MB\n\nDo not forget to change the 'theme' option in 'config.toml' to \"hugo-apero\"\nWarning message:\nThe theme has provided an example site. You should read the theme's documentation and at least take a look at the config file config.toml (or .yaml) of the example site, because not all Hugo themes work with any config files. \n\nAs indicated in console output, modify the config.toml file so it points to your new theme folder instead of hugo-academic:\n#theme = \"hugo-academic\"\ntheme = \"hugo-apero\"\n At this point you will probably start to get some error messages like the one below. Don‚Äôt panic! Let‚Äôs get through the rest of the steps first. I‚Äôm including my errors in this post in case they are helpful/validating for you!\nCould not build site because certain shortcodes weren't found\n\nError: Error building site: \"/Users/silvia/Documents/Website/silvia/content/home/demo.md:58:1\": failed to extract shortcode: template for shortcode \"alert\" not found"
  },
  {
    "objectID": "blog/2021-06-01-hello-hugo-apero/index.html#copy-all-academic-shortcodes-to-layouts-root-remove-later",
    "href": "blog/2021-06-01-hello-hugo-apero/index.html#copy-all-academic-shortcodes-to-layouts-root-remove-later",
    "title": "Hello Hugo Ap√©ro: Converting a Blogdown Site from Hugo Academic",
    "section": "2. Copy all Academic shortcodes to layouts/ root (remove later)",
    "text": "2. Copy all Academic shortcodes to layouts/ root (remove later)\n\n Follow along with me at commit f3c7d53\n\nCopy the shortcodes\n\nFrom themes/hugo-academic/layouts/shortcodes/\nTo layouts/shortcodes/\n\n My error message:\nError: Error building site: TOCSS: failed to transform \"style.main.scss\" (text/x-scss): SCSS processing failed: file \"stdin\", line 7, col 24: Invalid CSS after \"...textFontFamily:\": expected expression (e.g. 1px, bold), was \"&lt;no value&gt;;\""
  },
  {
    "objectID": "blog/2021-06-01-hello-hugo-apero/index.html#remove-all-assets",
    "href": "blog/2021-06-01-hello-hugo-apero/index.html#remove-all-assets",
    "title": "Hello Hugo Ap√©ro: Converting a Blogdown Site from Hugo Academic",
    "section": "3. Remove all assets",
    "text": "3. Remove all assets\n\n Follow along with me at commit 3843c76\n\nBefore deleting anything, I recommend making a backup of your entire website folder, just in case.\nIn the assets/ root folder, delete:\n\nthe images/ folder which might contain your site icon\nthe scss/ folder which might contain your custom.scss file\n\n My error message:\nError: Error building site: TOCSS: failed to transform \"style.main.scss\" (text/x-scss): SCSS processing failed: file \"stdin\", line 7, col 24: Invalid CSS after \"...textFontFamily:\": expected expression (e.g. 1px, bold), was \"&lt;no value&gt;;\""
  },
  {
    "objectID": "blog/2021-06-01-hello-hugo-apero/index.html#remove-all-custom-layouts",
    "href": "blog/2021-06-01-hello-hugo-apero/index.html#remove-all-custom-layouts",
    "title": "Hello Hugo Ap√©ro: Converting a Blogdown Site from Hugo Academic",
    "section": "4. Remove all custom layouts",
    "text": "4. Remove all custom layouts\n\n Follow along with me at commit 1ad7e3d\n\nI had a couple of partials that I deleted from the layouts/ folder:\n\n\npartials/site_footer.html which provided a custom footer for my website\n\npartials/widgets/about.html which included the custom formatting for certificates in the Education section of the About page of my Academic site\n\n My error message:\nError: Error building site: TOCSS: failed to transform \"style.main.scss\" (text/x-scss): SCSS processing failed: file \"stdin\", line 7, col 24: Invalid CSS after \"...textFontFamily:\": expected expression (e.g. 1px, bold), was \"&lt;no value&gt;;\""
  },
  {
    "objectID": "blog/2021-06-01-hello-hugo-apero/index.html#copy-over-ap√©ro-example-site-config.toml-file",
    "href": "blog/2021-06-01-hello-hugo-apero/index.html#copy-over-ap√©ro-example-site-config.toml-file",
    "title": "Hello Hugo Ap√©ro: Converting a Blogdown Site from Hugo Academic",
    "section": "5. Copy over Ap√©ro example site config.toml file",
    "text": "5. Copy over Ap√©ro example site config.toml file\n\n Follow along with me at commit db37289\n\nRename config.toml in the root folder to config_old.toml\nCopy config.toml\n\nFrom themes/hugo-apero/exampleSite/\nTo your root directory (in my case it was silvia/)\n\n My error message:\nError: Error building site: failed to render pages: render of \"page\" failed: execute of template failed: template: _default/single.html:3:8: executing \"_default/single.html\" at &lt;partial \"head.html\" .&gt;: error calling partial: \"/Users/silvia/Documents/Website/silvia/themes/hugo-apero/layouts/partials/head.html:14:53\": execute of template failed: template: partials/head.html:14:53: executing \"partials/head.html\" at &lt;js&gt;: can't evaluate field Build in type string"
  },
  {
    "objectID": "blog/2021-06-01-hello-hugo-apero/index.html#remove-academic-config-directory",
    "href": "blog/2021-06-01-hello-hugo-apero/index.html#remove-academic-config-directory",
    "title": "Hello Hugo Ap√©ro: Converting a Blogdown Site from Hugo Academic",
    "section": "6. Remove Academic config/ directory",
    "text": "6. Remove Academic config/ directory\n\n Follow along with me at commit 5541f38\n\nDelete the config/ folder from your root directory (in my case silvia/)\nI learned the hard way that the error below was due to not using an updated version of Hugo, which is why I included that step in the Prework. All this to say, I‚Äôm hoping you don‚Äôt see the error below!\n My error message:\nError: Error building site: failed to render pages: render of \"page\" failed: execute of template failed: template: _default/single.html:3:8: executing \"_default/single.html\" at &lt;partial \"head.html\" .&gt;: error calling partial: \"/Users/silvia/Documents/Website/silvia/themes/hugo-apero/layouts/partials/head.html:14:53\": execute of template failed: template: partials/head.html:14:53: executing \"partials/head.html\" at &lt;js&gt;: can't evaluate field Build in type string"
  },
  {
    "objectID": "blog/2021-06-01-hello-hugo-apero/index.html#migrating-the-content",
    "href": "blog/2021-06-01-hello-hugo-apero/index.html#migrating-the-content",
    "title": "Hello Hugo Ap√©ro: Converting a Blogdown Site from Hugo Academic",
    "section": "Migrating the content",
    "text": "Migrating the content\nAssuming you have made it this far and are able to at least serve a live site that uses the new Hugo Ap√©ro theme, you are ready to start migrating your content! :tada:\nFile are organized differently in Hugo Ap√©ro and the next steps detail the high-level changes I made to get my content to fit the new structure. The goal was to have my site parallel the Hugo Ap√©ro example site and Alison‚Äôs personal site.\nFile organization\nTo get an overview of how the file structure is different between the Academic and Ap√©ro themes we‚Äôll look at the content/ folder of the Ap√©ro example site, my old Academic site, and my current Ap√©ro site. These are organized into the panelsets below.\n\n\nExample site\nMy Academic site\nMy Ap√©ro site\n\n\n\n\n Location: silvia/themes/hugo-apero/exampleSite\n‚îú‚îÄ‚îÄ config.toml\n‚îú‚îÄ‚îÄ content\n    ‚îú‚îÄ‚îÄ _index.md\n    ‚îú‚îÄ‚îÄ about\n    ‚îú‚îÄ‚îÄ blog\n    ‚îú‚îÄ‚îÄ collection\n    ‚îú‚îÄ‚îÄ contributors.md\n    ‚îú‚îÄ‚îÄ elements\n    ‚îú‚îÄ‚îÄ form\n    ‚îú‚îÄ‚îÄ license.md\n    ‚îú‚îÄ‚îÄ project\n    ‚îî‚îÄ‚îÄ talk\n\n\n\n Location: silvia/\n.\n‚îú‚îÄ‚îÄ config.toml\n‚îú‚îÄ‚îÄ content\n    ‚îú‚îÄ‚îÄ authors\n    ‚îú‚îÄ‚îÄ courses\n    ‚îú‚îÄ‚îÄ home\n    ‚îú‚îÄ‚îÄ license.md\n    ‚îú‚îÄ‚îÄ post\n    ‚îú‚îÄ‚îÄ project\n    ‚îú‚îÄ‚îÄ publication\n    ‚îú‚îÄ‚îÄ slides\n    ‚îî‚îÄ‚îÄ talk\n\n\n\n Location: silvia/\n.\n‚îú‚îÄ‚îÄ config.toml\n‚îú‚îÄ‚îÄ content\n    ‚îú‚îÄ‚îÄ _index.md       # &lt;-- new!\n    ‚îú‚îÄ‚îÄ about           # &lt;-- new!\n    ‚îú‚îÄ‚îÄ blog            # &lt;-- renamed (formerly post)\n    ‚îú‚îÄ‚îÄ collection      # &lt;-- new!\n    ‚îú‚îÄ‚îÄ form            # &lt;-- new!\n    ‚îú‚îÄ‚îÄ license.md\n    ‚îú‚îÄ‚îÄ project\n    ‚îú‚îÄ‚îÄ publication\n    ‚îî‚îÄ‚îÄ talk\n\n\n\n\nAbout page\nResource: Customize your about page | Hugo Ap√©ro\nMy About page:\n\ncontent/about/header/index.md\ncontent/about/main/index.md\ncontent/about/sidebar/index.md\n\n\n\n\n\n\n\n\nThe header of my About page: https://silvia.rbind.io/about/\n\n\n\n\n\n\n\n\n\n\nThe main section of my About page: https://silvia.rbind.io/about/\n\n\n\nI wanted to reuse my content from the About section of my Academic site, so I did a lot of copy-and-pasting into the right spots before editing. These steps are outlined in the table below.\n\n\n\n\n\n\n\n\nStep\nContent to copy\nFrom\nTo\n\n\n\n1\nFolder\nthemes/hugo-apero/exampleSite/content/about/\ncontent/\n\n\n2\nBody part 1\ncontent/authors/silvia/_index.md\ncontent/about/header/index.md\n\n\n3\nBody part 2\ncontent/authors/silvia/_index.md\ncontent/about/main/index.md\n\n\n4\nBiography ‚Üí outro\ncontent/authors/silvia/_index.md\ncontent/about/main/index.md\n\n\n5\nInterests ‚Üí link_list\ncontent/authors/silvia/_index.md\ncontent/about/sidebar/index.md\n\n\n6\nPhoto\ncontent/authors/silvia/avatar.png\ncontent/about/sidebar/avatar.png\n\n\nHomepage\nResource: Customize your homepage | Hugo Ap√©ro\nMy homepage: content/_index.md\n\n\n\n\n\n\n\nMy Homepage: https://silvia.rbind.io\n\n\n\n\nCopy _ index.md from themes/hugo-apero/content/ to content/\nSave an image for your homepage in the static/img/ folder\nSpecify your homepage image in _ index.md\nBlog\nMy blog listing: content/blog/_index.md\n\n\n\n\n\n\n\nMy Blog listing: https://silvia.rbind.io/blog\n\n\n\nUpdate [menu] options in config.toml to activate Blog by changing url = \"/blog/\" and renaming content/post/ to content/blog/ to activate the new Ap√©ro layout with the sidebar on the blog post listing and to enable thumbnails\n[[menu.header]]\n  name = \"Blog\"\n  title = \"Blog\"\n  url = \"/blog/\"\n  weight = 2            # &lt;-- item 2 in the navigation bar\nEdit content/blog/_ index.md with heading for the Blog listing page\n\nMake sure text_link_url: /blog/\nThe author: field will populate the by-line in each blog post unless another author is indicated in the YAML of the blog post.\nPublications\nMy publication listing: content/publication/_index.md\n\n\n\n\n\n\n\nMy Publication listing: https://silvia.rbind.io/publication\n\n\n\nUpdate [menu] options in config.toml to activate Publications\n[[menu.header]]\n  name = \"Publications\"\n  title = \"Publications\"\n  url = \"/publication/\"\n  weight = 4            # &lt;-- item 4 in the navigation bar\nRename content/publication/_ index.md to _ index-old.md and copy over _ index.md from themes/hugo-apero/exampleSite/content/blog/\nEdit content/publication/_ index.md to suit your preferences\nModify individual publications:\n\nThe Ap√©ro theme doesn‚Äôt have a built-in ‚Äúabstract‚Äù field so I copied and pasted the content in this field from the YAML of each publication page into the area below the YAML.\nIf your publications have multiple authors, they can be included as a string list in the author: field of the YAML\nTalks\nMy talk listing: content/talk/_index.md\n\n\n\n\n\n\n\nMy Talk listing: https://silvia.rbind.io/talk\n\n\n\nRename content/talk/_ index.md to _ index-old.md and copy over _ index.md from themes/hugo-apero/exampleSite/content/talk/\nEdit content/talk/_ index.md to suit your preferences\n.Rmd ‚Üí .Rmarkdown\nYou can create content for your blogdown site from .md, .Rmd, and .Rmarkdown files, anytime and anywhere. However, there are some limitations:\n\n\n.md is great if your file doesn‚Äôt contain any R code\n\n.Rmd files generate .html files while .Rmarkdown files generate .markdown files. Both can run R code, but only .markdown files generated from .Rmarkdown benefit from some of the features available from Hugo, like the syntax highlighting built into Ap√©ro.\n\nIf you were writing R tutorials/posts/etc. in .Rmd (like me), you will notice any code chunks you were displaying will not be formatted with proper syntax highlighting :cry: To remedy this, you will have to:\n\nChange these index.Rmd files to index.Rmarkdown (I recommend using your computer‚Äôs file explorer for this)\nRebuild your index.Rmarkdown files to index.markdown (using blogdown::build_site(build_rmd = TRUE), see the helper functions for more granular control)\nDelete the index.html output files that had previously been generated\n\n Rebuilding your R Markdown pages may not be a good idea if they contain code that might break, so please proceed with caution!\nIf you made it this far, congratulations! You have a brand new site! :partying_face:"
  },
  {
    "objectID": "blog/2021-06-01-hello-hugo-apero/index.html#final-touches",
    "href": "blog/2021-06-01-hello-hugo-apero/index.html#final-touches",
    "title": "Hello Hugo Ap√©ro: Converting a Blogdown Site from Hugo Academic",
    "section": "Final touches",
    "text": "Final touches\nContact form\nResource: Built-in Contact Form | Hugo Ap√©ro\nIf you‚Äôd like to use Ap√©ro‚Äôs built-in contact form powered by Formspree, copy the themes/hugo-apero/exampleSite/content/form/ folder into content/ and edit contact.md.\nTidying up your directory\nNow you can delete all of the files and folders you don‚Äôt need anymore!\nI‚Äôm including the files and folders I deleted as a list and as a directory tree. These are organized in the panelset below.\n\n\nList of items\nDirectory tree\n\n\n\n\n\nThe content folders carried over from Hugo Academic: authors, home, post, courses, and slides\nThe config folder\nThe resources folder\nThe data folder containing fonts and themes folders\nThe assets/images folder\nThe static/img/headers, static/publications, and static/rmarkdown-libs folders\nAll of the index.html files in the blog, publication, and talks folders\nThe old config file, that I had renamed config_old.toml\n\nThe old index files that I had renamed _ index-old.md\n\nThe partials in layouts/shortcodes\nAnd finally the themes/hugo-academic folder! üî•\n\n\n\n\nI deleted the following files:\n\nAll of the index.html files in the blog, publication, and talks folders\nThe old config file, that I had renamed config_old.toml\n\nThe old index files that I had renamed _ index-old.md\n\n\nAnd I deleted the folders indicated in this directory tree:\n Location: silvia/\n.\n‚îú‚îÄ‚îÄ config                # &lt;-- this folder\n‚îú‚îÄ‚îÄ resources             # &lt;-- this folder\n‚îú‚îÄ‚îÄ data                  # &lt;-- this folder\n‚îú‚îÄ‚îÄ assets\n‚îÇ   ‚îî‚îÄ‚îÄ images            # &lt;-- this folder\n‚îú‚îÄ‚îÄ static\n‚îÇ   ‚îú‚îÄ‚îÄ img\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ headers       # &lt;-- this folder\n‚îÇ   ‚îú‚îÄ‚îÄ publications      # &lt;-- this folder\n‚îÇ   ‚îî‚îÄ‚îÄ rmarkdown-libs    # &lt;-- this folder\n‚îú‚îÄ‚îÄ layouts\n‚îÇ   ‚îî‚îÄ‚îÄ shortcodes        # &lt;-- custom partials in this folder\n‚îî‚îÄ‚îÄ themes\n    ‚îî‚îÄ‚îÄ hugo-academic     # &lt;-- this folder"
  },
  {
    "objectID": "blog/2021-06-01-hello-hugo-apero/index.html#customizing-your-site",
    "href": "blog/2021-06-01-hello-hugo-apero/index.html#customizing-your-site",
    "title": "Hello Hugo Ap√©ro: Converting a Blogdown Site from Hugo Academic",
    "section": "Customizing your site",
    "text": "Customizing your site\nHopefully all of that wasn‚Äôt terrible, and if it was, please know I‚Äôm rooting for you. You‚Äôre doing great! :raised_hands:\nNow you get to enjoy the fun part which is customizing your site! The theme documentation goes through this in detail:\n\nSet up your social | Hugo Ap√©ro\nStyle your site typography | Hugo Ap√©ro\nStyle your site colors | Hugo Ap√©ro"
  },
  {
    "objectID": "blog/2021-06-01-hello-hugo-apero/index.html#deploying-your-new-site",
    "href": "blog/2021-06-01-hello-hugo-apero/index.html#deploying-your-new-site",
    "title": "Hello Hugo Ap√©ro: Converting a Blogdown Site from Hugo Academic",
    "section": "Deploying your new site",
    "text": "Deploying your new site\nOnce you‚Äôre happy with your new Ap√©ro site, the last step is to merge your apero branch with the primary branch of your website repository. But first, a few steps:\n\nOptional: Create a branch of your primary branch and call it hugo-academic so that you have a snapshot of your Academic files right before the merge. Since we set up Netlify to deploy all of our branches, there will now be a live link for this new branch that you can visit whenever you feel like time traveling back to your old site. For me this link is https://hugo-academic‚Äìsilvia.netlify.app/\n\nSwitch back to your apero branch and update the baseURL field in config.toml to your regular website path. In my case:\nbaseURL = \"https://silvia.rbind.io/\"\nThen commit and push this change to your apero branch.\n\nMerge your apero branch with your primary branch. I usually use git commands in a combination of the RStudio terminal and the Git pane, but for this big merge I felt more comfortable doing it on github.com! :sweat_smile: Do what feels most comfortable for you.\n\nResolve any merge conflicts (I had a few!) in the git tool of your choosing. These are the git commands GitHub recommended:\ngit fetch origin       # makes sure local files were recent\ngit checkout apero     # moves you to your `apero` branch\ngit merge main         # attempts a merge with your `main` branch\nWhen you‚Äôre finished, commit your changes and push. Then follow these next steps, also recommended by GitHub:\ngit checkout main       # moves you to your `main` branch\ngit merge --no-ff apero # creates a new commit for the merge\nThis step will sort of replace all of the files that both themes had in common with the apero version (e.g.¬†config.toml, netlify.toml, content/publication), and leave the old Academic files alone. So you will have to delete these extra Academic files (again!). I‚Äôm not sure how to avoid this ‚Äì maybe it‚Äôs not an issue when you don‚Äôt have merge conflicts? I don‚Äôt know :thinking:\n\n\nTidy up your directory (again?)\nGo through the steps above to clean out any residual Academic files from your directory. Make sure to check your content/ folders for any example files from Academic that might still be hanging around and delete them.\nThen run blogdown::serve_site() to build your new Ap√©ro site locally. Go through the site and make sure everything looks the way it should and that links are generally pointing to the right places.\nWhen you‚Äôre satisfied, commit the changes to your primary branch!There may be a lot of files that were deleted and added during the switch to Ap√©ro and, while not generally recommended, I used the git add . command to stage all of the changes at once, commited the changes, and then pushed. I did this after thoroughly looking through the list of changed files so I knew what was happening.\n\nWait a couple of minutes for the changes to get pushed to your primary branch (e.g.¬†main) and then wait patiently for Netlify to build your site after the merge.\n Celebrate and share your brand new site! üéâ ü•≥ üçæIf you share on Twitter, use the #HugoApero hashtag so the Hugo Ap√©ro squad can clap for you!"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "Silvia Canel√≥n",
    "section": "",
    "text": "Hey, I‚Äôm happy you‚Äôre here\n\nThanks for stopping by!\nI‚Äôm a data analyst in the Penn Medicine Center for Health Justice at the University of Pennsylvania. My research interests include applications of biomedical and spatial data science in the public and population health fields.\nI work on projects that use electronic health record (EHR) and geospatial data to explore how the neighborhood environment and access to urban nature can impact the health of individuals in Philadelphia. Learn more about my research interests in publications.\nGet in touch by sending me a note!"
  },
  {
    "objectID": "about/index.html#about-me",
    "href": "about/index.html#about-me",
    "title": "Silvia Canel√≥n",
    "section": "About me",
    "text": "About me\n\n\nBiomedical engineer turned informaticist, curious about all intersections of data and society.\nI enjoy using R to optimize my data science workflow and have noticed it making guest appearances elsewhere in my life. I‚Äôm certified as an RStudio Tidyverse Instructor and am passionate about R education and data literacy as ways to build power in communities. Keep up with my R tinkering in my blog and presentations in talks.\n\n\nTidyverse Instructor Certification ‚àô RStudio, PBC ‚àô 2020\n\n\n\n\nPrior to joining the Center for Health Justice, I developed novel data mining methods to extract meaningful information from the EHR and study health outcomes and disparities in pregnant populations. I‚Äôm particularly interested in research that combines biomedical data science with open data sources in ways that prioritize health equity in communities.\n\n\nCertificate in Biomedical Informatics ‚àô University of Pennsylvania ‚àô 2019\n\n\nPh.D.¬†in Biomedical Engineering ‚àô Purdue University ‚àô 2018\n\n\nB.S. in Biomedical Engineering ‚àô University of Minnesota ‚àô 2012"
  },
  {
    "objectID": "about/index.html#lately",
    "href": "about/index.html#lately",
    "title": "Silvia Canel√≥n",
    "section": "Lately ‚Ä¶",
    "text": "Lately ‚Ä¶\n\n\nBlog\n\n\n\n\n\n\n\n\n\n\nHello Quarto: Porting my Website from Hugo Ap√©ro\n\n\nNotes from porting my personal Blogdown website to Quarto\n\n\n\n\n\n\n\nNo matching items\n\n\nSee all ‚Üí\n\n\nTalks\n\n\n\n\n\n\n\n\n\n\nConsidering Equity in Data Visualization\n\n\nInvited talk for the Leonard Davis Institute of Health Economics Summer Undergraduate Mentored Research Program (SUMR)\n\n\n\n\n\n\n\nNo matching items\n\n\nSee all ‚Üí\n\n\nPublications\n\n\n\n\n\n\n\n\n\n\nComparison of different definitions of traumatic brain injury: implications for cohort characteristics and survival in women, Philadelphia, USA\n\n\n\n\n\n\n\nNo matching items\n\n\nSee all ‚Üí\n\n\nProjects\n\n\n\n\n\n\n\n\n\n\nPhilly Center City District SIPS: An Interactive Map\n\n\nA collection of interactive maps showing restaurants participating in Phily‚Äôs CCD SIPS\n\n\n\n\n\n\n\nNo matching items\n\n\nSee all ‚Üí"
  },
  {
    "objectID": "publication/2020-05-06-preprint-hydroxychloroquine-pregnancy/index.html",
    "href": "publication/2020-05-06-preprint-hydroxychloroquine-pregnancy/index.html",
    "title": "Is Hydroxychloroquine Safe During Pregnancy? Observations from Penn Medicine",
    "section": "",
    "text": "Type I collagen morphology can be characterized using fibril D-spacing, a metric which describes the periodicity of repeating bands of gap and overlap regions of collagen molecules arranged into collagen fibrils. This fibrillar structure is stabilized by enzymatic crosslinks initiated by lysyl oxidase (LOX), a step which can be disrupted using Œ≤-aminopropionitrile (BAPN). Murine in vivo studies have confirmed effects of BAPN on collagen nanostructure and the objective of this study was to evaluate the mechanism of these effects in vitro by measuring D-spacing, evaluating the ratio of mature to immature crosslinks, and quantifying gene expression of type I collagen and LOX. Osteoblasts were cultured in complete media, and differentiated using ascorbic acid, in the presence or absence of 0.25mM BAPN-fumarate. The matrix produced was imaged using atomic force microscopy (AFM) and 2D Fast Fourier transforms were performed to extract D-spacing from individual fibrils. The experiment was repeated for quantitative reverse transcription polymerase chain reaction (qRT-PCR) and Fourier Transform infrared spectroscopy (FTIR) analyses. The D-spacing distribution of collagen produced in the presence of BAPN was shifted toward higher D-spacing values, indicating BAPN affects the morphology of collagen produced in vitro, supporting aforementioned in vivo experiments. In contrast, no difference in gene expression was found for any target gene, suggesting LOX inhibition does not upregulate the LOX gene to compensate for the reduction in aldehyde formation, or regulate expression of genes encoding type I collagen. Finally, the mature to immature crosslink ratio decreased with BAPN treatment and was linked to a reduction in peak percent area of mature crosslink hydroxylysylpyridinoline (HP). In conclusion, in vitro treatment of osteoblasts with low levels of BAPN did not induce changes in genes encoding LOX or type I collagen, but led to an increase in collagen D-spacing as well as a decrease in mature crosslinks."
  },
  {
    "objectID": "publication/2020-05-06-preprint-hydroxychloroquine-pregnancy/index.html#abstract",
    "href": "publication/2020-05-06-preprint-hydroxychloroquine-pregnancy/index.html#abstract",
    "title": "Is Hydroxychloroquine Safe During Pregnancy? Observations from Penn Medicine",
    "section": "",
    "text": "Type I collagen morphology can be characterized using fibril D-spacing, a metric which describes the periodicity of repeating bands of gap and overlap regions of collagen molecules arranged into collagen fibrils. This fibrillar structure is stabilized by enzymatic crosslinks initiated by lysyl oxidase (LOX), a step which can be disrupted using Œ≤-aminopropionitrile (BAPN). Murine in vivo studies have confirmed effects of BAPN on collagen nanostructure and the objective of this study was to evaluate the mechanism of these effects in vitro by measuring D-spacing, evaluating the ratio of mature to immature crosslinks, and quantifying gene expression of type I collagen and LOX. Osteoblasts were cultured in complete media, and differentiated using ascorbic acid, in the presence or absence of 0.25mM BAPN-fumarate. The matrix produced was imaged using atomic force microscopy (AFM) and 2D Fast Fourier transforms were performed to extract D-spacing from individual fibrils. The experiment was repeated for quantitative reverse transcription polymerase chain reaction (qRT-PCR) and Fourier Transform infrared spectroscopy (FTIR) analyses. The D-spacing distribution of collagen produced in the presence of BAPN was shifted toward higher D-spacing values, indicating BAPN affects the morphology of collagen produced in vitro, supporting aforementioned in vivo experiments. In contrast, no difference in gene expression was found for any target gene, suggesting LOX inhibition does not upregulate the LOX gene to compensate for the reduction in aldehyde formation, or regulate expression of genes encoding type I collagen. Finally, the mature to immature crosslink ratio decreased with BAPN treatment and was linked to a reduction in peak percent area of mature crosslink hydroxylysylpyridinoline (HP). In conclusion, in vitro treatment of osteoblasts with low levels of BAPN did not induce changes in genes encoding LOX or type I collagen, but led to an increase in collagen D-spacing as well as a decrease in mature crosslinks."
  },
  {
    "objectID": "publication/2021-11-24-sct-stillbirth/index.html",
    "href": "publication/2021-11-24-sct-stillbirth/index.html",
    "title": "Evaluation of Stillbirth Among Pregnant People With Sickle Cell Trait",
    "section": "",
    "text": "Importance. Relative to what is known about pregnancy complications and sickle cell disease (SCD), little is known about the risk of pregnancy complications among those with sickle cell trait (SCT). There is a lack of clinical research among sickle cell carriers largely due to low sample sizes and disparities in research funding.\nObjective. To evaluate whether there is an association between SCT and a stillbirth outcome.\nDesign, Setting, and Participants. This retrospective cohort study included data on deliveries occurring between January 1, 2010, and August 15, 2017, at 4 quaternary academic medical centers within the Penn Medicine health system in Pennsylvania. The population included a total of 2482 deliveries from 1904 patients with SCT but not SCD, and 215 deliveries from 164 patients with SCD. Data were analyzed from May 3, 2019, to September 16, 2021.\nExposures. The primary exposure of interest was SCT, identified using clinical diagnosis codes recorded in the electronic health record.\nMain Outcomes and Measures. A multivariate logistic regression model was constructed to assess the risk of stillbirth using the following risk factors: SCD, numbers of pain crises and blood transfusions before delivery, delivery episode (as a proxy for parity), prior cesarean delivery, multiple gestation, patient age, marital status, race and ethnicity, ABO blood type, Rhesus (Rh) factor, and year of delivery.\nResults. This cohort study included 50‚ÄØ560 patients (63‚ÄØ334 deliveries), most of whom were aged 25 to 34 years (29‚ÄØ387 of 50‚ÄØ560 [58.1%]; mean [SD] age, 29.5 [6.1] years), were single at the time of delivery (28 186 [55.8%]), were Black or African American (23‚ÄØ777 [47.0%]), had ABO blood type O (22‚ÄØ879 [45.2%]), and were Rhesus factor positive (44‚ÄØ000 [87.0%]). From this general population, 2068 patients (4.1%) with a sickle cell gene variation were identified: 1904 patients (92.1%) with SCT (2482 deliveries) and 164 patients (7.9%) with SCD (215 deliveries). In the fully adjusted model, SCT was associated with an increased risk of stillbirth (adjusted odds ratio [aOR],‚Äâ8.94; 95% CI, 1.05-75.79; P‚Äâ=‚Äâ.045) while adjusting for the risk factors of SCD (aOR,‚Äâ26.40; 95% CI, 2.48-280.90; P‚Äâ=‚Äâ.007) and multiple gestation (aOR,‚Äâ4.68; 95% CI, 3.48-6.29; P‚Äâ&lt;‚Äâ.001).\nConclusions and Relevance. The results of this large, retrospective cohort study indicate an increased risk of stillbirth among pregnant people with SCT. These findings underscore the need for additional risk assessment during pregnancy for sickle cell carriers.\n\n\n\nDirected Acyclic Graph With Stillbirth as the Outcome and Sickle Cell Trait (SCT) as the Primary Exposure of Interest.\n\n\n\n\nAlternative Figure 2\n\n\n\n\nAlternative Directed Acyclic Graph With Stillbirth as the Outcome and Sickle Cell Trait (SCT) as the Primary Exposure of Interest\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "publication/2022-11-24-mwas-repurposed-covid19-meds/index.html",
    "href": "publication/2022-11-24-mwas-repurposed-covid19-meds/index.html",
    "title": "A medication-wide association study (MWAS) on repurposed drugs for COVID-19 with Pre-pandemic prescription medication exposure and pregnancy outcomes",
    "section": "",
    "text": "Information on effects of medication therapies during pregnancy is lacking as pregnant patients are often excluded from clinical trials. This retrospective study explores the potential of using electronic health record (EHR) data to inform safety profiles of repurposed COVID medication therapies on pregnancy outcomes using pre-COVID data. We conducted a medication-wide association study (MWAS) on prescription medication exposures during pregnancy and the risk of cesarean section, preterm birth, and stillbirth, using EHR data between 2010‚Äì2017 on deliveries at PennMedicine. Repurposed drugs studied for treatment of COVID-19 were extracted from ClinicalTrials.gov (n‚Äâ=‚Äâ138). We adjusted for known comorbidities diagnosed within 2 years prior to birth. Using previously developed medication mapping and delivery-identification algorithms, we identified medication exposure in 2,830 of a total 63,334 deliveries; from 138 trials, we found 31 medications prescribed and included in our cohort. We found 21 (68%) of the 31 medications were not positively associated with increased risk of the outcomes examined. With caution, these medications warrant potential for inclusion of pregnant individuals in future studies, while drugs found to be associated with pregnancy outcomes require further investigation. MWAS facilitates hypothesis-driven evaluation of drug safety across all prescription medications, revealing potential drug candidates for further research."
  },
  {
    "objectID": "publication/2022-11-24-mwas-repurposed-covid19-meds/index.html#abstract",
    "href": "publication/2022-11-24-mwas-repurposed-covid19-meds/index.html#abstract",
    "title": "A medication-wide association study (MWAS) on repurposed drugs for COVID-19 with Pre-pandemic prescription medication exposure and pregnancy outcomes",
    "section": "",
    "text": "Information on effects of medication therapies during pregnancy is lacking as pregnant patients are often excluded from clinical trials. This retrospective study explores the potential of using electronic health record (EHR) data to inform safety profiles of repurposed COVID medication therapies on pregnancy outcomes using pre-COVID data. We conducted a medication-wide association study (MWAS) on prescription medication exposures during pregnancy and the risk of cesarean section, preterm birth, and stillbirth, using EHR data between 2010‚Äì2017 on deliveries at PennMedicine. Repurposed drugs studied for treatment of COVID-19 were extracted from ClinicalTrials.gov (n‚Äâ=‚Äâ138). We adjusted for known comorbidities diagnosed within 2 years prior to birth. Using previously developed medication mapping and delivery-identification algorithms, we identified medication exposure in 2,830 of a total 63,334 deliveries; from 138 trials, we found 31 medications prescribed and included in our cohort. We found 21 (68%) of the 31 medications were not positively associated with increased risk of the outcomes examined. With caution, these medications warrant potential for inclusion of pregnant individuals in future studies, while drugs found to be associated with pregnancy outcomes require further investigation. MWAS facilitates hypothesis-driven evaluation of drug safety across all prescription medications, revealing potential drug candidates for further research."
  },
  {
    "objectID": "publication/2020-08-02-maddie-ehr-delivery-episode-algorithm/index.html",
    "href": "publication/2020-08-02-maddie-ehr-delivery-episode-algorithm/index.html",
    "title": "Development and Evaluation of MADDIE: Method to Acquire Delivery Date Information from Electronic Health Records",
    "section": "",
    "text": "Objective. To develop an algorithm that infers patient delivery dates (PDDs) and delivery-specific details from Electronic Health Records (EHRs) with high accuracy; enabling pregnancy-level outcome studies in women‚Äôs health.\nMaterials and Methods. We obtained EHR data from 1,060,100 female patients treated at Penn Medicine hospitals or outpatient clinics between 2010-2017. We developed an algorithm called MADDIE: Method to Acquire Delivery Date Information from Electronic Health Records that infers a PDD for distinct deliveries based on EHR encounter dates assigned a delivery code, the frequency of code usage, and the time differential between code assignments. We validated MADDIE‚Äôs PDDs against a birth log independently maintained by the Department of Obstetrics and Gynecology.\nResults. MADDIE identified 50,560 patients having 63,334 distinct deliveries. MADDIE was 98.6% accurate (F1-score 92.1%) when compared to the birth log. The PDD was on average 0.68 days earlier than the true delivery date for patients with only one delivery (¬± 1.43 days) and 0.52 days earlier for patients with more than one delivery episode (¬± 1.11 days).\nDiscussion. MADDIE is the first algorithm to successfully infer PDD information using only structured delivery codes and identify multiple deliveries per patient. MADDIE is also the first to validate the accuracy of the PDD using an external gold standard of known delivery dates as opposed to manual chart review of a sample.Conclusion. MADDIE augments the EHR with delivery-specific details extracted with high accuracy and relies only on structured EHR elements while harnessing temporal information and the frequency of code usage to identify accurate PDDs.\n\n\n\nPoster presented at the 2020 AMIA Annual Symposium"
  },
  {
    "objectID": "publication/2020-08-02-maddie-ehr-delivery-episode-algorithm/index.html#abstract",
    "href": "publication/2020-08-02-maddie-ehr-delivery-episode-algorithm/index.html#abstract",
    "title": "Development and Evaluation of MADDIE: Method to Acquire Delivery Date Information from Electronic Health Records",
    "section": "",
    "text": "Objective. To develop an algorithm that infers patient delivery dates (PDDs) and delivery-specific details from Electronic Health Records (EHRs) with high accuracy; enabling pregnancy-level outcome studies in women‚Äôs health.\nMaterials and Methods. We obtained EHR data from 1,060,100 female patients treated at Penn Medicine hospitals or outpatient clinics between 2010-2017. We developed an algorithm called MADDIE: Method to Acquire Delivery Date Information from Electronic Health Records that infers a PDD for distinct deliveries based on EHR encounter dates assigned a delivery code, the frequency of code usage, and the time differential between code assignments. We validated MADDIE‚Äôs PDDs against a birth log independently maintained by the Department of Obstetrics and Gynecology.\nResults. MADDIE identified 50,560 patients having 63,334 distinct deliveries. MADDIE was 98.6% accurate (F1-score 92.1%) when compared to the birth log. The PDD was on average 0.68 days earlier than the true delivery date for patients with only one delivery (¬± 1.43 days) and 0.52 days earlier for patients with more than one delivery episode (¬± 1.11 days).\nDiscussion. MADDIE is the first algorithm to successfully infer PDD information using only structured delivery codes and identify multiple deliveries per patient. MADDIE is also the first to validate the accuracy of the PDD using an external gold standard of known delivery dates as opposed to manual chart review of a sample.Conclusion. MADDIE augments the EHR with delivery-specific details extracted with high accuracy and relies only on structured EHR elements while harnessing temporal information and the frequency of code usage to identify accurate PDDs.\n\n\n\nPoster presented at the 2020 AMIA Annual Symposium"
  },
  {
    "objectID": "publication/2024-05-27-tbi-definitions/index.html",
    "href": "publication/2024-05-27-tbi-definitions/index.html",
    "title": "Comparison of different definitions of traumatic brain injury: implications for cohort characteristics and survival in women, Philadelphia, USA",
    "section": "",
    "text": "Background: Traumatic brain injury (TBI) is an acute injury that is understudied in civilian cohorts, especially among women, as TBI has historically been considered to be largely a condition of athletes and military service people. Both the Centres for Disease Control and Prevention (CDC) and Department of Defense (DOD)/Veterans Affairs (VA) have developed case definitions to identify patients with TBI from medical records; however, their definitions differ. We sought to re-examine these definitions to construct an expansive and more inclusive definition among a cohort of women with TBI.\nMethods: In this study, we use electronic health records (EHR) from a single healthcare system to study the impact of using different case definitions to identify patients with TBI. Specifically, we identified adult female patients with TBI using the CDC definition, DOD/VA definition and a combined and expanded definition herein called the Penn definition.\nResults: We identified 4446 adult-female TBI patients meeting the CDC definition, 3619 meeting the DOD/VA definition, and together, 6432 meeting our expanded Penn definition that includes the CDC ad DOD/VA definitions.\nConclusions: Using the expanded definition identified almost two times as many patients, enabling investigations to more fully characterise these patients and related outcomes. Our expanded TBI case definition is available to other researchers interested in employing EHRs to investigate TBI."
  },
  {
    "objectID": "publication/2024-05-27-tbi-definitions/index.html#abstract",
    "href": "publication/2024-05-27-tbi-definitions/index.html#abstract",
    "title": "Comparison of different definitions of traumatic brain injury: implications for cohort characteristics and survival in women, Philadelphia, USA",
    "section": "",
    "text": "Background: Traumatic brain injury (TBI) is an acute injury that is understudied in civilian cohorts, especially among women, as TBI has historically been considered to be largely a condition of athletes and military service people. Both the Centres for Disease Control and Prevention (CDC) and Department of Defense (DOD)/Veterans Affairs (VA) have developed case definitions to identify patients with TBI from medical records; however, their definitions differ. We sought to re-examine these definitions to construct an expansive and more inclusive definition among a cohort of women with TBI.\nMethods: In this study, we use electronic health records (EHR) from a single healthcare system to study the impact of using different case definitions to identify patients with TBI. Specifically, we identified adult female patients with TBI using the CDC definition, DOD/VA definition and a combined and expanded definition herein called the Penn definition.\nResults: We identified 4446 adult-female TBI patients meeting the CDC definition, 3619 meeting the DOD/VA definition, and together, 6432 meeting our expanded Penn definition that includes the CDC ad DOD/VA definitions.\nConclusions: Using the expanded definition identified almost two times as many patients, enabling investigations to more fully characterise these patients and related outcomes. Our expanded TBI case definition is available to other researchers interested in employing EHRs to investigate TBI."
  },
  {
    "objectID": "publication/2020-12-10-csections-emergency-admissions/index.html",
    "href": "publication/2020-12-10-csections-emergency-admissions/index.html",
    "title": "Not All C-sections Are the Same: Investigating Emergency vs.¬†Elective C-section Deliveries as an Adverse Pregnancy Outcome",
    "section": "",
    "text": "Session: Advanced Methods for Big Data Analytics in Women‚Äôs Health"
  },
  {
    "objectID": "publication/2020-12-10-csections-emergency-admissions/index.html#abstract",
    "href": "publication/2020-12-10-csections-emergency-admissions/index.html#abstract",
    "title": "Not All C-sections Are the Same: Investigating Emergency vs.¬†Elective C-section Deliveries as an Adverse Pregnancy Outcome",
    "section": "Abstract",
    "text": "Abstract\nElectronic Health Records (EHR) contain detailed information about a patient‚Äôs medical history and can be helpful in understanding clinical outcomes among populations generally underrepresented in research, including pregnant individuals. A cesarean delivery is a clinical outcome often considered in studies as an adverse pregnancy outcome, when in reality there are circumstances in which a cesarean delivery is considered the safest or best choice given the patient‚Äôs medical history, situation, and comfort. Rather than consider all cesarean deliveries to be negative outcomes, it is important to examine other risk factors that may contribute to a cesarean delivery being an adverse event. Looking at emergency admissions can be a useful way to ascertain whether or not a cesarean delivery is part of an adverse event. This study utilizes EHR data from Penn Medicine to assess patient characteristics and pregnancy-related conditions as risk factors for an emergency admission at the time of delivery. After adjusting for pregnancy number and cesarean number for each patient, preterm birth increased risk of an emergency admission, and patients younger than 25, or identifying as Black/African American, Asian, or Other/Mixed, had an increased risk. Later pregnancies and repeat cesareans decreased the risk of an emergency delivery, and White, Hispanic, and Native Hawaiian/Pacific Islander patients were at decreased risk. The same risk factors and trends were found among cesarean deliveries, except that Asian patients did not have an increased risk, and Native Hawaiian/Pacific Islander patients did not have a reduced risk in this group.\n\n\n\n2021 PSB Poster (letter)"
  },
  {
    "objectID": "publication/index.html",
    "href": "publication/index.html",
    "title": "Publications",
    "section": "",
    "text": "Comparison of different definitions of traumatic brain injury: implications for cohort characteristics and survival in women, Philadelphia, USA\n\n\nEHR study describing different definitions for Traumatic Brain Injury (TBI) and re-examining them to provide an expanded definition able to better characterize TBI among female patients.\n\n\n\nResearch\n\n\nEHR\n\n\nTBI\n\n\n\n\n\n\nMay 27, 2024\n\n\nBernadette A. D‚ÄôAlonzo, Abigail C. Bretzin, Andrea L.C. Schneider, Rebecca B. Morse, Silvia P. Canel√≥n, Doug J. Wiebe, Mary Regina Boland\n\n\n\n\n\n\n\nA medication-wide association study (MWAS) on repurposed drugs for COVID-19 with Pre-pandemic prescription medication exposure and pregnancy outcomes\n\n\nEHR study describing an MWAS approach to explore connections between exposure to repurposed COVID-19 prescription medications and the risk of cesarean section, preterm birth, and stillbirth\n\n\n\nResearch\n\n\ncovid-19\n\n\nEHR\n\n\npregnancy\n\n\nmedications\n\n\n\n\n\n\nNov 24, 2022\n\n\nLena Davidson, Silvia P. Canel√≥n, Mary Regina Boland\n\n\n\n\n\n\n\nTen simple rules to host an inclusive conference\n\n\nCommunity-led publication describing ten guidelines for hosting an inclusive conference\n\n\n\nEducation\n\n\ncommunity\n\n\n\n\n\n\nJul 21, 2022\n\n\nRoc√≠o Joo, Andrea S√°nchez-Tapia, Sara Mortara, Yanina Bellini Saibene, Heather Turner, Dorothea Hug Peter, Natalia Soledad Morandeira, Matt Bannert, Batool Almazrouq, Elizabeth Hare, Laura Aci√≥n, Juan Pablo Narv√°ez-G√≥mez, Marcela Alfaro C√≥rdoba, Federico Marini, Rita Giordano, Silvia Canel√≥n, Anicet Ebou, Adithi R. Upadhya, Joselyn Ch√°vez, Janani Ravi\n\n\n\n\n\n\n\nMedication-Wide Association Study Using Electronic Health Record Data of Prescription Medication Exposure and Multifetal Pregnancies: Retrospective Study\n\n\nEHR study describing an MWAS approach to explore connections between prescription medication exposure and the risk of multiple gestation pregnancies\n\n\n\nResearch\n\n\nEHR\n\n\npregnancy\n\n\nmedications\n\n\n\n\n\n\nJun 7, 2022\n\n\nLena Davidson, Silvia P. Canel√≥n, Mary Regina Boland\n\n\n\n\n\n\n\nDesign and Evaluation of a Postpartum Depression Ontology\n\n\nStudy describing an ontology created for the identification of patients with postpartum depression.\n\n\n\nResearch\n\n\nEHR\n\n\npregnancy\n\n\nppd\n\n\n\n\n\n\nMar 9, 2022\n\n\nRebecca B. Morse, Abigail C. Bretzin, Silvia P. Canel√≥n, Bernadette A. D‚ÄôAlonzo, Andrea L. C. Schneider, Mary R. Boland\n\n\n\n\n\n\n\nEvaluation of Stillbirth Among Pregnant People With Sickle Cell Trait\n\n\nRetrospective cohort study finding both sickle cell trait and disease to be associated with an increased risk of stillbirth, suggesting that sickle cell carriers would benefit from additional risk assessment during pregnancy.\n\n\n\nResearch\n\n\nEHR\n\n\npregnancy\n\n\nsickle cell disease\n\n\n\n\n\n\nNov 24, 2021\n\n\nSilvia P. Canel√≥n, Samantha Butts, Mary Regina Boland\n\n\n\n\n\n\n\nHarnessing electronic health records to study emerging environmental disasters: a proof of concept with perfluoroalkyl substances (PFAS)\n\n\nProof-of-concept study detailing how Electronic Health Record (EHR) data can be leveraged to study the impacts of environmental disasters like widespread exposure to perfluoroalkyl substances (PFAS).\n\n\n\nResearch\n\n\nenvironment\n\n\nEHR\n\n\nPFAS\n\n\n\n\n\n\nAug 11, 2021\n\n\nMary Regina Boland, Lena M. Davidson, Silvia P. Canel√≥n, Jessica Meeker, Trevor Penning, John H. Holmes, Jason H. Moore\n\n\n\n\n\n\n\nA Bayesian Hierarchical Modeling Framework for Geospatial Analysis of Adverse Pregnancy Outcomes\n\n\nStudy describing a Bayesian hierarchichal modeling framework used to explore which neighborhood-level factors and patient-level features were most informative for preterm birth and stillbirth pregnancy outcomes.\n\n\n\nResearch\n\n\npregnancy\n\n\nhealth disparities\n\n\nEHR\n\n\npreprint\n\n\n\n\n\n\nMay 11, 2021\n\n\nCecilia Balocchi, Ray Bai, Jessica Liu, Silvia P. Canel√≥n, Edward I. George, Yong Chen, Mary Regina Boland\n\n\n\n\n\n\n\nIndividual-Level and Neighborhood-Level Risk Factors for Severe Maternal Morbidity\n\n\nStudy showing that neighborhood-level risk factors are independent predictors of Severe Maternal Morbidity, providing further evidence that racial disparities in maternal outcomes are symptoms of historical and structural racism.\n\n\n\nResearch\n\n\npregnancy\n\n\nhealth disparities\n\n\nEHR\n\n\n\n\n\n\nApr 8, 2021\n\n\nJessica R. Meeker, Silvia P. Canel√≥n, Ray Bai, Lisa D. Levine, Mary Regina Boland\n\n\n\n\n\n\n\nNot All C-sections Are the Same: Investigating Emergency vs.¬†Elective C-section Deliveries as an Adverse Pregnancy Outcome\n\n\nPublication and poster accepted for the 2021 Pacific Biocomputing Symposium. This study utilizes Electronic Health Record (EHR) data to assess the impact of pregnancy-specific maternal morbidity and patient-specific characteristics on experiencing an emergency admission at the time of delivery and its relationship to Cesarean section (C-section) deliveries\n\n\n\nResearch\n\n\npregnancy\n\n\nPSB\n\n\nEHR\n\n\n\n\n\n\nDec 10, 2020\n\n\nSilvia P. Canel√≥n, Mary Regina Boland\n\n\n\n\n\n\n\nDevelopment and Evaluation of MADDIE: Method to Acquire Delivery Date Information from Electronic Health Records\n\n\nAn R algorithm designed to extract delivery episode details from structured Electronic Health Record data.\n\n\n\nResearch\n\n\n\n\n\n\nNov 17, 2020\n\n\nSilvia P. Canel√≥n, Heather H. Burris, Lisa D. Levine, Mary Regina Boland\n\n\n\n\n\n\n\nIs Hydroxychloroquine Safe During Pregnancy? Observations from Penn Medicine\n\n\nPreprint as a contribution from a rapid response exploration of hydroxychloroquine effects on pregnancy-related outcomes.\n\n\n\nResearch\n\n\nEHR\n\n\ncovid-19\n\n\nmedications\n\n\npregnancy\n\n\nEnglish\n\n\npreprint\n\n\n\n\n\n\nMay 6, 2020\n\n\nLena Davidson, Silvia P. Canel√≥n, Mary Regina Boland\n\n\n\n\n\n\n\nA Systematic Literature Review of Factors Affecting the Timing of Menarche: The Potential for Climate Change to Impact Women‚Äôs Health\n\n\nReview paper highlighting how climate change could impact the timing of first menstruation and increase the burden of disease.\n\n\n\nResearch\n\n\nclimate change\n\n\nmenstruation\n\n\n\n\n\n\nMar 5, 2020\n\n\nSilvia P. Canel√≥n, Mary Regina Boland\n\n\n\n\n\n\n\nInvestigating Pregnancy-Related Health Outcomes Among Patients with Sickle Cell Disease and Linking with Health Disparities\n\n\nPoster presented at the 2019 American Medical Informatics Association Annual Symposium held November 16th-20th in Washington D.C.\n\n\n\nResearch\n\n\npregnancy\n\n\nAMIA\n\n\nEHR\n\n\nsickle cell disease\n\n\n\n\n\n\nNov 20, 2019\n\n\nSilvia P. Canel√≥n, Mary Regina Boland\n\n\n\n\n\n\n\nSubstrate Strain Mitigates Effects of Œ≤-Aminopropionitrile-Induced Reduction in Enzymatic Crosslinking\n\n\nResearch highlighting how the effects of BAPN on type I collagen, produced by osteoblasts, were mitigated by mechanical loading.\n\n\n\nResearch\n\n\nosteoblasts\n\n\nType I collagen\n\n\nBAPN\n\n\nAFM\n\n\ncrosslinking\n\n\nmechanical loading\n\n\n\n\n\n\nSep 3, 2019\n\n\nSilvia P. Canel√≥n, Joseph M. Wallace\n\n\n\n\n\n\n\nCharacterization of Type I Collagen and Osteoblast Response to Mechanical Loading\n\n\nDissertation completed as part of the requirements for a doctorate degree in Biomedical Engineering.\n\n\n\nResearch\n\n\nosteoblasts\n\n\nType I collagen\n\n\nBAPN\n\n\nAFM\n\n\ncrosslinking\n\n\nmechanical loading\n\n\n\n\n\n\nMay 1, 2018\n\n\nSilvia P. Canel√≥n\n\n\n\n\n\n\n\nŒ≤-Aminopropionitrile-Induced Reduction in Enzymatic Crosslinking Causes In Vitro Changes in Collagen Morphology and Molecular Composition\n\n\nPublication highlighting how a reduction in enzymatic crosslinking alters type I collagen morphology through an increase in D-spacing.\n\n\n\nResearch\n\n\nosteoblasts\n\n\nType I collagen\n\n\nBAPN\n\n\nAFM\n\n\ncrosslinking\n\n\n\n\n\n\nNov 6, 2016\n\n\nSilvia P. Canel√≥n, Joseph M. Wallace\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "publication/2018-05-01-dissertation/index.html",
    "href": "publication/2018-05-01-dissertation/index.html",
    "title": "Characterization of Type I Collagen and Osteoblast Response to Mechanical Loading",
    "section": "",
    "text": "Bone is a composite material made up of an inorganic (hydroxyapatite mineral) phase, a proteinaceous organic phase, and water. Comprising 90% of bone‚Äôs organic phase, type I collagen is the most abundant protein in the human body. Both hydroxyapatite and collagen contribute to bone mechanical properties, and because bone is a hierarchical material, changes in properties of either phase can influence bulk mechanical properties of the tissue and bone structure. Type I collagen in bone is synthesized by osteoblasts as a helical structure formed from three polypeptide chains of amino acids. These molecules are staggered into an array and the resulting collagen fibrils are stabilized by crosslinks. Enzymatic crosslinking can be limited by compounds such as Œ≤-aminopropionitrile (BAPN) and result in a crosslink deficiency characterizing a disease known as lathyrism. BAPN acts by irreversibly binding to the active site of the lysyl oxidase enzyme, blocking the formation of new crosslinks and the maturation of pre-existing immature crosslinks. Understanding how changes in bone properties on a cellular level transcend levels of bone hierarchy provides an opportunity to detect or diagnose bone disease before disease-related changes are expressed at the organ or tissue level. This dissertation studies the in vitro effect of BAPN-induced enzymatic crosslink reduction on osteoblast-produced collagen nanostructure, mechanical properties, crosslink ratio, and expression of genes related to type I collagen synthesis and crosslinking. The work also explores the effect of mechanical loading via applied substrate strain on these properties to investigate its potential compensatory impact."
  },
  {
    "objectID": "publication/2018-05-01-dissertation/index.html#abstract",
    "href": "publication/2018-05-01-dissertation/index.html#abstract",
    "title": "Characterization of Type I Collagen and Osteoblast Response to Mechanical Loading",
    "section": "",
    "text": "Bone is a composite material made up of an inorganic (hydroxyapatite mineral) phase, a proteinaceous organic phase, and water. Comprising 90% of bone‚Äôs organic phase, type I collagen is the most abundant protein in the human body. Both hydroxyapatite and collagen contribute to bone mechanical properties, and because bone is a hierarchical material, changes in properties of either phase can influence bulk mechanical properties of the tissue and bone structure. Type I collagen in bone is synthesized by osteoblasts as a helical structure formed from three polypeptide chains of amino acids. These molecules are staggered into an array and the resulting collagen fibrils are stabilized by crosslinks. Enzymatic crosslinking can be limited by compounds such as Œ≤-aminopropionitrile (BAPN) and result in a crosslink deficiency characterizing a disease known as lathyrism. BAPN acts by irreversibly binding to the active site of the lysyl oxidase enzyme, blocking the formation of new crosslinks and the maturation of pre-existing immature crosslinks. Understanding how changes in bone properties on a cellular level transcend levels of bone hierarchy provides an opportunity to detect or diagnose bone disease before disease-related changes are expressed at the organ or tissue level. This dissertation studies the in vitro effect of BAPN-induced enzymatic crosslink reduction on osteoblast-produced collagen nanostructure, mechanical properties, crosslink ratio, and expression of genes related to type I collagen synthesis and crosslinking. The work also explores the effect of mechanical loading via applied substrate strain on these properties to investigate its potential compensatory impact."
  },
  {
    "objectID": "publication/2021-04-08-smm-individual-neighborhood/index.html",
    "href": "publication/2021-04-08-smm-individual-neighborhood/index.html",
    "title": "Individual-Level and Neighborhood-Level Risk Factors for Severe Maternal Morbidity",
    "section": "",
    "text": "Objective: To investigate the association between individual-level and neighborhood-level risk factors and severe maternal morbidity.\nMethods: This was a retrospective cohort study of all pregnancies delivered between 2010 and 2017 in the University of Pennsylvania Health System. International Classification of Diseases codes classified severe maternal morbidity according to the Centers for Disease Control and Prevention guidelines. Logistic regression modeling evaluated individual-level risk factors for severe maternal morbidity, such as maternal age and preeclampsia diagnosis. Additionally, we used spatial autoregressive modeling to assess Census-tract, neighborhood-level risk factors for severe maternal morbidity such as violent crime and poverty.\nResults: Overall, 63,334 pregnancies were included, with a severe maternal morbidity rate of 2.73%, or 272 deliveries with severe maternal morbidity per 10,000 delivery hospitalizations. In our multivariable model assessing individual-level risk factors for severe maternal morbidity, the magnitude of risk was highest for patients with a cesarean delivery (adjusted odds ratio [aOR] 3.50, 95% CI 3.15-3.89), stillbirth (aOR 4.60, 95% CI 3.31-6.24), and preeclampsia diagnosis (aOR 2.71, 95% CI 2.41-3.03). Identifying as White was associated with lower odds of severe maternal morbidity at delivery (aOR 0.73, 95% CI 0.61-0.87). In our final multivariable model assessing neighborhood-level risk factors for severe maternal morbidity, the rate of severe maternal morbidity increased by 2.4% (95% CI 0.37-4.4%) with every 10% increase in the percentage of individuals in a Census tract who identified as Black or African American when accounting for the number of violent crimes and percentage of people identifying as White.\nConclusion: Both individual-level and neighborhood-level risk factors were associated with severe maternal morbidity. These factors may contribute to rising severe maternal morbidity rates in the United States. Better characterization of risk factors for severe maternal morbidity is imperative for the design of clinical and public health interventions seeking to lower rates of severe maternal morbidity and maternal mortality."
  },
  {
    "objectID": "publication/2021-04-08-smm-individual-neighborhood/index.html#abstract",
    "href": "publication/2021-04-08-smm-individual-neighborhood/index.html#abstract",
    "title": "Individual-Level and Neighborhood-Level Risk Factors for Severe Maternal Morbidity",
    "section": "",
    "text": "Objective: To investigate the association between individual-level and neighborhood-level risk factors and severe maternal morbidity.\nMethods: This was a retrospective cohort study of all pregnancies delivered between 2010 and 2017 in the University of Pennsylvania Health System. International Classification of Diseases codes classified severe maternal morbidity according to the Centers for Disease Control and Prevention guidelines. Logistic regression modeling evaluated individual-level risk factors for severe maternal morbidity, such as maternal age and preeclampsia diagnosis. Additionally, we used spatial autoregressive modeling to assess Census-tract, neighborhood-level risk factors for severe maternal morbidity such as violent crime and poverty.\nResults: Overall, 63,334 pregnancies were included, with a severe maternal morbidity rate of 2.73%, or 272 deliveries with severe maternal morbidity per 10,000 delivery hospitalizations. In our multivariable model assessing individual-level risk factors for severe maternal morbidity, the magnitude of risk was highest for patients with a cesarean delivery (adjusted odds ratio [aOR] 3.50, 95% CI 3.15-3.89), stillbirth (aOR 4.60, 95% CI 3.31-6.24), and preeclampsia diagnosis (aOR 2.71, 95% CI 2.41-3.03). Identifying as White was associated with lower odds of severe maternal morbidity at delivery (aOR 0.73, 95% CI 0.61-0.87). In our final multivariable model assessing neighborhood-level risk factors for severe maternal morbidity, the rate of severe maternal morbidity increased by 2.4% (95% CI 0.37-4.4%) with every 10% increase in the percentage of individuals in a Census tract who identified as Black or African American when accounting for the number of violent crimes and percentage of people identifying as White.\nConclusion: Both individual-level and neighborhood-level risk factors were associated with severe maternal morbidity. These factors may contribute to rising severe maternal morbidity rates in the United States. Better characterization of risk factors for severe maternal morbidity is imperative for the design of clinical and public health interventions seeking to lower rates of severe maternal morbidity and maternal mortality."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Send me a note ",
    "section": "",
    "text": "Send me a note \nYou can use this form to contact me about speaking engagements, collaborations, or simply to say hello.\nI also love hearing if my educational materials have been helpful for you, and how they could be improved ‚Äî particularly if they could be made more accessible \n      \n\n\n\n\n\n\n\n\nFull Name \nEmail Address \nMessage\n\n\nSend message\n\n\n\n\n\nSign-up for my newsletter \nYou can use this form to sign up to receive a little e-mail note from me anytime I post something new on my website.\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "publication/2022-03-09-ppd-ontology/index.html",
    "href": "publication/2022-03-09-ppd-ontology/index.html",
    "title": "Design and Evaluation of a Postpartum Depression Ontology",
    "section": "",
    "text": "Objective. Postpartum depression (PPD) remains an understudied research area despite its high prevalence. The goal of this study is to develop an ontology to aid in the identification of patients with PPD and to enable future analyses with electronic health record (EHR) data.\nMethods. We used Prot√©g√©-OWL to construct a postpartum depression ontology (PDO) of relevant comorbidities, symptoms, treatments, and other items pertinent to the study and treatment of PPD.\nResults. The PDO identifies and visualizes the risk factor status of variables for PPD, including comorbidities, confounders, symptoms, and treatments. The PDO includes 734 classes, 13 object properties, and 4,844 individuals. We also linked known and potential risk factors to their respective codes in the International Classification of Diseases versions 9 and 10 that would be useful in structured EHR data analyses. The representation and usefulness of the PDO was assessed using a task-based patient case study approach, involving 10 PPD case studies. Final evaluation of the ontology yielded 86.4% coverage of PPD symptoms, treatments, and risk factors. This demonstrates strong coverage of the PDO for the PPD domain.\nConclusion. The PDO will enable future researchers to study PPD using EHR data as it contains important information with regard to structured (e.g., billing codes) and unstructured data (e.g., synonyms of symptoms not coded in EHRs). The PDO is publicly available through the National Center for Biomedical Ontology (NCBO) BioPortal (https://bioportal.bioontology.org/ontologies/PARTUMDO) which will enable other informaticists to utilize the PDO to study PPD in other populations.\n\n\n\nA graphical overview of the Postpartum Depression Ontology Superclasses and Direct Subclasses of the Ontology."
  },
  {
    "objectID": "publication/2022-03-09-ppd-ontology/index.html#abstract",
    "href": "publication/2022-03-09-ppd-ontology/index.html#abstract",
    "title": "Design and Evaluation of a Postpartum Depression Ontology",
    "section": "",
    "text": "Objective. Postpartum depression (PPD) remains an understudied research area despite its high prevalence. The goal of this study is to develop an ontology to aid in the identification of patients with PPD and to enable future analyses with electronic health record (EHR) data.\nMethods. We used Prot√©g√©-OWL to construct a postpartum depression ontology (PDO) of relevant comorbidities, symptoms, treatments, and other items pertinent to the study and treatment of PPD.\nResults. The PDO identifies and visualizes the risk factor status of variables for PPD, including comorbidities, confounders, symptoms, and treatments. The PDO includes 734 classes, 13 object properties, and 4,844 individuals. We also linked known and potential risk factors to their respective codes in the International Classification of Diseases versions 9 and 10 that would be useful in structured EHR data analyses. The representation and usefulness of the PDO was assessed using a task-based patient case study approach, involving 10 PPD case studies. Final evaluation of the ontology yielded 86.4% coverage of PPD symptoms, treatments, and risk factors. This demonstrates strong coverage of the PDO for the PPD domain.\nConclusion. The PDO will enable future researchers to study PPD using EHR data as it contains important information with regard to structured (e.g., billing codes) and unstructured data (e.g., synonyms of symptoms not coded in EHRs). The PDO is publicly available through the National Center for Biomedical Ontology (NCBO) BioPortal (https://bioportal.bioontology.org/ontologies/PARTUMDO) which will enable other informaticists to utilize the PDO to study PPD in other populations.\n\n\n\nA graphical overview of the Postpartum Depression Ontology Superclasses and Direct Subclasses of the Ontology."
  },
  {
    "objectID": "publication/2020-03-05-climate-change-menarche/index.html",
    "href": "publication/2020-03-05-climate-change-menarche/index.html",
    "title": "A Systematic Literature Review of Factors Affecting the Timing of Menarche: The Potential for Climate Change to Impact Women‚Äôs Health",
    "section": "",
    "text": "Menarche is the first occurrence of a woman‚Äôs menstruation, an event that symbolizes reproductive capacity and the transition from childhood into womanhood. The global average age for menarche is 12 years and this has been declining in recent years. Many factors that affect the timing menarche in girls could be affected by climate change. A systematic literature review was performed regarding the timing of menarche and four publication databases were interrogated: EMBASE, SCOPUS, PubMed, and Cochrane Reviews. Themes were identified from 112 articles and related to environmental causes of perturbations in menarche (either early or late), disease causes and consequences of perturbations, and social causes and consequences. Research from climatology was incorporated to describe how climate change events, including increased hurricanes, avalanches/mudslides/landslides, and extreme weather events could alter the age of menarche by disrupting food availability or via increased toxin/pollutant release. Overall, our review revealed that these perturbations in the timing of menarche are likely to increase the disease burden for women in four key areas: mental health, fertility-related conditions, cardiovascular disease, and bone health. In summary, the climate does have the potential to impact women‚Äôs health through perturbation in the timing of menarche and this, in turn, will affect women‚Äôs risk of disease in future."
  },
  {
    "objectID": "publication/2020-03-05-climate-change-menarche/index.html#abstract",
    "href": "publication/2020-03-05-climate-change-menarche/index.html#abstract",
    "title": "A Systematic Literature Review of Factors Affecting the Timing of Menarche: The Potential for Climate Change to Impact Women‚Äôs Health",
    "section": "",
    "text": "Menarche is the first occurrence of a woman‚Äôs menstruation, an event that symbolizes reproductive capacity and the transition from childhood into womanhood. The global average age for menarche is 12 years and this has been declining in recent years. Many factors that affect the timing menarche in girls could be affected by climate change. A systematic literature review was performed regarding the timing of menarche and four publication databases were interrogated: EMBASE, SCOPUS, PubMed, and Cochrane Reviews. Themes were identified from 112 articles and related to environmental causes of perturbations in menarche (either early or late), disease causes and consequences of perturbations, and social causes and consequences. Research from climatology was incorporated to describe how climate change events, including increased hurricanes, avalanches/mudslides/landslides, and extreme weather events could alter the age of menarche by disrupting food availability or via increased toxin/pollutant release. Overall, our review revealed that these perturbations in the timing of menarche are likely to increase the disease burden for women in four key areas: mental health, fertility-related conditions, cardiovascular disease, and bone health. In summary, the climate does have the potential to impact women‚Äôs health through perturbation in the timing of menarche and this, in turn, will affect women‚Äôs risk of disease in future."
  },
  {
    "objectID": "publication/2021-08-11-ehr-environmental-exposure-pfas/index.html",
    "href": "publication/2021-08-11-ehr-environmental-exposure-pfas/index.html",
    "title": "Harnessing electronic health records to study emerging environmental disasters: a proof of concept with perfluoroalkyl substances (PFAS)",
    "section": "",
    "text": "Environmental disasters are anthropogenic catastrophic events that affect health. Famous disasters include the Seveso disaster and the Fukushima-Daiichi nuclear meltdown, which had disastrous health consequences. Traditional methods for studying environmental disasters are costly and time-intensive. We propose the use of electronic health records (EHR) and informatics methods to study the health effects of emergent environmental disasters in a cost-effective manner. An emergent environmental disaster is exposure to perfluoroalkyl substances (PFAS) in the Philadelphia area. Penn Medicine (PennMed) comprises multiple hospitals and facilities within the Philadelphia Metropolitan area, including over three thousand PFAS-exposed women living in one of the highest PFAS exposure areas nationwide. We developed a high-throughput method that utilizes only EHR data to evaluate the disease risk in this heavily exposed population. We replicated all five disease/conditions implicated by PFAS exposure, including hypercholesterolemia, thyroid disease, proteinuria, kidney disease and colitis, either directly or via closely related diagnoses. Using EHRs coupled with informatics enables the health impacts of environmental disasters to be more easily studied in large cohorts versus traditional methods that rely on interviews and expensive serum-based testing. By reducing cost and increasing the diversity of individuals included in studies, we can overcome many of the hurdles faced by previous studies, including a lack of racial and ethnic diversity. This proof-of-concept study confirms that EHRs can be used to study human health and disease impacts of environmental disasters and produces equivalent disease-exposure knowledge to prospective epidemiology studies while remaining cost-effective.\n\n\n\nHorsham-Warminster-Warrington area PFAS exposure timeline"
  },
  {
    "objectID": "publication/2021-08-11-ehr-environmental-exposure-pfas/index.html#abstract",
    "href": "publication/2021-08-11-ehr-environmental-exposure-pfas/index.html#abstract",
    "title": "Harnessing electronic health records to study emerging environmental disasters: a proof of concept with perfluoroalkyl substances (PFAS)",
    "section": "",
    "text": "Environmental disasters are anthropogenic catastrophic events that affect health. Famous disasters include the Seveso disaster and the Fukushima-Daiichi nuclear meltdown, which had disastrous health consequences. Traditional methods for studying environmental disasters are costly and time-intensive. We propose the use of electronic health records (EHR) and informatics methods to study the health effects of emergent environmental disasters in a cost-effective manner. An emergent environmental disaster is exposure to perfluoroalkyl substances (PFAS) in the Philadelphia area. Penn Medicine (PennMed) comprises multiple hospitals and facilities within the Philadelphia Metropolitan area, including over three thousand PFAS-exposed women living in one of the highest PFAS exposure areas nationwide. We developed a high-throughput method that utilizes only EHR data to evaluate the disease risk in this heavily exposed population. We replicated all five disease/conditions implicated by PFAS exposure, including hypercholesterolemia, thyroid disease, proteinuria, kidney disease and colitis, either directly or via closely related diagnoses. Using EHRs coupled with informatics enables the health impacts of environmental disasters to be more easily studied in large cohorts versus traditional methods that rely on interviews and expensive serum-based testing. By reducing cost and increasing the diversity of individuals included in studies, we can overcome many of the hurdles faced by previous studies, including a lack of racial and ethnic diversity. This proof-of-concept study confirms that EHRs can be used to study human health and disease impacts of environmental disasters and produces equivalent disease-exposure knowledge to prospective epidemiology studies while remaining cost-effective.\n\n\n\nHorsham-Warminster-Warrington area PFAS exposure timeline"
  },
  {
    "objectID": "publication/2022-06-07-mwas-multiple-birth/index.html",
    "href": "publication/2022-06-07-mwas-multiple-birth/index.html",
    "title": "Medication-Wide Association Study Using Electronic Health Record Data of Prescription Medication Exposure and Multifetal Pregnancies: Retrospective Study",
    "section": "",
    "text": "Background. Medication-wide association studies (MWAS) have been applied to assess the risk of individual prescription use and a wide range of health outcomes, including cancer, acute myocardial infarction, acute liver failure, acute renal failure, and upper gastrointestinal ulcers. Current literature on the use of preconception and periconception medication and its association with the risk of multiple gestation pregnancies (eg, monozygotic and dizygotic) is largely based on assisted reproductive technology (ART) cohorts. However, among non-ART pregnancies, it is unknown whether other medications increase the risk of multifetal pregnancies.\nObjective. This study aimed to investigate the risk of multiple gestational births (eg., twins and triplets) following preconception and periconception exposure to prescription medications in patients who delivered at Penn Medicine.\nMethods. We used electronic health record data between 2010 and 2017 on patients who delivered babies at Penn Medicine, a health care system in the Greater Philadelphia area. We explored 3 logistic regression models: model 1 (no adjustment); model 2 (adjustment for maternal age); and model 3‚Äîour final logistic regression model (adjustment for maternal age, ART use, and infertility diagnosis). In all models, multiple births (MBs) were our outcome of interest (binary outcome), and each medication was assessed separately as a binary variable. To assess our MWAS model performance, we defined ART medications as our gold standard, given that these medications are known to increase the risk of MB.\nResults. Of the 63,334 distinct deliveries in our cohort, only 1877 pregnancies (2.96%) were prescribed any medication during the preconception and first trimester period. Of the 123 medications prescribed, we found 26 (21.1%) medications associated with MB (using nominal P values) and 10 (8.1%) medications associated with MB (using Bonferroni adjustment) in fully adjusted model 3. We found that our model 3 algorithm had an accuracy of 85% (using nominal P values) and 89% (using Bonferroni-adjusted P values).\nConclusions. Our work demonstrates the opportunities in applying the MWAS approach with electronic health record data to explore associations between preconception and periconception medication exposure and the risk of MB while identifying novel candidate medications for further study. Overall, we found 3 novel medications linked with MB that could be explored in further work; this demonstrates the potential of our method to be used for hypothesis generation.\n\n\n\nA graphical overview of the medication-wide association study analyses on multiple birth."
  },
  {
    "objectID": "publication/2022-06-07-mwas-multiple-birth/index.html#abstract",
    "href": "publication/2022-06-07-mwas-multiple-birth/index.html#abstract",
    "title": "Medication-Wide Association Study Using Electronic Health Record Data of Prescription Medication Exposure and Multifetal Pregnancies: Retrospective Study",
    "section": "",
    "text": "Background. Medication-wide association studies (MWAS) have been applied to assess the risk of individual prescription use and a wide range of health outcomes, including cancer, acute myocardial infarction, acute liver failure, acute renal failure, and upper gastrointestinal ulcers. Current literature on the use of preconception and periconception medication and its association with the risk of multiple gestation pregnancies (eg, monozygotic and dizygotic) is largely based on assisted reproductive technology (ART) cohorts. However, among non-ART pregnancies, it is unknown whether other medications increase the risk of multifetal pregnancies.\nObjective. This study aimed to investigate the risk of multiple gestational births (eg., twins and triplets) following preconception and periconception exposure to prescription medications in patients who delivered at Penn Medicine.\nMethods. We used electronic health record data between 2010 and 2017 on patients who delivered babies at Penn Medicine, a health care system in the Greater Philadelphia area. We explored 3 logistic regression models: model 1 (no adjustment); model 2 (adjustment for maternal age); and model 3‚Äîour final logistic regression model (adjustment for maternal age, ART use, and infertility diagnosis). In all models, multiple births (MBs) were our outcome of interest (binary outcome), and each medication was assessed separately as a binary variable. To assess our MWAS model performance, we defined ART medications as our gold standard, given that these medications are known to increase the risk of MB.\nResults. Of the 63,334 distinct deliveries in our cohort, only 1877 pregnancies (2.96%) were prescribed any medication during the preconception and first trimester period. Of the 123 medications prescribed, we found 26 (21.1%) medications associated with MB (using nominal P values) and 10 (8.1%) medications associated with MB (using Bonferroni adjustment) in fully adjusted model 3. We found that our model 3 algorithm had an accuracy of 85% (using nominal P values) and 89% (using Bonferroni-adjusted P values).\nConclusions. Our work demonstrates the opportunities in applying the MWAS approach with electronic health record data to explore associations between preconception and periconception medication exposure and the risk of MB while identifying novel candidate medications for further study. Overall, we found 3 novel medications linked with MB that could be explored in further work; this demonstrates the potential of our method to be used for hypothesis generation.\n\n\n\nA graphical overview of the medication-wide association study analyses on multiple birth."
  },
  {
    "objectID": "publication/2021-05-11-geospatial-analysis-pregnancy-outcomes/index.html",
    "href": "publication/2021-05-11-geospatial-analysis-pregnancy-outcomes/index.html",
    "title": "A Bayesian Hierarchical Modeling Framework for Geospatial Analysis of Adverse Pregnancy Outcomes",
    "section": "",
    "text": "Studying the determinants of adverse pregnancy outcomes like stillbirth and preterm birth is of considerable interest in epidemiology. Understanding the role of both individual and community risk factors for these outcomes is crucial for planning appropriate clinical and public health interventions. With this goal, we develop geospatial mixed effects logistic regression models for adverse pregnancy outcomes. Our models account for both spatial autocorrelation and heterogeneity between neighborhoods. To mitigate the low incidence of stillbirth and preterm births in our data, we explore using class rebalancing techniques to improve predictive power. To assess the informative value of the covariates in our models, we use posterior distributions of their coefficients to gauge how well they can be distinguished from zero. As a case study, we model stillbirth and preterm birth in the city of Philadelphia, incorporating both patient-level data from electronic health records (EHR) data and publicly available neighborhood data at the census tract level. We find that patient-level features like self-identified race and ethnicity were highly informative for both outcomes. Neighborhood-level factors were also informative, with poverty important for stillbirth and crime important for preterm birth. Finally, we identify the neighborhoods in Philadelphia at highest risk of stillbirth and preterm birth."
  },
  {
    "objectID": "publication/2021-05-11-geospatial-analysis-pregnancy-outcomes/index.html#abstract",
    "href": "publication/2021-05-11-geospatial-analysis-pregnancy-outcomes/index.html#abstract",
    "title": "A Bayesian Hierarchical Modeling Framework for Geospatial Analysis of Adverse Pregnancy Outcomes",
    "section": "",
    "text": "Studying the determinants of adverse pregnancy outcomes like stillbirth and preterm birth is of considerable interest in epidemiology. Understanding the role of both individual and community risk factors for these outcomes is crucial for planning appropriate clinical and public health interventions. With this goal, we develop geospatial mixed effects logistic regression models for adverse pregnancy outcomes. Our models account for both spatial autocorrelation and heterogeneity between neighborhoods. To mitigate the low incidence of stillbirth and preterm births in our data, we explore using class rebalancing techniques to improve predictive power. To assess the informative value of the covariates in our models, we use posterior distributions of their coefficients to gauge how well they can be distinguished from zero. As a case study, we model stillbirth and preterm birth in the city of Philadelphia, incorporating both patient-level data from electronic health records (EHR) data and publicly available neighborhood data at the census tract level. We find that patient-level features like self-identified race and ethnicity were highly informative for both outcomes. Neighborhood-level factors were also informative, with poverty important for stillbirth and crime important for preterm birth. Finally, we identify the neighborhoods in Philadelphia at highest risk of stillbirth and preterm birth."
  },
  {
    "objectID": "publication/2016-11-06-bapn-morphology/index.html",
    "href": "publication/2016-11-06-bapn-morphology/index.html",
    "title": "Œ≤-Aminopropionitrile-Induced Reduction in Enzymatic Crosslinking Causes In Vitro Changes in Collagen Morphology and Molecular Composition",
    "section": "",
    "text": "Type I collag een morphology can be characterized using fibril D-spacing, a metric which describes the periodicity of repeating bands of gap and overlap regions of collagen molecules arranged into collagen fibrils. This fibrillar structure is stabilized by enzymatic crosslinks initiated by lysyl oxidase (LOX), a step which can be disrupted using Œ≤-aminopropionitrile (BAPN). Murine in vivo studies have confirmed effects of BAPN on collagen nanostructure and the objective of this study was to evaluate the mechanism of these effects in vitro by measuring D-spacing, evaluating the ratio of mature to immature crosslinks, and quantifying gene expression of type I collagen and LOX. Osteoblasts were cultured in complete media, and differentiated using ascorbic acid, in the presence or absence of 0.25mM BAPN-fumarate. The matrix produced was imaged using atomic force microscopy (AFM) and 2D Fast Fourier transforms were performed to extract D-spacing from individual fibrils. The experiment was repeated for quantitative reverse transcription polymerase chain reaction (qRT-PCR) and Fourier Transform infrared spectroscopy (FTIR) analyses. The D-spacing distribution of collagen produced in the presence of BAPN was shifted toward higher D-spacing values, indicating BAPN affects the morphology of collagen produced in vitro, supporting aforementioned in vivo experiments. In contrast, no difference in gene expression was found for any target gene, suggesting LOX inhibition does not upregulate the LOX gene to compensate for the reduction in aldehyde formation, or regulate expression of genes encoding type I collagen. Finally, the mature to immature crosslink ratio decreased with BAPN treatment and was linked to a reduction in peak percent area of mature crosslink hydroxylysylpyridinoline (HP). In conclusion, in vitro treatment of osteoblasts with low levels of BAPN did not induce changes in genes encoding LOX or type I collagen, but led to an increase in collagen D-spacing as well as a decrease in mature crosslinks."
  },
  {
    "objectID": "publication/2016-11-06-bapn-morphology/index.html#abstract",
    "href": "publication/2016-11-06-bapn-morphology/index.html#abstract",
    "title": "Œ≤-Aminopropionitrile-Induced Reduction in Enzymatic Crosslinking Causes In Vitro Changes in Collagen Morphology and Molecular Composition",
    "section": "",
    "text": "Type I collag een morphology can be characterized using fibril D-spacing, a metric which describes the periodicity of repeating bands of gap and overlap regions of collagen molecules arranged into collagen fibrils. This fibrillar structure is stabilized by enzymatic crosslinks initiated by lysyl oxidase (LOX), a step which can be disrupted using Œ≤-aminopropionitrile (BAPN). Murine in vivo studies have confirmed effects of BAPN on collagen nanostructure and the objective of this study was to evaluate the mechanism of these effects in vitro by measuring D-spacing, evaluating the ratio of mature to immature crosslinks, and quantifying gene expression of type I collagen and LOX. Osteoblasts were cultured in complete media, and differentiated using ascorbic acid, in the presence or absence of 0.25mM BAPN-fumarate. The matrix produced was imaged using atomic force microscopy (AFM) and 2D Fast Fourier transforms were performed to extract D-spacing from individual fibrils. The experiment was repeated for quantitative reverse transcription polymerase chain reaction (qRT-PCR) and Fourier Transform infrared spectroscopy (FTIR) analyses. The D-spacing distribution of collagen produced in the presence of BAPN was shifted toward higher D-spacing values, indicating BAPN affects the morphology of collagen produced in vitro, supporting aforementioned in vivo experiments. In contrast, no difference in gene expression was found for any target gene, suggesting LOX inhibition does not upregulate the LOX gene to compensate for the reduction in aldehyde formation, or regulate expression of genes encoding type I collagen. Finally, the mature to immature crosslink ratio decreased with BAPN treatment and was linked to a reduction in peak percent area of mature crosslink hydroxylysylpyridinoline (HP). In conclusion, in vitro treatment of osteoblasts with low levels of BAPN did not induce changes in genes encoding LOX or type I collagen, but led to an increase in collagen D-spacing as well as a decrease in mature crosslinks."
  },
  {
    "objectID": "publication/2019-12-01-bapn-substrate-strain/index.html",
    "href": "publication/2019-12-01-bapn-substrate-strain/index.html",
    "title": "Substrate Strain Mitigates Effects of Œ≤-Aminopropionitrile-Induced Reduction in Enzymatic Crosslinking",
    "section": "",
    "text": "Enzymatic crosslinks stabilize type I collagen and are catalyzed by lysyl oxidase (LOX), a step interrupted through Œ≤-aminopropionitrile (BAPN) exposure. This study evaluated dose-dependent effects of BAPN on osteoblast gene expression of type I collagen, LOX, and genes associated with crosslink formation. The second objective was to characterize collagen produced in vitro after exposure to BAPN, and to explore changes to collagen properties under continuous cyclical substrate strain. To evaluate dose-dependent effects, osteoblasts were exposed to a range of BAPN dosages (0‚Äì10 mM) for gene expression analysis and cell proliferation. Results showed significant upregulation of BMP-1, POST, and COL1A1 and change in cell proliferation. Results also showed that while the gene encoding LOX was unaffected by BAPN treatment, other genes related to LOX activation and matrix production were upregulated. For the loading study, the combined effects of BAPN and mechanical loading were assessed. Gene expression was quantified, atomic force microscopy was used to extract elastic properties of the collagen matrix, and Fourier Transform infrared spectroscopy was used to assess collagen secondary structure for enzymatic crosslinking analysis. BAPN upregulated BMP-1 in static samples and BAPN combined with mechanical loading downregulated LOX when compared to control-static samples. Results showed a higher indentation modulus in BAPN-loaded samples compared to control-loaded samples. Loading increased the mature-to-immature crosslink ratios in control samples, and BAPN increased the height ratio in static samples. In summary, effects of BAPN (upregulation of genes involved in crosslinking, mature/immature crosslinking ratios, upward trend in collagen elasticity) were mitigated by mechanical loading."
  },
  {
    "objectID": "publication/2019-12-01-bapn-substrate-strain/index.html#abstract",
    "href": "publication/2019-12-01-bapn-substrate-strain/index.html#abstract",
    "title": "Substrate Strain Mitigates Effects of Œ≤-Aminopropionitrile-Induced Reduction in Enzymatic Crosslinking",
    "section": "",
    "text": "Enzymatic crosslinks stabilize type I collagen and are catalyzed by lysyl oxidase (LOX), a step interrupted through Œ≤-aminopropionitrile (BAPN) exposure. This study evaluated dose-dependent effects of BAPN on osteoblast gene expression of type I collagen, LOX, and genes associated with crosslink formation. The second objective was to characterize collagen produced in vitro after exposure to BAPN, and to explore changes to collagen properties under continuous cyclical substrate strain. To evaluate dose-dependent effects, osteoblasts were exposed to a range of BAPN dosages (0‚Äì10 mM) for gene expression analysis and cell proliferation. Results showed significant upregulation of BMP-1, POST, and COL1A1 and change in cell proliferation. Results also showed that while the gene encoding LOX was unaffected by BAPN treatment, other genes related to LOX activation and matrix production were upregulated. For the loading study, the combined effects of BAPN and mechanical loading were assessed. Gene expression was quantified, atomic force microscopy was used to extract elastic properties of the collagen matrix, and Fourier Transform infrared spectroscopy was used to assess collagen secondary structure for enzymatic crosslinking analysis. BAPN upregulated BMP-1 in static samples and BAPN combined with mechanical loading downregulated LOX when compared to control-static samples. Results showed a higher indentation modulus in BAPN-loaded samples compared to control-loaded samples. Loading increased the mature-to-immature crosslink ratios in control samples, and BAPN increased the height ratio in static samples. In summary, effects of BAPN (upregulation of genes involved in crosslinking, mature/immature crosslinking ratios, upward trend in collagen elasticity) were mitigated by mechanical loading."
  },
  {
    "objectID": "publication/2022-07-21-ten-simple-rules-inclusive-conference/index.html",
    "href": "publication/2022-07-21-ten-simple-rules-inclusive-conference/index.html",
    "title": "Ten simple rules to host an inclusive conference",
    "section": "",
    "text": "Conferences are spaces to meet and network within and across academic and technical fields, learn about new advances, and share our work. They can help define career paths and create long-lasting collaborations and opportunities. However, these opportunities are not equal for all. This article introduces 10 simple rules to host an inclusive conference based on the authors‚Äô recent experience organizing the 2021 edition of the useR! statistical computing conference, which attracted a broad range of participants from academia, industry, government, and the nonprofit sector. Coming from different backgrounds, career stages, and even continents, we embraced the challenge of organizing a high-quality virtual conference in the context of the Coronavirus Disease 2019 (COVID-19) pandemic and making it a kind, inclusive, and accessible experience for as many people as possible. The rules result from our lessons learned before, during, and after the organization of the conference. They have been written mainly for potential organizers and selection committees of conferences and contain multiple practical tips to help a variety of events become more accessible and inclusive. We see this as a starting point for conversations and efforts towards building more inclusive conferences across the world. * Translated versions of the English abstract and the list of rules are available in 10 languages in S1 Text: Arabic, French, German, Italian, Japanese, Korean, Portuguese, Spanish, Tamil, and Thai.\n\n\n\nSchematic diagram of the rules organized in 3 groups: foundation (Rules 1 to 3), design (Rules 4 to 9), and continuity (Rule 10)."
  },
  {
    "objectID": "publication/2022-07-21-ten-simple-rules-inclusive-conference/index.html#abstract",
    "href": "publication/2022-07-21-ten-simple-rules-inclusive-conference/index.html#abstract",
    "title": "Ten simple rules to host an inclusive conference",
    "section": "",
    "text": "Conferences are spaces to meet and network within and across academic and technical fields, learn about new advances, and share our work. They can help define career paths and create long-lasting collaborations and opportunities. However, these opportunities are not equal for all. This article introduces 10 simple rules to host an inclusive conference based on the authors‚Äô recent experience organizing the 2021 edition of the useR! statistical computing conference, which attracted a broad range of participants from academia, industry, government, and the nonprofit sector. Coming from different backgrounds, career stages, and even continents, we embraced the challenge of organizing a high-quality virtual conference in the context of the Coronavirus Disease 2019 (COVID-19) pandemic and making it a kind, inclusive, and accessible experience for as many people as possible. The rules result from our lessons learned before, during, and after the organization of the conference. They have been written mainly for potential organizers and selection committees of conferences and contain multiple practical tips to help a variety of events become more accessible and inclusive. We see this as a starting point for conversations and efforts towards building more inclusive conferences across the world. * Translated versions of the English abstract and the list of rules are available in 10 languages in S1 Text: Arabic, French, German, Italian, Japanese, Korean, Portuguese, Spanish, Tamil, and Thai.\n\n\n\nSchematic diagram of the rules organized in 3 groups: foundation (Rules 1 to 3), design (Rules 4 to 9), and continuity (Rule 10)."
  },
  {
    "objectID": "publication/2019-11-20-amia-annual-symposium/index.html",
    "href": "publication/2019-11-20-amia-annual-symposium/index.html",
    "title": "Investigating Pregnancy-Related Health Outcomes Among Patients with Sickle Cell Disease and Linking with Health Disparities",
    "section": "",
    "text": "Poster presented at the AMIA 2019 Annual Symposium\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Silvia Canel√≥n, PhD",
    "section": "",
    "text": "I am a researcher and R educator with a love for community. My research leverages electronic health record and spatial data to study the intersection of health equity and urban nature. My community projects value the partnership between open source tools and data literacy as a way to build power and effect change.\nLearn more about me ‚Üí\n\n    \n    \n  \n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "blog/2020-10-07-rstudio-instructor-certification-tidyverse/index.html",
    "href": "blog/2020-10-07-rstudio-instructor-certification-tidyverse/index.html",
    "title": "Becoming certified as an RStudio Tidyverse Instructor",
    "section": "",
    "text": "February 12th, 2021 was Greg Wilson‚Äôs last day at RStudio. This means he is no longer running the instructor training program, so the future of the program is unclear. You may want to contact traininginstructor@rstudio.com with any specific questions.\nYou can also jump down in this blog post to Teaching resources to find a consolidated list of materials previously taught as part of the RStudio certification program, in addition to some related resources (thanks to Yanina for adding to this list!).\nLastly, you may want to consider becoming certified through The Carpentries. Yanina Bellini Saibene (@yabellini) and Dorris Scott (@Dorris_Scott) are a couple of RStudio instructors that have also been certified through The Carpentries."
  },
  {
    "objectID": "blog/2020-10-07-rstudio-instructor-certification-tidyverse/index.html#asking-around",
    "href": "blog/2020-10-07-rstudio-instructor-certification-tidyverse/index.html#asking-around",
    "title": "Becoming certified as an RStudio Tidyverse Instructor",
    "section": "Asking around",
    "text": "Asking around\nIn the interest of making an informed decision, I asked a few instructors to share a bit about their experience with the certification process before I made the commitment.\n\nüá∫üá∏ Stephan Kadauke is a colleague I met through the Children‚Äôs Hospital of Philadelphia R User group. Specifically at an Intro to Machine Learning with the Tidyverse workshop led by Alison Hill.\n\nI met these wonderful people through the R-Ladies Global Slack workspace:\n\nüá¶üá∑ Yanina Bellini Saibene shared her experience with this process in her blog post Obtaining RStudio certification. A shared path.\nüáßüá¥ üá≥üá± Paloma Rojas-Saunero shared her view as a Ph.D.¬†candidate with experience teaching R in R-Ladies workshops and as a teaching assistant in biostatistics courses.\nüá∞üá™ Shelmith Kariuki speaks to her experience in her blog post The RStudio Certification Process.\n\n\nHere‚Äôs what folks had to say!\nHighlights are shared with the authors‚Äô permission and my gratitude to them.\n\nWhat made you want to pursue the certification?\n\nOne, it gave me incentive to read R for Data Science cover to cover which I had been meaning to do for a while. Two, I‚Äôm teaching R and the certification gives me some gravitas to do that. Three, it forced me to critically think about cognitive load theory, concept mapping, and lesson development, all of which are super useful when you actually have to develop lessons. ‚ÄìStephan\n\n\nI pursued the certification for a few reasons. First because I am really enthusiastic about teaching and I love the tidyverse, so I wanted to find opportunities of teaching it outside my university. Second because I feel that RStudio is growing so fast on teaching materials that sharing with other instructors would be a great way to always keep updated. And last but not least, I was also encouraged by the idea of going through the process with Yanina Bellini Saibene and other amazing women as she discusses in her blog post. ‚ÄìPaloma\n\n\n\nWhat did you think of the training itself, particularly the pedagogical aspects?\n\nThe training is top notch. In my mind, Greg Wilson is the #1 authority when it comes to teaching programming and R in particular. ‚ÄìStephan\n\n\nI think the best part is to take and learn the pedagogical aspect. Greg Wilson is an awesome trainer and you will love as a student all the tools and techniques that he teaches you. For learning this, the course is already worth it. All the content is more developed in the book Teaching Tech Together by Greg Wilson if you want to look it over. ‚ÄìYanina\n\n\nAbout the training, it was mind blowing, it changed my view of teaching not only programming but everything. Greg‚Äôs book is amazing and the way he teaches is outstanding. I learned so much. ‚ÄìPaloma\n\n\n\nHave you been able to implement what you learned in some way either at work or elsewhere?\n\nYes! As you probably saw, I‚Äôm teaching the intro to R course for R/Medicine. And I‚Äôve been teaching a similar course to doctors, in addition to some other teaching sessions that I‚Äôve done for the CHOP R User group and/or medical resident teaching. ‚ÄìStephan\n\n\nYes! Immediately. I delivered 3 in-person courses after training and more than 15 courses on-line using all the pedagogical tools. I also co-founded Metadocencia where we share practical tools to help teachers teach online (volunteer-run and free) using these principles learned in the training. I also use some of the tools for my work as the chief of a research group for some meetings and identifying the target of some of our development (especially concept maps and learner personas). ‚ÄìYanina\n\n\nI think I use what I learned so far even when I am preparing my work presentations, when developing any type of class, event, book club, etc. Overall it was an experience that made me reflect a lot on how teaching is usually done, how is my teaching so far and an inspiration about the teacher I want to be. ‚ÄìPaloma"
  },
  {
    "objectID": "blog/2020-10-07-rstudio-instructor-certification-tidyverse/index.html#attending-the-mir-panel",
    "href": "blog/2020-10-07-rstudio-instructor-certification-tidyverse/index.html#attending-the-mir-panel",
    "title": "Becoming certified as an RStudio Tidyverse Instructor",
    "section": "Attending the MiR panel",
    "text": "Attending the MiR panel\nIf you read the questions and responses above you might have noticed one character in this story that I haven‚Äôt introduced yet. His name is Greg Wilson. I tend to take such strong endorsements with a spoonful of skepticism and (spoiler alert) I‚Äôm happy to say I fully agree with everything that was said by those above. In that spirit, I‚Äôll add my own glowing recommendation:\n\nGreg Wilson is truly a programming pedagogy expert, and an incredibly kind human being. I‚Äôm grateful to have learned from him within the context of the certification, and appreciate being able to continue learning from his example in a variety of other contexts.\n\nNevertheless, I‚Äôm glad I got to do a gut-check beforehand when I attended the RStudio Instructor Certification Panel hosted by the MiR Community and facilitated by Dorris Scott and Danielle Smalls-Perkins. You‚Äôll notice Yanina and Shelmith were two of the panelists! Hearing from this panel was the last piece of the puzzle I needed to feel like pursuing the certification was an enthusiastic yes."
  },
  {
    "objectID": "blog/2020-10-07-rstudio-instructor-certification-tidyverse/index.html#teaching-exam",
    "href": "blog/2020-10-07-rstudio-instructor-certification-tidyverse/index.html#teaching-exam",
    "title": "Becoming certified as an RStudio Tidyverse Instructor",
    "section": "Teaching exam",
    "text": "Teaching exam\nI relied on the instructor training materials and my in-class notes to prepare my demonstration lesson and study for the written component of the teaching exam. For anything that didn‚Äôt fully sink in, I consulted Teaching Tech Together.\nYou can find all materials for my teaching demonstration on GitHub. They include the slides below and this R Markdown file that I used to incorporate live coding into the lesson.\nI found an excellent reference for a demonstration lesson in Florencia D‚ÄôAndrea‚Äôs post Two examples of iteration with purrr - Class for the RStudio certification.\nIt comes highly recommended that someone take a look at each one of our lessons before it ships out because it seems it‚Äôs common not to realize we‚Äôve packed too much in! Yanina was kind enough to sit through my lesson as a learner and provided fantastic feedback. Some of the things I was able to work on before my teaching exam included providing context for the lesson at the beginning (asking the learner to download the file, introducing the lesson in the context of a workshop, etc.) and talking through all my key strokes during the live coding portions. Thanks again Yani!"
  },
  {
    "objectID": "blog/2020-10-07-rstudio-instructor-certification-tidyverse/index.html#tidyverse-exam",
    "href": "blog/2020-10-07-rstudio-instructor-certification-tidyverse/index.html#tidyverse-exam",
    "title": "Becoming certified as an RStudio Tidyverse Instructor",
    "section": "Tidyverse exam",
    "text": "Tidyverse exam\nLucky for me the MiR Community organized some study sessions specifically for preparing for the Tidyverse exam! Dorris and I met regularly to discuss our approach to the sample exam (v2.0) and present chapters of R for Data Science that we weren‚Äôt as comfortable with. Yanina joined us for some of the sessions to lend us her expertise and provide tips and tricks!\nOne of the recommendations Yanina made was to explore the RStudio Primers for any topic we wanted to practice. For me that meant iteration using purrr‚Äôs map functions. After the iteration primer and the companion R for Data Science chapter, I felt like I could iterate all day every day.\nIn real life, both the written portion of the teaching exam and the Tidyverse exam are very much like the sample exams provided on the RStudio Education blog. You can find those here:\n\nSample exam v1.0 (February 2020): Instructor Certification Exams\nSample exam v2.0 (August 2020): More sample exams\n\nIf you‚Äôre a member of the MiR Community and like the idea of studying with some structure and friendly accountability, join us for the study group! And if you‚Äôre not, you can learn more about joining MiR as a member or ally here."
  },
  {
    "objectID": "blog/2020-10-07-rstudio-instructor-certification-tidyverse/index.html#teaching-resources",
    "href": "blog/2020-10-07-rstudio-instructor-certification-tidyverse/index.html#teaching-resources",
    "title": "Becoming certified as an RStudio Tidyverse Instructor",
    "section": "Teaching resources",
    "text": "Teaching resources\n\n Slides for the instructor training course ‚Ä¢ Greg Wilson\n Teaching Tech Together ‚Ä¢ Greg Wilson\n Teaching R and Data Science with RStudio ‚Ä¢ Mine √áetinkaya-Rundel\n Teaching in Production ‚Ä¢ Alison Hill\n Teaching Online at Short Notice - RStudio 2020 ‚Ä¢ Greg Wilson\n Sharing on Short Notice - RStudio 2020 ‚Ä¢ Alison Hill & Desir√©e De Leon\n Evidence Based Teaching: What We Know and How to Use It - EuroSciPy 2015 ‚Ä¢ Greg Wilson\n rstudio-education/r4ds-instructors: Instructors‚Äô Guide to accompany ‚ÄúR for Data Science‚Äù ‚Ä¢ RStudio Education\n Cursos cortos para ense√±ar online ‚Ä¢ MetaDocencia\n Flattening the leaRning curve: Teaching R online during COVID-19 ‚Ä¢ Brendan Cullen"
  },
  {
    "objectID": "blog/2020-10-07-rstudio-instructor-certification-tidyverse/index.html#experiences-with-the-certification-process",
    "href": "blog/2020-10-07-rstudio-instructor-certification-tidyverse/index.html#experiences-with-the-certification-process",
    "title": "Becoming certified as an RStudio Tidyverse Instructor",
    "section": "Experiences with the certification process",
    "text": "Experiences with the certification process\n\nYanina Bellini Saibene ‚Äì Obtaining RStudio certification. A shared path\nShelmith Kariuki ‚Äì The RStudio Certification Process\nTed Laderas ‚Äì My Experience with RStudio Instructor Training\nRayna Harris ‚Äì A Review: RStudio Teaching Certification Course\nBrendan Cullen ‚Äì Reflections on RStudio Instructor Training\nYuqi Liao ‚Äì Getting Certified as an RStudio Instructor\nBeatriz Milz ‚Äì Certifica√ß√£o da RStudio\nRohan Alexander ‚Äì In Appreciation of Greg Wilson"
  },
  {
    "objectID": "blog/2020-10-07-rstudio-instructor-certification-tidyverse/index.html#teaching-exam-examples",
    "href": "blog/2020-10-07-rstudio-instructor-certification-tidyverse/index.html#teaching-exam-examples",
    "title": "Becoming certified as an RStudio Tidyverse Instructor",
    "section": "Teaching exam examples",
    "text": "Teaching exam examples\n\nSilvia Canel√≥n\n\nLesson slides: Using lubridate to work with time intervals\nGitHub repo\n\nYanina Bellini Saibene\n\nLesson materials: Concept map and formative assessments\nLesson slides: C√≥digo en R Markdown\nGitHub repo\n\nPaloma Rojas-Saunero\n\nLesson overview\nLesson slides: Tidy data\nLesson script: Tidyr: Reshape\n\nFlorencia D‚ÄôAndrea\n\nLesson slides: Iteration with purrr package for automatized file management\nBlog post: Two examples of iteration with purrr - Class for the RStudio certification\nGitHub repo\n\nBeatriz Milz\n\nLesson slides: Adding figures in R Markdown\nGitHub repo\n\nLaurie Baker\n\nLesson slides\nGitHub repo\n\nCorrado Lanera\n\nLesson slides: (Meta)data texting in {ggplot2}\nGitHub repo\n\nBrendan Cullen\n\nLesson slides: Column-wise operations with dplyr: Old and New\nGitHub repo\n\nAdi Sarid\n\nGitHub repo: Exercise on purrr\n\nDavid John Baker\n\nLesson slides: Learn to Pivot!\nGitHub repo\n\nYuqi Liao\n\nLesson slides: Creating animated visualizations in R\nGitHub repo\n\nLuis Verde\n\nGitHub repo"
  },
  {
    "objectID": "blog/2020-10-07-rstudio-instructor-certification-tidyverse/index.html#tidyverse-sample-exam-solutions",
    "href": "blog/2020-10-07-rstudio-instructor-certification-tidyverse/index.html#tidyverse-sample-exam-solutions",
    "title": "Becoming certified as an RStudio Tidyverse Instructor",
    "section": "Tidyverse sample exam solutions",
    "text": "Tidyverse sample exam solutions\n\nSilvia Canel√≥n ‚Äì August 2020 sample exam (v2.0)\nBrendan Cullen ‚Äì August 2020 sample exam (v2.0)\nMarly Gotti ‚Äì February 2020 sample exam (v1.0)\nEzekiel Adebayo Ogundepo ‚Äì August 2020 sample exam (v2.0)"
  },
  {
    "objectID": "blog/2023-09-29-hello-quarto/index.html",
    "href": "blog/2023-09-29-hello-quarto/index.html",
    "title": "Hello Quarto: Porting my Website from Hugo Ap√©ro",
    "section": "",
    "text": "In 2019 I created my first website using blogdown and the Hugo Academic theme, and in 2021 I migrated that site to the Hugo Ap√©ro theme created by Alison Hill. I even documented that trek in great detail üòÖ to provide something resembling a paved path for others to use on their journey adopting this beautiful and functional theme. Over the past two years, my Ap√©ro site became a wonderful place to cultivate a digital garden1. Now the time has come to say thank you, say goodbye, and travel down a new path. Enter Quarto."
  },
  {
    "objectID": "blog/2023-09-29-hello-quarto/index.html#goodbye-hugo-ap√©ro",
    "href": "blog/2023-09-29-hello-quarto/index.html#goodbye-hugo-ap√©ro",
    "title": "Hello Quarto: Porting my Website from Hugo Ap√©ro",
    "section": "",
    "text": "In 2019 I created my first website using blogdown and the Hugo Academic theme, and in 2021 I migrated that site to the Hugo Ap√©ro theme created by Alison Hill. I even documented that trek in great detail üòÖ to provide something resembling a paved path for others to use on their journey adopting this beautiful and functional theme. Over the past two years, my Ap√©ro site became a wonderful place to cultivate a digital garden1. Now the time has come to say thank you, say goodbye, and travel down a new path. Enter Quarto."
  },
  {
    "objectID": "blog/2023-09-29-hello-quarto/index.html#why-port-to-quarto",
    "href": "blog/2023-09-29-hello-quarto/index.html#why-port-to-quarto",
    "title": "Hello Quarto: Porting my Website from Hugo Ap√©ro",
    "section": "Why port to Quarto?",
    "text": "Why port to Quarto?\nQuarto is a new and powerful technical publishing system in active development, natively friendly to a variety of programming languages and IDEs. There are countless features available in Quarto that I was interested in having access to in my website, so I‚Äôll list just my top five:\n\nFlexibility in design. Quarto offers options for website navigation (top navigation vs.¬†side navigation), ‚Äúabout‚Äù pages like the postcard landing pages that a lot of folks use in their distill sites, listing pages that are generated from a list of documents, among others. These components would act like modules that I could combine to design a site that truly fit my needs.\nFlexibility in content layout. With Quarto I would gain the ability to organize content in ways I hadn‚Äôt even dreamt of. Tables and figures could be laid out across multiple columns and rows as sub-tables and sub-figures of a panel. How much of the page the content took up would be up to me. Content could even go in the margin! ü§© \nFreezing computations. Quarto would give me the option to freeze posts containing executable code. This was huge for me, because updating my blogdown site always produced a little bit of anxiety. I used to worry that blogdown might try to re-render old R Markdown blog posts and break things! üò±\nSite search. With content spread out over blog posts, talks, publications, and projects, I wanted site visitors (including myself!) to be able to keyword search for something in particular. Tags and categories in blogdown would get me part of the way there, but Quarto offers built-in search capability.\nEmbedding computations. Ok this is a feature that I learned about a week ago at posit::conf(2023) from Mine √áetinkaya-Rundel‚Äôs talk ‚ÄúReproducible Manuscripts with Quarto.‚Äù Mine demo‚Äôd pulling a table from a .qmd file and a figure from an .ipynb file into the same manuscript .qmd file, without having to execute the source code again! üëÄ This is a game changer for anyone compiling results from computations performed in different files, and in my personal site I could see it coming in handy if I have a series of blog posts with outputs that I want to cross-reference. Currently we can only embed computations from Jupyter notebook files, but hopefully we‚Äôll be able to embed .qmd computations in Quarto v1.4! ü§ûüèΩ\nI mean, it‚Äôs pretty cool that content can go in the margin, right??  It could even be a picture: The book page reads verdere expedities which is Dutch for ‚Äúfurther expeditions‚Äù"
  },
  {
    "objectID": "blog/2023-09-29-hello-quarto/index.html#the-cost-of-porting",
    "href": "blog/2023-09-29-hello-quarto/index.html#the-cost-of-porting",
    "title": "Hello Quarto: Porting my Website from Hugo Ap√©ro",
    "section": "The cost of porting",
    "text": "The cost of porting\nGaining the aforementioned Quarto functionality did not come without a cost. To me, the biggest cost was the aesthetics ‚Äì the Hugo Ap√©ro theme is quite lovely! ‚Äì but I customized my Quarto site enough to reflect the design aspects I loved the most. More on styling later. Some other costs included:\n\n\nLoss of the sidebar layout. The Ap√©ro theme has options for adding a nicely styled sidebar that I had been using for my blog. It included a featured image and details about the individual post like tags, categories, length, etc. All of this information is available in Quarto posts, it‚Äôs just organized a little differently.\nExample of the sidebar\n\n\n\n\nLoss of Utterances comments. Any interactions with folks through Utteranc.es comments did not transfer over, and I‚Äôll miss them. The few comments on my site have been very kind (see example below) and I‚Äôve really enjoy reading them!\nExample of Utterances comments\n\n\n\n\n\n\n\nUpdate: Oct.¬†12, 2023\n\n\n\n\n\nThanks to Emily Riederer, I‚Äôm happy to report this is a non-issue! See her tips in the comments at the end of the post, or on GitHub.\n\n\n\n\nHugo Ap√©ro collections. The Ap√©ro theme had a way of bundling together posts that were related into a collection of posts. Garrick and I used this feature for our user!2021 xaringan workshop and it worked well to organize learning materials for different sections of our workshop. If I wanted something like this in the future, I would probably use Quarto‚Äôs sidebar navigation feature like Andrew Bray did in his Rmd to Quarto workshop for rstudio::conf(2022).\nName pronunciation on the About page. Ap√©ro had a built-in option for adding an audio clip under your name that you could use to help people learn how your name is pronounced. I never used this feature myself, but if I wanted to, I could look to Emil Hvitfeldt‚Äôs site as an example.\nRedirects. The Ap√©ro theme gave me the option to define the combination of date information and URL slugs for each of my posts, and I had them set up as year-slug (e.g., blog/2023-hello-quarto). Quarto does not offer that functionality and strictly creates URLs for posts based on the filepath (e.g., blog/2023-09-29-hello-quarto). In order to continue using my year-month-day-slug naming convention for my post folders, I had to set up redirects from the old URLs to the new ones so that there wouldn‚Äôt be broken links sprinkled throughout the internet. More on redirects later."
  },
  {
    "objectID": "blog/2023-09-29-hello-quarto/index.html#designing-the-site",
    "href": "blog/2023-09-29-hello-quarto/index.html#designing-the-site",
    "title": "Hello Quarto: Porting my Website from Hugo Ap√©ro",
    "section": "Designing the site",
    "text": "Designing the site\nAp√©ro had posts in the content folder but with Quarto I could pull blog, talk, publication, and project subfolders into the root folder.\nStructure\n\n\nQuarto\nHugo Ap√©ro\n\n\n\n.\n‚îú‚îÄ‚îÄ _quarto.yml\n‚îú‚îÄ‚îÄ about\n‚îú‚îÄ‚îÄ blog\n‚îú‚îÄ‚îÄ talk\n‚îú‚îÄ‚îÄ publication\n‚îú‚îÄ‚îÄ project\n‚îú‚îÄ‚îÄ index.qmd\n‚îî‚îÄ‚îÄ silvia.Rproj\n\n\n.\n‚îú‚îÄ‚îÄ content\n‚îÇ   ‚îú‚îÄ‚îÄ _index.md\n‚îÇ   ‚îú‚îÄ‚îÄ about    \n‚îÇ   ‚îú‚îÄ‚îÄ blog      \n‚îÇ   ‚îú‚îÄ‚îÄ project\n‚îÇ   ‚îú‚îÄ‚îÄ publication\n‚îÇ   ‚îî‚îÄ‚îÄ talk\n‚îú‚îÄ‚îÄ config.toml\n‚îú‚îÄ‚îÄ netlify.toml\n‚îú‚îÄ‚îÄ index.Rmd\n‚îî‚îÄ‚îÄ silvia.Rproj\n\n\n\nAbout & listing pages\nI decided to use a combination of about pages and listing pages to replicate the site structure I enjoyed in my Ap√©ro site. I used an about page layout for both my home and about pages, and listing pages to generate a list of blog posts, talks, publications, and projects. There was also some custom CSS involved, but we haven‚Äôt gotten to that part of the blog post yet wink üòâ Dear reader, it‚Äôs at this point in my blog post drafting that I start realizing that what was meant to be a brief post is turning into a novel (sigh)\nOne of the aspects I liked about my Ap√©ro site was that the About page highlighted the most recent posts from the blog, talk, publication, and project groups. In my Quarto site, I achieved this by including a one-entry listing grid for each group on my About page.\n\n\n\n\n\n\nCSS tip\n\n\n\n\n\nThese listing cards looked great on a wide screen but as the screen got narrower (think mobile device) the listing cards just became narrower and narrower üòÇ. I took care of this by tweaking the CSS so that the cards would wrap.\n\n\nassets/about.css\n\n  /* wrap lately section */\n  #lately .grid {\n    display: flex;\n    flex-wrap: wrap;\n  }\n\n  /* listings */\n  #blog, #talks, #publications, #projects {\n    flex-basis: 100% !important;\n  }\n\n source code\n\n\n\nContact form\nThe last structural piece I wanted to recreate from Ap√©ro was a contact form. I saw a great example on Michael McCarthy‚Äôs Tidy Tales blog, site and did a little repo-diving to get ideas on how to organize the content. I ended up using the Bootstrap CSS Grid to layout the content exactly how I wanted to. See what I mean about Quarto offering a lot of flexibility in content layout?\n\n\n\n\n\n\nBones of the contact page\n\n\n\n\n\n\n\ncontact.qmd\n\n\n&lt;!-- start grid --&gt;\n::: {.grid} \n\n&lt;!-- column for the body text --&gt;\n::: {.g-col-5}\n\n# Send me a note\n\n&lt; Body text&gt;\n\n&lt; HTML code for social media icons &gt;\n\n:::\n\n&lt;!-- column for spacing --&gt;\n::: {.g-col-1}\n:::\n\n&lt;!-- column for the form --&gt;\n::: {.g-col-6}\n\n&lt; HTML embed code provided by Formspree &gt;\n\n:::\n\n:::\n&lt;!-- end grid --&gt;\n\n source code"
  },
  {
    "objectID": "blog/2023-09-29-hello-quarto/index.html#adapting-old-posts",
    "href": "blog/2023-09-29-hello-quarto/index.html#adapting-old-posts",
    "title": "Hello Quarto: Porting my Website from Hugo Ap√©ro",
    "section": "Adapting old posts",
    "text": "Adapting old posts\nYAML fields\nOk so once I figured out how to incorporate all of the structural elements I wanted, I had to deal with the (relatively small) challenge of porting my old posts to Quarto. Quarto was designed to be compatible with existing R Markdown documents, but I didn‚Äôt actually want it trying to re-render old R Markdown files so I had Quarto ignore those completely2 and render the Markdown version of each post instead3. There were also a handful of YAML fields that I had to remove or modify to play nicely with Quarto:\n\nRemove layout: (e.g., layout: single-sidebar)\nRemove publishDate\n\nRemove lastUpdated\n\nRemove featured (e.g., featured: yes)\nMerge categories with tags and keep tags\n\nAdd image (e.g.¬†image: featured.png)\nPartials\nIf you‚Äôve used Ap√©ro you might have come to love the cute button links created from the links field in the YAML, like the one at the top of this post, pointing to the Quarto docs.\nlinks:\n- icon: journal-text\n  name: Quarto Docs\n  url: https://quarto.org/docs/websites/\nWell, these button links are not ready-made by Quarto, but lucky for me (us!), Garrick figured out a way to bring them in right where we I need them. I repo-dived and found that he modified an HTML partial for title blocks, which controls the layout and styling of the post title, description, and tags, shown at the top of the page.\nThe original title block partial has sections controlling the placement and styling of text provided in the title, subtitle, authors, date, and abstract fields of the document YAML.\nAs an example, line 2 might read:If there‚Äôs something in the title field of the YAML, give it a level 1 heading and style it with CSS class .title\n\n\ngithub.com/quarto-dev/quarto-cli/src/resources/formats/html/pandoc/title-block.html\n\n&lt;header id=\"title-block-header\"&gt;\n$if(title)$&lt;h1 class=\"title\"&gt;$title$&lt;/h1&gt;$endif$\n$if(subtitle)$\n&lt;p class=\"subtitle\"&gt;$subtitle$&lt;/p&gt;\n$endif$\n$for(author)$\n&lt;p class=\"author\"&gt;$author$&lt;/p&gt;\n$endfor$\n\n$if(date)$\n&lt;p class=\"date\"&gt;$date$&lt;/p&gt;\n$endif$\n$if(abstract)$\n&lt;div class=\"abstract\"&gt;\n&lt;div class=\"abstract-title\"&gt;$abstract-title$&lt;/div&gt;\n$abstract$\n&lt;/div&gt;\n$endif$\n&lt;/header&gt;\n\nThe modified partial  includes some additional sections but I‚Äôll break down the one for links.\nThere‚Äôs more styling going on in the modified partial, but starting on line 6, the structure for the link buttons is effectively:If the links field is populated in the YAML, create an HTML container styled by some CSS, and give it some specific HTML properies.Then, for each sub-item of the links field: create a hyperlink from the url sub-item, apply some CSS classes to create the button, add a Bootstrap icon defined by the icon sub-item, and finally add hyperlink text defined by the name sub-item.\n\n\n_partials/title-block-link-buttons/title-block.html\n\n&lt;header id=\"title-block-header\" class=\"quarto-title-block default page-columns\"&gt;\n...\n$if(links)$\n&lt;div class=\"mt-4 d-flex flex-row flex-wrap gap-1 justify-content-left justify-content-sm-start\" role=\"group\" aria-label=\"Links\"&gt;\n$for(links)$\n&lt;a href=\"$links.url$\" class=\"btn btn-secondary text-capitalize\"&gt;&lt;i class=\"bi bi-$links.icon$ me-1\"&gt;&lt;/i&gt;$links.name$&lt;/a&gt;\n$endfor$\n&lt;/div&gt;\n$endif$\n...\n&lt;/header&gt;"
  },
  {
    "objectID": "blog/2023-09-29-hello-quarto/index.html#styling-the-site",
    "href": "blog/2023-09-29-hello-quarto/index.html#styling-the-site",
    "title": "Hello Quarto: Porting my Website from Hugo Ap√©ro",
    "section": "Styling the site",
    "text": "Styling the site\nSCSS variables\nI may have published my brand new Quarto site in the fall of 2023, but I had actually taken my first go at porting it from Ap√©ro in the fall of 2022. In an attempt to replicate the styling of my old site I tried to strong-arm my Quarto site into using tachyons4, and I wrote way too much custom CSS in the process üò©.\nSomething didn‚Äôt feel right about it, so I took a break and came back to my in-progress Quarto site several months later ‚Äì outside of the Quarto release craze, and with the perspective that I wanted to work with the built-in theming capabilities, rather than against them üòå. This time around I leaned into the Bootstrap SCSS variables, and added custom styling as needed.\nTo be more specific, I created a custom theme 5, and populated it with definitions for some of the built-in Bootstrap Sass variables. If you poke around my custom theme, you will notice that some colors are defined by color variables that start with $spc-. These are variables pointing to colors that I‚Äôve defined elsewhere, and they can be replaced with a hex code of your choosing! üé®\n\n\nassets/silvia-theme.scss\n\n/*-- scss:defaults --*/\n\n// Colors\n$primary:                    $spc-primary-light;\n$secondary:                  $spc-secondary;\n\nThe Sass variables listed in the documentation got me pretty far, but there were still elements of my site using default colors and styling that I wanted to change. So I repo-dived to learn about additional Quarto Bootstrap variables and rules:\n\nBootstrap variables: https://github.com/quarto-dev/quarto-cli/blob/main/src/resources/formats/html/bootstrap/_bootstrap-variables.scss\n\nBootstrap rules: https://github.com/quarto-dev/quarto-cli/blob/main/src/resources/formats/html/bootstrap/_bootstrap-rules.scss\n\n\nTo give you an example, someone in the Quarto Discussions forum asked how to set the color of block quotes, figure captions, and outlines, something not defined in the documentation. One of the replies suggested using the browser‚Äôs inspector to find the CSS rule applied to the element in question, we‚Äôll say the figure caption, and then looking at how Quarto implemented that rule. I‚Äôll make that process a little more explicit here and use the figure caption as an example:\n\nUse the browser inspector to highlight a figure caption\nThe inspector will reveal that the element is styled by CSS class .figure-caption\nRun a keyword search for ‚Äúfigure-caption‚Äù in the Bootstrap variables file. This will yield no results ü§î\n\nRun the same keyword search in the Bootstrap rules file ‚Äì success! We have a clue, which is that .figure-caption is styled by a variable named body-secondary üîç\n.panel-caption,\n.figure-caption,\n.subfigure-caption,\n.table-caption,\nfigcaption.quarto-float-caption,\ncaption {\n  font-size: 0.9rem;\n  @include body-secondary;\n}\n\n\nDefine your own body-secondary color variable in your custom theme file\n\n\nassets/custom-theme.scss\n\n/*-- scss:defaults --*/\n\n$body-secondary: #6C757D;\n\n\nEnjoy the fruits of your labor as a CSS detective üïµüèΩ‚Äç‚ôÄÔ∏è\nIndividual page styling\nIn some cases, I wanted to style individual pages differently than I was styling my entire site. Poking around Garrick‚Äôs repo (again!), I learned that you can reference CSS stylesheets in the YAML of any particular document. I used this approach to separately style my Home, About, and listing pages.\n\n\nindex.qmd\n\nexecute: \n  freeze: false\n  echo: false\n  warning: false\n\n\n\nindex.qmd  source code\n\n\nassets/index.css  source code\n\nBackground image for title blocks\nOk one of the aesthetic pieces I was excited to add to my Quarto site that I didn‚Äôt have in my old site is a featured image at the top of each post. I was inspired by Matt Worthington‚Äôs site while I was reading one of his excellent blog posts on a workflow for interactive maps in R ‚Äì I loved that the title block included an image in the background! ü§©\nAfter some web inspecting and repo-diving in Matt‚Äôs website repo I came up with some styling that I could apply to the title block of each post. It took modifying the title block partial described earlier, and adding some CSS to my custom theme.\nFor styling that I wanted to apply uniformly to all post title blocks, I created a .figured-image CSS class in my custom theme:\nDon‚Äôt miss the code annotations for this code chunk! üëÄ Such a cool feature!\n\n\nassets/custom-theme.scss\n\n  // style background image on posts\n  .featured-image {\n1    background-size: cover;\n2    background-position: center;\n3    color: white;\n4    box-shadow: inset 0 0 0 1000px rgba(0,38,66,0.75);\n  }\n\n\n1\n\nHave the image cover the background\n\n2\n\nCenter the image\n\n3\n\nMake the overlaying text color white\n\n4\n\nAdd shadowing that gives the appearance of a dark overlay\n\n\nAlright, but why didn‚Äôt I use a background-image property to define the image? If I define the background image in my .featured-image class then that is the image that‚Äôs going to show up in all of the posts across my site. I want the title block of each post to display the featured image belonging to each individual post. That‚Äôs where the partial comes back in.\n\n\n_partials/title-block-link-buttons/title-block.html\n\n&lt;div \nid=\"title-block-header-title\" \nclass=\"quarto-title page-columns page-full page-layout-full featured-image p-4\" \nstyle=\"background-image: url(featured.png), url(featured.jpg), url(../featured.jpg);\"&gt;\n...\n&lt;/div&gt;\n\nAlong with some other CSS classes, the div container for the title block is styled with the featured-image class defined earlier, using the class= property. In addition, the div itself is styled using the style= property, and that‚Äôs where I defined the background image. The partial will look for a featured image of some kind either in the same folder as the post, or in the parent folder, and display it in the background of the title block.\nThis is a hacky way of getting what I really want which is for the partial to check for a featured image in the order I specify and then just stop once it finds one. As it stands right now, the styling attempts to layer on all three images, with the first image on the top and the last image on the bottom. This means that I get a warning every time I preview or render my site because the partial can‚Äôt find one or two of the other urls, but I‚Äôm ok with that!\n\n\n\n\n\n\nExample warning\n\n\n\n/blog/2023-09-29-hello-quarto/featured.png (404: Not Found)"
  },
  {
    "objectID": "blog/2023-09-29-hello-quarto/index.html#setting-up-redirects",
    "href": "blog/2023-09-29-hello-quarto/index.html#setting-up-redirects",
    "title": "Hello Quarto: Porting my Website from Hugo Ap√©ro",
    "section": "Setting up redirects",
    "text": "Setting up redirects\nResources\nLast but not least, I can‚Äôt finish this blog post without talking about the necessary task of redirecting old Ap√©ro URLs to new Quarto ones 6. Many thanks to Danielle Navarro and Tom Mock for documenting their solutions for automatically generating a _redirects file with each render of the site.\n\nDanielle‚Äôs blog post: Notes from a data witch - Porting a distill blog to quarto\n\nTom‚Äôs source code: index.qmd - The MockUp\n\n\nI adapted their code to (1) fit my site, which has multiple folders of posts that all need redirects, and (2) combine these automatically generated redirects with ones I had already defined manually. I placed this code within my home page index.qmd file  and I specified freeze: false in the YAML so that the code would run each time I rendered the site. The following sections will take a look at the code piece by piece.\nImporting manual redirects\nThe first step imports the manually-defined redirects that I had already been using in my old site. These redirects primarily have the task of redirecting my rbind.io domain to my custom domain silviacanelon.com.\n\n\n\nindex.qmd\n\nmanual_redirects &lt;-\n  readr::read_table(here::here(\"static\", \"_manualredirects.txt\"),\n                    col_names = FALSE) |&gt; \n  dplyr::mutate(redirect = paste0(X1, \" \", X2, \" \", X3))\n\nmanual_redirects &lt;- manual_redirects$redirect\n\nhead(manual_redirects)\n\n\n[1] \"https://silvia.rbind.io/authors/silvia/avatar.png https://silviacanelon.com/about/sidebar/avatar.png 301!\"\n[2] \"https://silvia.rbind.io/post/* https://silviacanelon.com/blog/:splat 301!\"                                \n[3] \"https://silvia.rbind.io/blog/* https://silviacanelon.com/blog/:splat 301!\"                                \n[4] \"https://silvia.rbind.io/talk/* https://silviacanelon.com/talk/:splat 301!\"                                \n[5] \"https://silvia.rbind.io/project/* https://silviacanelon.com/project/:splat 301!\"                          \n[6] \"http://silvia.rbind.io/* https://silviacanelon.com/:splat 301!\"                                           \n\n\nListing subdirectories\nThe next step defines a function that obtains a list of subdirectories, iterates it over the four groups of posts in my site (blog posts, talks, publications, and projects), and compiles the files into a data frame.\n\n\n\nindex.qmd\n\n# function: obtain list of post paths\nlist_paths &lt;- function(folder) {\n  posts &lt;-\n    list.dirs(\n    path = c(here::here(folder)),\n    full.names = FALSE,\n    recursive = FALSE\n    ) |&gt; \n    tibble::as_tibble_col(column_name = \"path\")  |&gt;\n    dplyr::mutate(folder = folder)\n}\n\n# define post folders\nfolders &lt;- c(\"blog\", \"project\", \"publication\", \"talk\")\n\n# list post paths by folder\nposts &lt;- purrr::map(folders, list_paths) |&gt; purrr::list_rbind()\n\nhead(posts)\n\n\n\n  \n\n\n\nDefining redirects\nThis next chunk removes the month and day from year-month-day-slug so that I‚Äôm left with shorter paths with the format year-slug, and uses these paths and the folders they are housed in to create redirects.\nThe resulting redirects will point the short year-slug link to this blog post:\nhttps://silviacanelon.com/blog/2023-hello-quarto\nTo the longer year-month-day-slug Quarto link to this post:\nhttps://silviacanelon.com/blog/2023-09-29-hello-quarto\n\n# extract short paths and create redirects\nposts &lt;- \n  posts |&gt; \n  dplyr::mutate(\n    # extract the year-slugs\n    short_path = stringr::str_remove(path, \"(?!\\\\d{4}-)\\\\d{2}-\\\\d{2}-(?!\\\\d)\"),\n    # create short paths\n    short_path = paste0(folder, \"/\", short_path),\n    # create lines to insert to a netlify _redirect file\n    redirects = paste0(\"/\", short_path, \" \", \"/\", folder, \"/\", path)\n    )\n\nhead(posts)\n\n\n  \n\n\n\nWriting redirects file\nThe last step takes the redirects from the data frame produced in the previous step, combines them with the manual redirects, and writes them to a new text file _redirects. This file is written into the _site folder where my Quarto site is rendered, and where Netlify will know to find it.\n\n\n\nindex.qmd\n\n# extract redirects\nredirects &lt;- posts$redirects\n\n# combine with manual redirects\nredirects_combined &lt;- c(manual_redirects, redirects)\n\n# write the _redirect file\nwriteLines(redirects_combined, here::here(\"_site\", \"_redirects\"))"
  },
  {
    "objectID": "blog/2023-09-29-hello-quarto/index.html#fin",
    "href": "blog/2023-09-29-hello-quarto/index.html#fin",
    "title": "Hello Quarto: Porting my Website from Hugo Ap√©ro",
    "section": "Fin",
    "text": "Fin\nNow that it‚Äôs been over a year since Quarto made its debut, there are so many wonderful blog posts walking folks through how to create a Quarto site. My hope is that the notes I took in this blog post help provide some stepping stones for folks making the transition from blogdown sites, and offer some ideas for what is possible with the flexibility of this new publishing framework. I, for one, am looking forward to growing my digital garden with Quarto tools üå±."
  },
  {
    "objectID": "blog/2023-09-29-hello-quarto/index.html#acknowledgments",
    "href": "blog/2023-09-29-hello-quarto/index.html#acknowledgments",
    "title": "Hello Quarto: Porting my Website from Hugo Ap√©ro",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nFeatured photo by Annelies Geneyn on Unsplash."
  },
  {
    "objectID": "blog/2023-09-29-hello-quarto/index.html#footnotes",
    "href": "blog/2023-09-29-hello-quarto/index.html#footnotes",
    "title": "Hello Quarto: Porting my Website from Hugo Ap√©ro",
    "section": "Footnotes",
    "text": "Footnotes\n\nSee also Digital gardens let you cultivate your own little bit of the internet | MIT Technology Review‚Ü©Ô∏é\nBy adding an underscore prefix (e.g., _index.Rmarkdown)‚Ü©Ô∏é\nI.e., index.markdown‚Ü©Ô∏é\nA CSS design system used in the Hugo Ap√©ro theme: https://tachyons.io‚Ü©Ô∏é\nFor more on custom theming, see Quarto - HTML Theming and Quarto - More About Quarto Themes‚Ü©Ô∏é\nDon‚Äôt skip this step! People will almost certainly have shared one or more of your posts somewhere on the internet, and it helps everyone if you can point them to the right spot‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/2020-05-26-dark-mode-custom-with-atom/index.html",
    "href": "blog/2020-05-26-dark-mode-custom-with-atom/index.html",
    "title": "Customizing Hugo Academic‚Äôs Dark Mode with Help from Atom",
    "section": "",
    "text": "With Alison Hill‚Äôs Up and Running with Blogdown post! Super helpful, though because I came to it 2.5 years late, it was more like ‚Äòup and running with lots of water breaks‚Äô because I had to stop and account for changes made to the Hugo Academic theme in the meantime.\n\nFor example, prior to Academic version 4.6, custom CSS was added using the plugins_css option in params.toml, but in current version 4.8, the theme supports SCSS (a superset of CSS) and a custom.scss file is added in the assets/scss/ folder.\n\nThe going futher section in Alison‚Äôs post specifically talks about customizing the out-of-the-box theme and Alison directly links to her custom CSS file, which I closely referred to when changing colors in my custom SCSS file.\nAlison‚Äôs CSS helped me customize everything from text colors and fonts to alert colors and borders for Academic‚Äôs light mode. At this point I had the light mode looking the way I wanted but the dark mode still used out-of-the-box colors for the most part and they just didn‚Äôt go.\n\nSo I decided not to enable the dark-mode option in params.toml until I could figure out how to customize my stylesheet accordingly. That time has come because it turns out it‚Äôs pretty straightforward!\nThe Blogdown book does an excellent job summarizing what you need to know about CSS. This post builds on that a little by incorporating features made possible by SCSS including variables."
  },
  {
    "objectID": "blog/2020-05-26-dark-mode-custom-with-atom/index.html#basics-of-dark-theme-design",
    "href": "blog/2020-05-26-dark-mode-custom-with-atom/index.html#basics-of-dark-theme-design",
    "title": "Customizing Hugo Academic‚Äôs Dark Mode with Help from Atom",
    "section": "Basics of dark theme design",
    "text": "Basics of dark theme design\n\nThe primary surface color for dark themes should be dark gray, rather than black. The recommended color is #121212\nAs you layer components, surfaces with a higher elevation (closer to the hypothetical ‚Äòlight source‚Äô) should be lighter than those below it to create a visual hierarchy. This can be achieved by applying a semi-transparent white overlay to the primary dark gray surface.\n\n\n\nThe primary text color for dark themes should not be 100% opaque white (i.e.¬†#FFFFFF) because it can appear to bleed or blur against dark backgrounds and be difficult to read.\nText hierarchy is established by controlling the opacity, for example:\n\nHigh emphasis text is white with 87% opacity:rgba(255, 255, 255, 0.87)\nMedium emphasis is white with 60% opacity:rgba(255, 255, 255, 0.60)\nDisabled text is white with 38% opacity:rgba(255, 255, 255, 0.38)\n\nTo meet WCAG AA standard, there must be a 4.5:1 contrast level between the body text and the dark theme surface at the highest/lightest elevation. The contrast level is 7:1 for the WCAG AAA standard."
  },
  {
    "objectID": "blog/2020-05-26-dark-mode-custom-with-atom/index.html#tools-to-explore-palettes",
    "href": "blog/2020-05-26-dark-mode-custom-with-atom/index.html#tools-to-explore-palettes",
    "title": "Customizing Hugo Academic‚Äôs Dark Mode with Help from Atom",
    "section": "Tools to explore palettes",
    "text": "Tools to explore palettes\nMaterial Design has a color palette generator and a color tool that can be used to dark and light variants of a color. I used the color tool to find a dark and light variant of my primary and secondary colors. The accessibility feature of the color tool is helpful to determine the minimum opacity for white text to ensure enough contrast. The Coolors color contrast checker is another great tool."
  },
  {
    "objectID": "blog/2020-05-12-trello-to-airtable/index.html",
    "href": "blog/2020-05-12-trello-to-airtable/index.html",
    "title": "Migrating from Trello to Airtable: Working with JSON Data in R",
    "section": "",
    "text": "Airtable is a user-friendly and powerful tool that until recently I‚Äôd been using for personal projects (i.e.¬†document organizing, apartment hunting, etc.). A couple of weeks ago I leaned on Airtable to create a base designed for the Philadelphia Reproductive Freedom Collective to support our COVID-19 mutual aid efforts.\nHaving fallen in some Airtable deep-work I figured maybe it was time to retire my Trello boards in favor of some task bases. Airtable accepts CSV files from Trello but, alas, my free Trello account only gave me the option to print as a PDF or export as JSON. I decided this would be a good opportunity to learn how to parse JSON data and export it as a CSV ready for import to Airtable."
  },
  {
    "objectID": "blog/2020-05-12-trello-to-airtable/index.html#cards",
    "href": "blog/2020-05-12-trello-to-airtable/index.html#cards",
    "title": "Migrating from Trello to Airtable: Working with JSON Data in R",
    "section": "Cards",
    "text": "Cards\nThe first step is to extract information about the Trello cards themselves. This information is contained within a list of data frames and requires flattening which makes the nested hierarchical data structure into a flatter structure by assigning each of the nested variables its own column as much as possible. Then, the most important variables are selected as cards_trim before moving on to extracting label information.\n# selecting cards information\ncards &lt;- trello$cards # list of 1\n\n# flattening\ncards_flat &lt;- flatten(cards) #list of 37\n\n# tibble time\ncards_flat_tbl &lt;- as_tibble(cards_flat) # 32 obs of 37 variables\nglimpse(cards_flat_tbl)\n\n# selecting wanted variables\ncards_trim &lt;- cards_flat_tbl %&gt;%\n  select(id, idShort, idList, dateLastActivity, name, desc, dueComplete, due,\n         labels, attachments, shortUrl, closed) %&gt;%\n  arrange(desc(dateLastActivity))\n\nLabels\nRelevant information about the labels is selected and the unnest function is used to flatten because labels is a list of data frames. Again, I found Kan‚Äôs post helpful here! Particularly for saving the label details as a character list, which is helpful later on. Once we get to Airtable it‚Äôll be important that label information for each card be structured as a simple list of words (i.e.¬†label1, label2, label3). We get close once the labels are contained within a character list labelList, but there are still ‚Äúc‚Äùs and parentheses that need to be removed. String manipulation is something I‚Äôm still learning about so the code below is far from elegant!\n# extracting labels details\nlabels_info &lt;- cards_trim %&gt;%\n  select(id, idShort, labels) %&gt;%\n  unnest() %&gt;% # no arguments because the nested items don't have names\n  rename(labelName = name) %&gt;%\n  select(id, idShort, labelName) %&gt;%\n  group_by(id, idShort) %&gt;%\n  summarize(labelList = list(labelName)) %&gt;%\n  mutate(labelList = as.character(labelList)) %&gt;%\n  mutate(labelList_tidy = str_remove_all(labelList, pattern = \"\\\"\")) %&gt;%\n  mutate(labelList_tidy = str_remove_all(labelList_tidy, pattern =\"c\\\\(\")) %&gt;%\n  mutate(labelList_tidy = str_remove_all(labelList_tidy, pattern =\"\\\\)\")) %&gt;%\n  unique()\n\nknitr::kable(labels_info %&gt;% head(n = 3L))\n\n# joining back with main cards data frame\nct_labels &lt;- left_join(cards_trim %&gt;% select(-labels), labels_info %&gt;% select(-labelList))\n\n\nAttachments\nThe next step is to download all of the items attached to the cards onto a local folder. I found this StackOverflow post really helpful. When I tried this out on my own Trello board I also found that I couldn‚Äôt download the few attachments I had made from my local drive. This StackOverflow post helped me figure out how to flag and catch these download errors so that I could create a list of the urls with ‚Äúattachment errors‚Äù that I could follow up with manually.\n# expanding the attachment lists into separate url records\natt_urls &lt;- ct_labels %&gt;%\n  select(idShort, attachments) %&gt;%\n  unnest() %&gt;%\n  select(idShort, url) %&gt;%\n  mutate(url = as.character(url),\n         attachmentError = 'FALSE')\nknitr::kable(att_urls %&gt;% head(n = 3L))\n\n# creating directory for attachments\ndirAttachments &lt;- \"attachments/\"\ndir.create(dirAttachments)\n\n# downloading urls and checking for errors using try()\nfor (i in 1:length(att_urls$url)){\n  locAttachments &lt;-\n        paste(dirAttachments, \"/\", att_urls$idShort[i], \"_\", basename(att_urls$url[i]), sep = \"\")\n  step_to_try &lt;- try(attachment_check &lt;- download.file(att_urls$url[i], destfile = locAttachments))\n  if(\"try-error\" %in% class(step_to_try)) {\n    cat(\"Error row: \", i, \"\\n\", \"Error message: \", step_to_try[1], sep = \"\")\n    att_urls$attachmentError[i] = 'TRUE'\n  }\n}\nThe following selects the attachment records with errors, renames somes variables, and exports the data frame as a CSV.\n# preparing data frame for export to CSV\nattachment_errors &lt;- att_urls %&gt;%\n  filter(attachmentError == TRUE) %&gt;%\n  rename(Task_Id = idShort, Attachment_URL = url, Attachment_Error = attachmentError)\n\n# exporting to CSV\nwrite.csv(attachment_errors, file = \"attachment_errors.csv\")\n\nAside: If you have a lot of attachments per card, you may want to create a directory folder for each card. This for loop will get you there ‚Äì use it instead of the one above:\n\n# creates individual directory folders for each card id\nfor (i in 1:length(att_urls$url)){\n  dirAttachments &lt;- paste(dirFiles, \"attachments\", att_urls$idShort[i], sep = \"/\")\n  dir.create(dirAttachments) # creates directory for each unique card id\n  locAttachments &lt;- paste(dirAttachments, basename(url[i]), sep = \"/\")\n  download.file(url[i], destfile = locAttachments)\n}\nRecords in the main cards data frame are labeled ‚ÄúTRUE‚Äù within the attachments column if they have attachments and ‚ÄúFALSE‚Äù if they don‚Äôt.\n# converts the attachment column to a categorical variable in the main cards+labels data frame\nct_labels &lt;- ct_labels %&gt;%\n  mutate(attachments = ifelse(idShort %in% att_urls$idShort, TRUE, FALSE))"
  },
  {
    "objectID": "blog/2020-05-12-trello-to-airtable/index.html#lists",
    "href": "blog/2020-05-12-trello-to-airtable/index.html#lists",
    "title": "Migrating from Trello to Airtable: Working with JSON Data in R",
    "section": "Lists",
    "text": "Lists\nThe lists information is extracted similarly to the cards information, but flattening is a little more straightforward because it involves only one data frame. With more data frames, the unnest function is a better choice.\n# selecting lists information\nlists &lt;- trello$lists # list of 1 data frame\nglimpse(lists)\n\n# flattening\nlists_flat &lt;- lists[[1]] # 17 obs of 9 variables\n\n# selecting wanted variables\nlists_trim &lt;- lists_flat %&gt;%\n  select(id, name, closed) %&gt;%\n  rename(idList = id, nameList = name, closedList = closed)\nknitr::kable(lists_trim %&gt;% head(n = 3L))\n\n# joining back with main cards+labels data frame\nct_labels_list &lt;- left_join(ct_labels, lists_trim) %&gt;%\n  select(id:shortUrl, labelList_tidy:nameList, closed, closedList)"
  },
  {
    "objectID": "blog/2020-05-12-trello-to-airtable/index.html#data-prepping",
    "href": "blog/2020-05-12-trello-to-airtable/index.html#data-prepping",
    "title": "Migrating from Trello to Airtable: Working with JSON Data in R",
    "section": "Data prepping",
    "text": "Data prepping\nColumns in the new ct_labels_list data frame are given new names, and the lubridate package is used next to convert the date fields. This resource was helpful in understanding date conversions and formatting.\n# changing variable names\ntidy_cards &lt;- ct_labels_list %&gt;%\n  select(-id, -idList, -closedList) %&gt;%\n  rename(Task = name, Task_ID = idShort, Notes = desc, Done = dueComplete, Date_Due = due,\n         Labels = labelList_tidy, Trello_List = nameList, Trello_Last_Modified = dateLastActivity,\n         Trello_Url = shortUrl, Trello_Attachments = attachments, Archived = closed) %&gt;%\n  select(Task, Task_ID, Notes, Done, Date_Due, Labels, Trello_List, Trello_Last_Modified,\n         Trello_Url, Trello_Attachments, Archived) %&gt;%\n  mutate(Trello_Last_Modified = as_datetime(Trello_Last_Modified, tz = \"\"),\n         Date_Due = as_datetime(Date_Due, tz = \"\"),\n         Done = ifelse(is.na(Date_Due) == TRUE, 'NA', Done)) # ensures only undone tasks assigned a due date get marked as \"FALSE\"\nThe last step before exporting the final data frame tidy_cards is to check the unique number of tasks to make sure it matches the number of records in the data frame (i.e.¬†one task per observation).\n# determining the number of unique tasks\nlength(unique(tidy_cards$Task_ID))\n\n# final look at tidy_cards\nglimpse(tidy_cards)"
  },
  {
    "objectID": "blog/2020-05-12-trello-to-airtable/index.html#data-exporting",
    "href": "blog/2020-05-12-trello-to-airtable/index.html#data-exporting",
    "title": "Migrating from Trello to Airtable: Working with JSON Data in R",
    "section": "Data exporting",
    "text": "Data exporting\nwrite.csv(tidy_cards, file = \"tidy_cards.csv\")"
  },
  {
    "objectID": "blog/2020-05-12-trello-to-airtable/index.html#task",
    "href": "blog/2020-05-12-trello-to-airtable/index.html#task",
    "title": "Migrating from Trello to Airtable: Working with JSON Data in R",
    "section": "Task",
    "text": "Task\n\nBecause we know each observation in our table is unique, we can copy and paste Task into the first column and hide/delete the original column. Task is now the primary field."
  },
  {
    "objectID": "blog/2020-05-12-trello-to-airtable/index.html#task_id",
    "href": "blog/2020-05-12-trello-to-airtable/index.html#task_id",
    "title": "Migrating from Trello to Airtable: Working with JSON Data in R",
    "section": "Task_ID",
    "text": "Task_ID\n\nConvert Task_ID field type to ‚Äúnumber‚Äù."
  },
  {
    "objectID": "blog/2020-05-12-trello-to-airtable/index.html#notes",
    "href": "blog/2020-05-12-trello-to-airtable/index.html#notes",
    "title": "Migrating from Trello to Airtable: Working with JSON Data in R",
    "section": "Notes",
    "text": "Notes\n\nConvert Notes field type to ‚Äúlong text‚Äù and enable rich text formatting. This gives us the option of using Markdown in the future, but sadly doesn‚Äôt automatically recognize fully formatted Markdown in the imported text."
  },
  {
    "objectID": "blog/2020-05-12-trello-to-airtable/index.html#labels-1",
    "href": "blog/2020-05-12-trello-to-airtable/index.html#labels-1",
    "title": "Migrating from Trello to Airtable: Working with JSON Data in R",
    "section": "Labels",
    "text": "Labels\n\nChange Labels field type to ‚Äúmultiple select‚Äù so that it turns each item in each list into a label.\nOptional: Create a new Projects column next to Labels and use the labels to guide you in creating Project labels/categories: Group the records by Labels field and add to Projects field as appropriate.\n\nI recommend creating an NA project from the NA labels so that these tasks aren‚Äôt marked as ‚Äúuncategorized‚Äù in the Projects column. Having records with an ‚Äúempty‚Äù assignment gets in the way whenever you want to group by that category. To that end, it‚Äôs helpful to group by Project and make sure any ‚Äúempty‚Äù records get assigned to the ‚ÄúNA‚Äù Project.\n\nDelete from Labels any labels that were converted to Projects and ungroup the records."
  },
  {
    "objectID": "blog/2020-05-12-trello-to-airtable/index.html#trello_lists",
    "href": "blog/2020-05-12-trello-to-airtable/index.html#trello_lists",
    "title": "Migrating from Trello to Airtable: Working with JSON Data in R",
    "section": "Trello_Lists",
    "text": "Trello_Lists\n\nConvert Trello_Lists column field type into ‚Äúsingle select‚Äù. This gives us the option of using the Kanban style we were used to in Trello.\n\nEvery record should already be associated with a Trello_List.\n\nIf you want to replicate the Trello kanban layout, change the order of the single select options in Trello_Lists to match the order from left-to-right of your Trello board"
  },
  {
    "objectID": "blog/2020-05-12-trello-to-airtable/index.html#trello_url",
    "href": "blog/2020-05-12-trello-to-airtable/index.html#trello_url",
    "title": "Migrating from Trello to Airtable: Working with JSON Data in R",
    "section": "Trello_URL",
    "text": "Trello_URL\n\nConvert the Trello_URL field type to ‚ÄúURL‚Äù and then hide it if you don‚Äôt think you‚Äôll reference it often."
  },
  {
    "objectID": "blog/2020-05-12-trello-to-airtable/index.html#trello_attachments",
    "href": "blog/2020-05-12-trello-to-airtable/index.html#trello_attachments",
    "title": "Migrating from Trello to Airtable: Working with JSON Data in R",
    "section": "Trello_Attachments",
    "text": "Trello_Attachments\n\nConvert Trello_Attachments field type to ‚Äúsingle select‚Äù\nCreate a new Attachments column with field type ‚Äúattachment‚Äù. This is where you‚Äôll upload your downloaded attachments.\nFilter your records by Trello_Attachments so only show ‚ÄúTRUE‚Äù results\nSort records by Task_ID and simplify your view by temporarily hiding all columns except for Task_Name (primary field), Task_ID, Trello_Attachments, and the new Attachments column.\nOpen your local attachments folder and drag and drop the files to their corresponding Attachments field according to their Task_ID in the filename.\n\nIncrease the height of the records for this step. It‚Äôll make it easier to make sure you‚Äôre dragging and dropping to the correct record\n\nIf you encountered errors downloading some of your attachment URLs, now is the time to check your local attachment_errors.csv file for the URLs with errors during the download process. These are attachments you‚Äôll have to find elsewhere and upload to the Attachments field as needed.\nRemove the filter to your view and unhide any columns you wish to remain visible."
  },
  {
    "objectID": "blog/2020-05-12-trello-to-airtable/index.html#done-archived",
    "href": "blog/2020-05-12-trello-to-airtable/index.html#done-archived",
    "title": "Migrating from Trello to Airtable: Working with JSON Data in R",
    "section": "Done & Archived",
    "text": "Done & Archived\n\nConvert the Done and Archived field types to ‚ÄúCheckbox‚Äù and it will automatically assign a ‚Äúcheck‚Äù to all records marked ‚ÄúTRUE‚Äù and leave the ones marked ‚ÄúFALSE‚Äù or ‚ÄúNA‚Äù unchecked. So easy!\nThere is no direct option to ‚Äúarchive‚Äù tasks that have been completed like you can do in Trello, but you can apply a filter to your table view to hide the tasks that are complete. To do this, set the filter so that the Done and Archived fields are unchecked.\n\nThis must be repeated for each saved View of your records."
  },
  {
    "objectID": "blog/2020-05-12-trello-to-airtable/index.html#dates",
    "href": "blog/2020-05-12-trello-to-airtable/index.html#dates",
    "title": "Migrating from Trello to Airtable: Working with JSON Data in R",
    "section": "Dates",
    "text": "Dates\n\nModify Date_Due and Trello_Last_Modified field types to ‚ÄúDate‚Äù with time.\nYou can sort the records by Trello_Last_Modified if that‚Äôs helpful, but otherwise you can hide the column and keep it for historical reference.\nCreate a new column Last_Modified with field type ‚ÄúLast modified time‚Äù and select all columns you want to track changes to on a date/time basis moving forward."
  },
  {
    "objectID": "blog/2020-05-12-trello-to-airtable/index.html#record-views",
    "href": "blog/2020-05-12-trello-to-airtable/index.html#record-views",
    "title": "Migrating from Trello to Airtable: Working with JSON Data in R",
    "section": "Record Views",
    "text": "Record Views\n\nSelect Kanban from the Views options and group by Trello_List to see your tasks similar to how you saw them in Trello, complete with attachment covers! A bonus is that if you have multiple images attached to a card, you can view them without expanding the card by just hovering over the attachment cover!\nMove, collapse, and delete stacks as you see fit. Customize cards with as little or as much information as you want."
  },
  {
    "objectID": "blog/2020-05-12-trello-to-airtable/index.html#tasks-vs-subtasks",
    "href": "blog/2020-05-12-trello-to-airtable/index.html#tasks-vs-subtasks",
    "title": "Migrating from Trello to Airtable: Working with JSON Data in R",
    "section": "Tasks vs Subtasks",
    "text": "Tasks vs Subtasks\nThere are probably many ways to parallel the checklist option Trello gives you within a card.\n\nThe most straightforward is to use the basic checklist formatting within the Description field to create lists\nAnother is to think of your primary field Tasks instead as ‚Äòsubtasks‚Äô and create a new column to serve as the umbrella ‚Äòtask‚Äô. This new ‚Äòtask‚Äô column would be field type ‚Äúsingle selection‚Äù, then you could group your records by ‚Äòtask‚Äô."
  },
  {
    "objectID": "blog/2021-09-23-data-viz-a11y/index.html",
    "href": "blog/2021-09-23-data-viz-a11y/index.html",
    "title": "Resources for Data Viz Accessibility",
    "section": "",
    "text": "Updated on 2021-11-19 to include a link to a series of educational blog posts written by Mara Averick that cover {highcharter} and the accessibility module in detail. Thank you Mara!"
  },
  {
    "objectID": "blog/2021-09-23-data-viz-a11y/index.html#general-resources",
    "href": "blog/2021-09-23-data-viz-a11y/index.html#general-resources",
    "title": "Resources for Data Viz Accessibility",
    "section": "General resources",
    "text": "General resources\n\nNote: There is an extensive list of data viz accessibility resources at https://github.com/dataviza11y/resources/blob/main/README.md\nArticle by Doug Schepers that provides great background on data viz accessibility, explains how data visualization itself is assistive technology, and offers considerations for a variety of readers: Why Accessibility Is at the Heart of Data Visualization\nThe Chartability methodology helps data viz practitioners audit their data viz, and it‚Äôs language/tool-agnostic. Chartability was created by Frank Elavsky with input from the broader community and is the most thorough set of standards I‚Äôve come across.\n\n√òystein Moseng provides some basic practices to consider in the post 10 Guidelines for DataViz Accessibility. Among those included are these two which I don‚Äôt see covered as often:\n\nDo not rely on color alone to convey information. I‚Äôve also heard this referred to as ‚Äúcolor independence‚Äù and in some cases as ‚Äúdual-encoding‚Äù of information\n\nPrefer simple, familiar visualizations over complex novelties.\n\n\n\n\n\nPie chart from √òystein‚Äôs post using color and (optional) patterns to encode information\n\n\n\n\nTalk at the Data Visualization Society‚Äôs Outlier conference earlier this year, by Frank Elavsky, Larene Le Gassick, and Sarah Fossheim: Are your visualizations excluding people?\n\nGuidelines by Amy Cesal on how to write alt text for data visualizations: Writing Alt Text for Data Visualization\n\n\n\n\n\nExample template from Amy‚Äôs post\n\n\n\nPost by Lisa Charlotte Muth on how to pick colors for your data viz that everyone can appreciate: How to pick more beautiful colors for your data visualizations - Datawrapper Blog\n\n\n\n\n\nExample from Charlotte‚Äôs post of two different approaches to improving a pie chart\n\n\n\nPost by Gareth Ford Williams from The Readability Group about how to make more informed font choices: A Guide to Understanding What Makes a Typeface Accessible\n\n\nRelated is a talk from The Readability Group sharing findings from a survey study about font preferences including 2000+ participants. Among these were participants with dyslexia characteristics and participants with poor near vision: Don‚Äôt Believe the Type!\n\n\n\n\n\nBar graph showing the frequency by which 20 different fonts were selected by study participants with strong poor near vision in comparison with users with no poor near vision.\n\n\n\n\n\nSarah Fossheim authored a post titled An intro to designing accessible data visualizations which uses real-word applications to demonstrate 10 different accessibility practices.\nSarah also provides a code-through showing how to make screenreader-friendly graphs using D3.js in their post How to create a screen reader accessible graph like Apple‚Äôs with D3.js\n\n\n\nAmber Thomas provides an example of how to make scrollytales more accessible in a piece created with Ofunne Amaka for The Pudding: The Naked Truth\n\n\n\nI'm excited to release this project for many reasons, but one among them is that I introduced lots of new (to me) #a11y features. My favorite: the ability to turn off scrollytelling üíñ Would love to hear what folks think! pic.twitter.com/eDSQr9RjFe\n\n‚Äî Amber Thomas (@ProQuesAsker) March 25, 2021\n\n\n\n\nChris DeMartini has a series of blog posts documenting his journey auditing one of his public Tableau visualizations for accessibility:\n\nA Tableau Accessibility Journey\nFocus Order\nColor Contrast and Font Size\n\nKeyboard Accessibility \n\n\n\n\n\n\n\nTitle of Chris‚Äôs Tableau visualization being checked for color contrast."
  },
  {
    "objectID": "blog/2021-09-23-data-viz-a11y/index.html#r-resources",
    "href": "blog/2021-09-23-data-viz-a11y/index.html#r-resources",
    "title": "Resources for Data Viz Accessibility",
    "section": "R resources",
    "text": "R resources\n\n\nLiz Hare and I gave a talk earlier this year on alt text in data viz shared as a part of TidyTuesday on Twitter. After web-scraping alt text from TidyTuesday tweets we found that only 3% of data viz tweets had alt text to accompany them (over the first 3 years of the TidyTuesday project). Links to the video recording, slides, and resources at https://github.com/spcanelon/csvConf2021. The talk includes guidelines on what makes effective alt text for data viz (complementary to those Amy Cesal includes in her post).\n\n\n\n\n\nSlide from our presentation summarizing the most useful alt-text features found among 196 data viz tweets\n\n\n\nPost from RStudio on how to add alt text to visualizations produced in R Markdown using code chunk option fig.alt: New in knitr: Improved accessibility with image alt text. New in knitr v1.35: You can now add code chunk options inside the code chunk!\nExample updated thanks to a heads-up from Garrick:\n#| fig.cap: Bigger flippers, bigger bills \n#| fig.alt: Scatterplot of flipper length by bill length of 3 penguin species, where we show penguins with bigger flippers have bigger bills.\n\nggplot(data = penguins, aes(x = flipper_length_mm,\n                            y = bill_length_mm,\n                            color = species)) +\n  geom_point(aes(shape = species), alpha = 0.8) +\n  scale_color_manual(\n    values = c(\"darkorange\",\"purple\",\"cyan4\")) \n\n\nCode chunk adapted from the RStudio blog post\n\nThe previous example included fig.cap and fig.alt in the code chunk heading:\n\n\n\n\nBigger flippers, bigger bills\n\n\n\n\n\n\nThe ggpattern R package developed by Mike FC supports filling ggplot2 geometries with patterns. If used judiciously, patterns can help make visualizations more accessible by providing an additional way to encode information without relying on color. Below is one example using ggpattern v0.2.2:\n\nlibrary(ggpattern)\n\npenguinColors &lt;- c(\"darkorange\", \"purple\", \"cyan4\")\n\nggplot(penguins, aes(species)) +\ngeom_bar_pattern(aes(fill = species,\n                    pattern = species,\n                    pattern_color = species),\n  fill = penguinColors,\n  alpha = 0.1,\n  linewidth = 1,\n  color = penguinColors,\n  pattern_color = penguinColors,\n  pattern_fill = penguinColors,\n  pattern_spacing = 0.025\n) +\ntheme_minimal() +\ntheme(legend.position = 'none')\n\n\n\nDifferent patterns mapped onto penguin species along with different colors\n\n\n\n\n\nThe Highcharter R package developed by Joshua Kunst adds interactivity to data viz using Highcharts JavaScript components designed with web accessibility in mind. The package has a learning curve, but lucky for us Mara Averick wrote an excellent series of blog posts on using the Highcharts accessibility module with {highcharter}.\n\n\n\n\n\nInteractive scatterplot from Mara‚Äôs post using color and shape to encode information about penguin species"
  },
  {
    "objectID": "project/2021-01-01-useR-2021/index.html",
    "href": "project/2021-01-01-useR-2021/index.html",
    "title": "useR!2021 Cost Conversion Tool",
    "section": "",
    "text": "I created a cost conversion tool used for the useR!2021 Conference to adapt conference and sponsorship fees according to the country of residence. The cost conversion was done according to Gross Domestic Product (GDP) adjusted by Purchasing Power Parity (PPP) provided by the World Bank. We wanted conference attendees and sponsors from different parts of the world to be able to participate in useR! and believed that this is a fair approach. It reflects the reality that attendees and sponsors from ‚ÄúHigh income‚Äù countries have a different purchasing power than those from ‚ÄúLow income‚Äù countries. The income categories and cost conversions are listed in a data table created in R that attendees can use to search for their country and attendee status if applicable (i.e.¬†Industry, Academia, Student). They can use a built-in search bar, or filter according to a specific column.\nYou can read more about purchasing power parities, price level indexes, and PPP-based expenditures in the May 2020 World Bank post New results from the International Comparison Program shed light on the size of the global economy.\nThe Global Income Groups listed in the fee tables below were obtained using data from the 2017 International Comparison Program (ICP) which you can read more about in the report Purchasing Power Parities and the Size of World Economies: Results from the 2017 International Comparison Program. The conversion factors were calculated using PPP-based GDP per capita for each Global Income Group using data from the ICP 2017 World Bank Database.\n\n\n\n Back to topCitationFor attribution, please cite this work as:\nCanel√≥n, Silvia. 2021. ‚ÄúuseR!2021 Cost Conversion Tool.‚Äù\nJanuary 1, 2021. https://silviacanelon.com/project/2021-01-01-useR-2021/."
  },
  {
    "objectID": "project/2020-11-03-xaringan-nhs-r/index.html#workshop",
    "href": "project/2020-11-03-xaringan-nhs-r/index.html#workshop",
    "title": "Sharing Your Work with xaringan",
    "section": "Workshop",
    "text": "Workshop\nDay 1 covers the nuts and bolts of creating presentation slides using xaringan and deploying them in HTML format for easy sharing with others.\nDay 2 covers how to take your slides to the next level with the xaringanExtra package and how to customize slides with CSS.\nThis workshop is designed for R users already familiar with R Markdown and GitHub."
  },
  {
    "objectID": "project/2023-04-18-r-for-the-rest-of-us/index.html",
    "href": "project/2023-04-18-r-for-the-rest-of-us/index.html",
    "title": "R for the Rest of Us Podcast: Episode #7",
    "section": "",
    "text": "From David Keyes of R for the Rest of Us:\n\nIn this episode, I talk with Silvia Canel√≥n, a postdoctoral research scientist in the Department of Biostatistics, Epidemiology, and Informatics at the University of Pennsylvania. Silvia shares why she loves using xaringan to create captivating, audience-friendly presentations directly from R markdown. Making presentations with R Markdown not only saves her time, but also eases the stress associated with updating and distributing presentations.\n\n\n\n\n Back to topCitationFor attribution, please cite this work as:\nCanel√≥n, Silvia. 2023. ‚ÄúR for the Rest of Us Podcast: Episode\n#7.‚Äù April 18, 2023. https://silviacanelon.com/project/2023-04-18-r-for-the-rest-of-us/."
  },
  {
    "objectID": "project/index.html",
    "href": "project/index.html",
    "title": "Projects",
    "section": "",
    "text": "Philly Center City District SIPS: An Interactive Map\n\n\n\nR\n\n\nmaps\n\n\nwebscraping\n\n\nrobotstxt\n\n\nrvest\n\n\nleaflet\n\n\ntidygeocoder\n\n\n\n\nJun 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR for the Rest of Us Podcast: Episode #7\n\n\n\nR\n\n\nxaringan\n\n\nR Markdown\n\n\npodcast\n\n\n\n\nApr 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProfessional, Polished, Presentable\n\n\n\nR\n\n\nxaringan\n\n\nR\n\n\nEducation\n\n\n\n\nJul 7, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesdayAltText\n\n\n\nR\n\n\nTidyTuesday\n\n\nTidyTuesdayAltText\n\n\naccessibility\n\n\nPackage\n\n\n\n\nMay 4, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nuseR!2021 Cost Conversion Tool\n\n\n\nuseR\n\n\ntidyverse\n\n\nR\n\n\n\n\nJan 1, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnse√±ar Tecnolog√≠a en Comunidad\n\n\n\nEducation\n\n\nEspa√±ol\n\n\n\n\nDec 28, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnhsr CSS Theme for xaringan\n\n\n\nR\n\n\nxaringan\n\n\ncss\n\n\n\n\nDec 9, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSharing Your Work with xaringan\n\n\n\nR\n\n\nxaringan\n\n\nEducation\n\n\n\n\nNov 3, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nxaringan CSS Theme for nhsrtheme\n\n\n\nOct 29, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing the Inside Journey of Recovery from Opioid Use Disorder\n\n\n\nEducation\n\n\ndata hack\n\n\nopioid\n\n\n\n\nMar 25, 2020\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "project/2020-12-28-teaching-tech-together-es/index.html",
    "href": "project/2020-12-28-teaching-tech-together-es/index.html",
    "title": "Ense√±ar Tecnolog√≠a en Comunidad",
    "section": "",
    "text": "Este proyecto llev√≥ acabo la traducci√≥n al castellano del libro Teaching Tech Together escrito por Greg Wilson. El proyecto fue coordinado por mi amiga y colega Yanina Bellini Saibene.\nYo particip√© como traductora del cap√≠tulo ‚ÄúMotivation and Demotivation‚Äù y revisora del cap√≠tulo ‚ÄúExpertise and Memory.‚Äù\n\nSeptiembre de 2020 ‚Äì Diciembre de 2020. Traducci√≥n colaborativa al castellano del libro ‚ÄúTeaching Tech Together. How to create and deliver lessons that work and build a teaching community around them‚Äù de Greg Wilson (2019, Taylor & Francis, ISBN 978-0-367-35328-5, https://teachtogether.tech/). Coordinaci√≥n general de la traducci√≥n: Yanina Bellini Saibene; Edici√≥n general: Yanina Bellini Saibene y Natalia Morandeira. Participaci√≥n como traductora y revisora de cap√≠tulos. M√°s informaci√≥n y grupo de traductoras: https://github.com/gvwilson/teachtogether.tech/blob/master/es/README.md"
  },
  {
    "objectID": "project/2020-12-28-teaching-tech-together-es/index.html#proyecto",
    "href": "project/2020-12-28-teaching-tech-together-es/index.html#proyecto",
    "title": "Ense√±ar Tecnolog√≠a en Comunidad",
    "section": "",
    "text": "Este proyecto llev√≥ acabo la traducci√≥n al castellano del libro Teaching Tech Together escrito por Greg Wilson. El proyecto fue coordinado por mi amiga y colega Yanina Bellini Saibene.\nYo particip√© como traductora del cap√≠tulo ‚ÄúMotivation and Demotivation‚Äù y revisora del cap√≠tulo ‚ÄúExpertise and Memory.‚Äù\n\nSeptiembre de 2020 ‚Äì Diciembre de 2020. Traducci√≥n colaborativa al castellano del libro ‚ÄúTeaching Tech Together. How to create and deliver lessons that work and build a teaching community around them‚Äù de Greg Wilson (2019, Taylor & Francis, ISBN 978-0-367-35328-5, https://teachtogether.tech/). Coordinaci√≥n general de la traducci√≥n: Yanina Bellini Saibene; Edici√≥n general: Yanina Bellini Saibene y Natalia Morandeira. Participaci√≥n como traductora y revisora de cap√≠tulos. M√°s informaci√≥n y grupo de traductoras: https://github.com/gvwilson/teachtogether.tech/blob/master/es/README.md"
  },
  {
    "objectID": "project/2020-10-29-nhsrtheme/index.html",
    "href": "project/2020-10-29-nhsrtheme/index.html",
    "title": "xaringan CSS Theme for nhsrtheme",
    "section": "",
    "text": "In preparation for a xaringan workshop I created for the NHS-R 2020 Conference, I designed a custom CSS theme with input from the NHS-R Community that followed the NHS identity guidelines. This theme was also contributed to the xaringan package developed by Yihui Xie."
  },
  {
    "objectID": "project/2020-10-29-nhsrtheme/index.html#theme",
    "href": "project/2020-10-29-nhsrtheme/index.html#theme",
    "title": "xaringan CSS Theme for nhsrtheme",
    "section": "",
    "text": "In preparation for a xaringan workshop I created for the NHS-R 2020 Conference, I designed a custom CSS theme with input from the NHS-R Community that followed the NHS identity guidelines. This theme was also contributed to the xaringan package developed by Yihui Xie."
  },
  {
    "objectID": "accessibility.html",
    "href": "accessibility.html",
    "title": "Accessibility commitment",
    "section": "",
    "text": "Travel back to the home page or about page."
  },
  {
    "objectID": "accessibility.html#feedback",
    "href": "accessibility.html#feedback",
    "title": "Accessibility commitment",
    "section": "Feedback",
    "text": "Feedback\nI welcome any feedback on the accessibility of my site and/or the educational materials I create. Please let me know if you encounter any accessibility barriers by using my contact form and I‚Äôll do my best to respond promptly.\nThank you for visiting my site and for taking the time to read this page"
  },
  {
    "objectID": "accessibility.html#accessibility-practices",
    "href": "accessibility.html#accessibility-practices",
    "title": "Accessibility commitment",
    "section": "Accessibility practices",
    "text": "Accessibility practices\nThis site has been designed with the following features in mind:\n\nA color palette that meets WCAG 2.1 AA standards for contrast\nAlternative text for all informative images\nReadable font faces, specifically to avoid impostor letter shapes and mirroring. This site primarily uses Red Hat Text which is freely available and has been found to be relatively accessible to users with dyslexic traits and poor near vision.1\nA table of contents in the blog post sidebar for easier navigation\n\nI‚Äôm aware there is much more to inclusive and accessible design and I‚Äôm learning how to implement better accessibility practices in the content I create. I‚Äôm not a web developer but my plan is to regularly audit my site for accessibility failures and learn how to remedy them as best I can. I‚Äôll be using the following evaluation tools:\n\nWAVE Web Accessibility Evaluation Tool\n\nIn addition, I‚Äôll document the failures and any corrective actions as issues in the GitHub repository housing the files used to build this site."
  },
  {
    "objectID": "accessibility.html#work-related-to-accessibility",
    "href": "accessibility.html#work-related-to-accessibility",
    "title": "Accessibility commitment",
    "section": "Work related to accessibility",
    "text": "Work related to accessibility\n\nTalk: Revealing Room for Improvement in Accessibility within a Social Media Data Visualization Learning Community\nBlog post: Resources for Data Viz Accessibility\nBlog post: Auditing for Web Accessibility"
  },
  {
    "objectID": "accessibility.html#footnotes",
    "href": "accessibility.html#footnotes",
    "title": "Accessibility commitment",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor more on font accessibility, I recommend the talk Don‚Äôt Believe the Type! by The Readability Group.‚Ü©Ô∏é"
  },
  {
    "objectID": "talk/2023-03-09-penn-community-scholars/index.html",
    "href": "talk/2023-03-09-penn-community-scholars/index.html",
    "title": "Data Analytics 101",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "talk/2022-11-10-thinking-big/index.html",
    "href": "talk/2022-11-10-thinking-big/index.html",
    "title": "Thinking Big with Maps in R",
    "section": "",
    "text": "The road to map-making can take some unexpected twists and turns when you scale up an interactive map from hundreds of features to hundreds of thousands. This talk is a story about creative spatial data wrangling, powerful R packages, and a heroic #RStats community.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "talk/2022-04-27-dbei-research-day/index.html",
    "href": "talk/2022-04-27-dbei-research-day/index.html",
    "title": "Exploring Traumatic Brain Injury Mechanisms and Severity Using Electronic Health Records",
    "section": "",
    "text": "This abstract was one of 10 selected for a flashtalk presentation. And the flashtalk received an award! üéâ\nThe talk recording will be available to the public on April 28, 2022. The accompanying (PowerPoint) slides are available to download using the ‚ÄúSlides‚Äù link above.\n2022 CCEB & DBEI Research Day Poster (letter)"
  },
  {
    "objectID": "talk/2022-04-27-dbei-research-day/index.html#abstract",
    "href": "talk/2022-04-27-dbei-research-day/index.html#abstract",
    "title": "Exploring Traumatic Brain Injury Mechanisms and Severity Using Electronic Health Records",
    "section": "Abstract",
    "text": "Abstract\n\nObjective\nOften referred to as the ‚Äúsilent epidemic,‚Äù Traumatic Brain Injury (TBI) is a public health concern contributing to disability and death worldwide. Our study describes a cohort of TBI patients within the Penn Medicine health system and the distribution of TBI injury mechanisms and severity.\n\n\nMethods\nWe obtained Electronic Health Record data for 1,060,100 female patients treated at Penn Medicine inpatient or outpatient clinics from 2010-2017. We identified patients with TBI diagnoses using ICD-9/10 codes and the Disease Control and Prevention (CDC) and Department of Defense (DOD) definitions for TBI and TBI severity. The CDC/DOD codes for TBI were then manually annotated with mechanisms of TBI injury (e.g.¬†Sport Mechanism of Injury, Collision or Crash, Foreign Body Object). The highest TBI severity category was noted for each patient and defined, in increasing severity, as ‚ÄúMild,‚Äù ‚ÄúModerate,‚Äù ‚ÄúSevere,‚Äù or ‚ÄúPenetrating.‚Äù We report the distribution of TBI mechanisms and severity among this patient population.\n\n\nResults\nThere were 4,392 patients with a total of 9,800 TBI diagnoses. The majority of diagnoses in the cohort were Mild (5,704; 58%), followed by Moderate (3,840; 39%), Severe (173; 1.8%), and Penetrating (83; 0.8%). The following are the six most common mechanisms observed to contribute to TBI diagnoses: ‚ÄúInjury,‚Äù ‚ÄúMechanism of Injury,‚Äù ‚ÄúAccidents,‚Äù ‚ÄúPhysical Accidents,‚Äù ‚ÄúFall Mechanism of Injury,‚Äù and ‚ÄúTraffic Vehicle Accident.‚Äù"
  },
  {
    "objectID": "talk/2024-03-26-env-justice/index.html",
    "href": "talk/2024-03-26-env-justice/index.html",
    "title": "Environmental Justice and Policy Panel",
    "section": "",
    "text": "Source: Climate Leaders @Penn on LinkedIn\nWhat: Panel discussion with speakers from Philly Thrive, Penn Medicine Center for Health Justice, and Philadelphia Office of Sustainability\nTopics: How did you enter the environmental justice field? How can we engage with community care/environmental justice outside of our careers? Do I need to have a certain degree or job in order to advocate for change? How do we challenge hierarchies of knowledge? What are examples of place-based initiatives in Philadelphia?\n\n\n\n Back to top"
  },
  {
    "objectID": "talk/2021-03-16-xaringan-deploy-demo/index.html",
    "href": "talk/2021-03-16-xaringan-deploy-demo/index.html",
    "title": "Writing Presentations in R",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "talk/2021-07-07-presentable-user2021/index.html",
    "href": "talk/2021-07-07-presentable-user2021/index.html",
    "title": "Professional, Polished, Presentable: Making Great Slides with xaringan",
    "section": "",
    "text": "Co-instructed with Garrick Aden-Buie"
  },
  {
    "objectID": "talk/2021-07-07-presentable-user2021/index.html#abstract",
    "href": "talk/2021-07-07-presentable-user2021/index.html#abstract",
    "title": "Professional, Polished, Presentable: Making Great Slides with xaringan",
    "section": "Abstract",
    "text": "Abstract\nThe xaringan package brings professional, impressive, and visually appealing slides to the powerful R Markdown ecosystem. Through our hands-on tutorial, you will learn how to design highly effective slides that support presentations for teaching and reporting alike. Over three hours, you will learn how to create an accessible baseline design that matches your institution or organization‚Äôs style guide. Together we‚Äôll explore the basics of CSS‚Äîthe design language of the internet‚Äîand how we can leverage CSS to produce elegant slides for effective communication."
  },
  {
    "objectID": "talk/2021-03-23-amia-informatics-summit/index.html",
    "href": "talk/2021-03-23-amia-informatics-summit/index.html",
    "title": "The Impact of Sickle Cell Status on Adverse Delivery Outcomes Using Electronic Health Record Data",
    "section": "",
    "text": "This study investigates the effect of sickle cell trait and sickle cell disease, on adverse pregnancy outcomes at Penn Medicine. The risk of a Cesarean section (C-section), preterm birth, stillbirth, pain crisis, blood transfusion, and hemorrhage during delivery were all found to be significantly correlated with race/ethnicity, sickle cell disease, the number of pain crises before delivery, and the number of blood transfusions before delivery. Multiple birth was also found to significantly increase the risk of these same outcomes.\n\nOral Presentations S17: March 23, 2021 11:30am-1pm ET\n\n\n\nBanner for the 2021 AMIA Informatics Summit (March 22-25)"
  },
  {
    "objectID": "talk/2021-03-23-amia-informatics-summit/index.html#abstract",
    "href": "talk/2021-03-23-amia-informatics-summit/index.html#abstract",
    "title": "The Impact of Sickle Cell Status on Adverse Delivery Outcomes Using Electronic Health Record Data",
    "section": "",
    "text": "This study investigates the effect of sickle cell trait and sickle cell disease, on adverse pregnancy outcomes at Penn Medicine. The risk of a Cesarean section (C-section), preterm birth, stillbirth, pain crisis, blood transfusion, and hemorrhage during delivery were all found to be significantly correlated with race/ethnicity, sickle cell disease, the number of pain crises before delivery, and the number of blood transfusions before delivery. Multiple birth was also found to significantly increase the risk of these same outcomes.\n\nOral Presentations S17: March 23, 2021 11:30am-1pm ET\n\n\n\nBanner for the 2021 AMIA Informatics Summit (March 22-25)"
  },
  {
    "objectID": "talk/2024-07-10-data-equity-ldi/index.html",
    "href": "talk/2024-07-10-data-equity-ldi/index.html",
    "title": "Considering Equity in Data Visualization",
    "section": "",
    "text": "Emily and I had the pleasure of presenting to the 2024 cohort of LDI Summer Undergraduate Mentored Research Program (SUMR). The materials for this interactive presentation were adapted from the Urban Institute‚Äôs series of Do No Harm guides, which focus on how to incorporate principles of equity into data collection, visualization, and communication. We concluded our talk by playing a game with the Scholars, encouraging them to use what they took away from the presentation to identify areas for improvement in a series of visualizations taken from published dashboards, papers, and other sources."
  },
  {
    "objectID": "talk/2024-07-10-data-equity-ldi/index.html#description",
    "href": "talk/2024-07-10-data-equity-ldi/index.html#description",
    "title": "Considering Equity in Data Visualization",
    "section": "",
    "text": "Emily and I had the pleasure of presenting to the 2024 cohort of LDI Summer Undergraduate Mentored Research Program (SUMR). The materials for this interactive presentation were adapted from the Urban Institute‚Äôs series of Do No Harm guides, which focus on how to incorporate principles of equity into data collection, visualization, and communication. We concluded our talk by playing a game with the Scholars, encouraging them to use what they took away from the presentation to identify areas for improvement in a series of visualizations taken from published dashboards, papers, and other sources."
  }
]